{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M2.5 - Homework Assignment: Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Student: Antonio López Chávez - A01741741\n",
    "#### Professor: PhD Jorge Mario Cruz Duarte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Experiment 1 (40/100 points): Baseline Model**\n",
    "#### This baseline model will be the one you must beat in the next experiments. So, implement a basic CNN model with the following architecture:\n",
    "* Convolutional layer with 32 filters, 3×3 kernel size, and ReLU activation.\n",
    "* MaxPooling layer with 2×2 pool size.\n",
    "* Flatten layer.\n",
    "* Dense layer with 128 units and ReLU activation.\n",
    "* Dense output layer with softmax activation.\n",
    "#### After compiling the model, train it on the CIFAR-10 dataset and report the accuracy. Consider that this model would be the one to beat in the following experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Very important to import these libraries first\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.functional import relu, log_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the seed to get reproducible results\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Using the correct mean and std for the CIFAR-10 dataset, usually used as 0.5 for both or 0.5 for mean and 0.25 for std\n",
    "# Sources: TODO https://stackoverflow.com/questions/66678052/how-to-calculate-the-mean-and-the-std-of-cifar10-data\n",
    "customize_image_transforming = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using GPU acceleration to speed up the training process (finally using the GPU for academic purposes!)\n",
    "gpu_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Downloading the CIFAR-10 dataset with the customized image transformation (may take a while, especially the first time and with bad internet connection)\n",
    "cifar_train_data = datasets.CIFAR10(root='./data', train=True, download=True, transform=customize_image_transforming)\n",
    "cifar_test_data = datasets.CIFAR10(root='./data', train=False, download=True, transform=customize_image_transforming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the batch size to 4 and shuffling the training data for better training (best practices)\n",
    "cifar_train_loader = DataLoader(cifar_train_data, batch_size=4, shuffle=True)\n",
    "cifar_test_loader = DataLoader(cifar_test_data, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now define the Convolutional Neural Network Layers\n",
    "convolutional_layer = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1).to(gpu_device)   # 32 filters, 3x3 kernel and ReLU activation function, directed to the gpu processor\n",
    "max_pooling_layer = nn.MaxPool2d(2, 2).to(gpu_device)   # Max pooling layer with 2x2 pool size, directed to the gpu processor\n",
    "dense_layer = nn.Linear(32 * 16 * 16, 128).to(gpu_device)   # Dense layer with 128 units and ReLU activation, directed to the gpu processor\n",
    "dense_output_layer = nn.Linear(128, 10).to(gpu_device)  # Dense output layer, transforming the output to a prediction of 10 classes, directed to the gpu processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "loss_criterion = torch.nn.NLLLoss()\n",
    "adam_optimizer = optim.Adam([{'params': convolutional_layer.parameters()},\n",
    "                        {'params': dense_layer.parameters()},\n",
    "                        {'params': dense_output_layer.parameters()}], lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining training and testing functions, as it is easier to invoke them for each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "def train(epoch):\n",
    "    # It's only necessary to set the training mode for dropout and batch normalization layers\n",
    "    for batch_index, (data, target) in enumerate(cifar_train_loader):\n",
    "        data, target = data.to(gpu_device), target.to(gpu_device)\n",
    "        adam_optimizer.zero_grad()\n",
    "        tensor_x = relu(convolutional_layer(data))\n",
    "        tensor_x = max_pooling_layer(tensor_x)\n",
    "        tensor_x = tensor_x.view(-1, 32 * 16 * 16)  # Flatten layer\n",
    "        tensor_x = relu(dense_layer(tensor_x))\n",
    "        tensor_x = dense_output_layer(tensor_x)\n",
    "        training_loss = log_softmax(tensor_x, dim=1)  # Apply log-softmax\n",
    "        training_loss = loss_criterion(training_loss, target)\n",
    "        training_loss.backward()\n",
    "        adam_optimizer.step()\n",
    "        if batch_index % 100 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_index * len(data)}/{len(cifar_train_loader.dataset)} ({100. * batch_index / len(cifar_train_loader):.0f}%)]\\tLoss: {training_loss.item():.6f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the model\n",
    "def test():\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in cifar_test_loader:\n",
    "            data, target = data.to(gpu_device), target.to(gpu_device)\n",
    "            tensor_x = relu(convolutional_layer(data))\n",
    "            tensor_x = max_pooling_layer(tensor_x)\n",
    "            tensor_x = tensor_x.view(-1, 32 * 16 * 16)\n",
    "            tensor_x = relu(dense_layer(tensor_x))\n",
    "            tensor_x = dense_output_layer(tensor_x)\n",
    "            test_loss_prob = log_softmax(tensor_x, dim=1)  # Apply log-softmax\n",
    "            test_loss += loss_criterion(test_loss_prob, target).item()\n",
    "            pred = test_loss_prob.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(cifar_test_loader.dataset)\n",
    "    accuracy = 100. * correct / len(cifar_test_loader.dataset)\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(cifar_test_loader.dataset)} ({accuracy:.0f}%)\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.371911\n",
      "Train Epoch: 1 [400/50000 (1%)]\tLoss: 1.976027\n",
      "Train Epoch: 1 [800/50000 (2%)]\tLoss: 2.199131\n",
      "Train Epoch: 1 [1200/50000 (2%)]\tLoss: 2.541399\n",
      "Train Epoch: 1 [1600/50000 (3%)]\tLoss: 1.936052\n",
      "Train Epoch: 1 [2000/50000 (4%)]\tLoss: 1.300260\n",
      "Train Epoch: 1 [2400/50000 (5%)]\tLoss: 1.912566\n",
      "Train Epoch: 1 [2800/50000 (6%)]\tLoss: 1.484597\n",
      "Train Epoch: 1 [3200/50000 (6%)]\tLoss: 0.890588\n",
      "Train Epoch: 1 [3600/50000 (7%)]\tLoss: 1.362807\n",
      "Train Epoch: 1 [4000/50000 (8%)]\tLoss: 1.463050\n",
      "Train Epoch: 1 [4400/50000 (9%)]\tLoss: 1.787107\n",
      "Train Epoch: 1 [4800/50000 (10%)]\tLoss: 1.919241\n",
      "Train Epoch: 1 [5200/50000 (10%)]\tLoss: 1.882367\n",
      "Train Epoch: 1 [5600/50000 (11%)]\tLoss: 2.721268\n",
      "Train Epoch: 1 [6000/50000 (12%)]\tLoss: 2.248428\n",
      "Train Epoch: 1 [6400/50000 (13%)]\tLoss: 1.088720\n",
      "Train Epoch: 1 [6800/50000 (14%)]\tLoss: 0.935433\n",
      "Train Epoch: 1 [7200/50000 (14%)]\tLoss: 1.312252\n",
      "Train Epoch: 1 [7600/50000 (15%)]\tLoss: 0.892239\n",
      "Train Epoch: 1 [8000/50000 (16%)]\tLoss: 0.858540\n",
      "Train Epoch: 1 [8400/50000 (17%)]\tLoss: 1.348632\n",
      "Train Epoch: 1 [8800/50000 (18%)]\tLoss: 1.039339\n",
      "Train Epoch: 1 [9200/50000 (18%)]\tLoss: 0.931786\n",
      "Train Epoch: 1 [9600/50000 (19%)]\tLoss: 2.813616\n",
      "Train Epoch: 1 [10000/50000 (20%)]\tLoss: 1.486924\n",
      "Train Epoch: 1 [10400/50000 (21%)]\tLoss: 0.936259\n",
      "Train Epoch: 1 [10800/50000 (22%)]\tLoss: 1.893560\n",
      "Train Epoch: 1 [11200/50000 (22%)]\tLoss: 1.169865\n",
      "Train Epoch: 1 [11600/50000 (23%)]\tLoss: 1.045546\n",
      "Train Epoch: 1 [12000/50000 (24%)]\tLoss: 1.654455\n",
      "Train Epoch: 1 [12400/50000 (25%)]\tLoss: 1.757789\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 1.299408\n",
      "Train Epoch: 1 [13200/50000 (26%)]\tLoss: 1.390415\n",
      "Train Epoch: 1 [13600/50000 (27%)]\tLoss: 1.963534\n",
      "Train Epoch: 1 [14000/50000 (28%)]\tLoss: 1.060811\n",
      "Train Epoch: 1 [14400/50000 (29%)]\tLoss: 1.540615\n",
      "Train Epoch: 1 [14800/50000 (30%)]\tLoss: 1.933642\n",
      "Train Epoch: 1 [15200/50000 (30%)]\tLoss: 0.656723\n",
      "Train Epoch: 1 [15600/50000 (31%)]\tLoss: 1.397880\n",
      "Train Epoch: 1 [16000/50000 (32%)]\tLoss: 0.598861\n",
      "Train Epoch: 1 [16400/50000 (33%)]\tLoss: 1.661258\n",
      "Train Epoch: 1 [16800/50000 (34%)]\tLoss: 1.597335\n",
      "Train Epoch: 1 [17200/50000 (34%)]\tLoss: 1.194976\n",
      "Train Epoch: 1 [17600/50000 (35%)]\tLoss: 0.497748\n",
      "Train Epoch: 1 [18000/50000 (36%)]\tLoss: 1.424102\n",
      "Train Epoch: 1 [18400/50000 (37%)]\tLoss: 2.296517\n",
      "Train Epoch: 1 [18800/50000 (38%)]\tLoss: 1.474198\n",
      "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 1.006103\n",
      "Train Epoch: 1 [19600/50000 (39%)]\tLoss: 1.734535\n",
      "Train Epoch: 1 [20000/50000 (40%)]\tLoss: 1.460442\n",
      "Train Epoch: 1 [20400/50000 (41%)]\tLoss: 1.607670\n",
      "Train Epoch: 1 [20800/50000 (42%)]\tLoss: 1.146181\n",
      "Train Epoch: 1 [21200/50000 (42%)]\tLoss: 1.040121\n",
      "Train Epoch: 1 [21600/50000 (43%)]\tLoss: 1.608279\n",
      "Train Epoch: 1 [22000/50000 (44%)]\tLoss: 1.791869\n",
      "Train Epoch: 1 [22400/50000 (45%)]\tLoss: 1.169424\n",
      "Train Epoch: 1 [22800/50000 (46%)]\tLoss: 1.088159\n",
      "Train Epoch: 1 [23200/50000 (46%)]\tLoss: 1.650542\n",
      "Train Epoch: 1 [23600/50000 (47%)]\tLoss: 0.976556\n",
      "Train Epoch: 1 [24000/50000 (48%)]\tLoss: 0.580996\n",
      "Train Epoch: 1 [24400/50000 (49%)]\tLoss: 1.767766\n",
      "Train Epoch: 1 [24800/50000 (50%)]\tLoss: 1.500808\n",
      "Train Epoch: 1 [25200/50000 (50%)]\tLoss: 1.935693\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 1.309811\n",
      "Train Epoch: 1 [26000/50000 (52%)]\tLoss: 1.290856\n",
      "Train Epoch: 1 [26400/50000 (53%)]\tLoss: 2.099776\n",
      "Train Epoch: 1 [26800/50000 (54%)]\tLoss: 1.110203\n",
      "Train Epoch: 1 [27200/50000 (54%)]\tLoss: 0.923619\n",
      "Train Epoch: 1 [27600/50000 (55%)]\tLoss: 1.562910\n",
      "Train Epoch: 1 [28000/50000 (56%)]\tLoss: 1.653514\n",
      "Train Epoch: 1 [28400/50000 (57%)]\tLoss: 2.852113\n",
      "Train Epoch: 1 [28800/50000 (58%)]\tLoss: 2.369246\n",
      "Train Epoch: 1 [29200/50000 (58%)]\tLoss: 2.328216\n",
      "Train Epoch: 1 [29600/50000 (59%)]\tLoss: 0.584399\n",
      "Train Epoch: 1 [30000/50000 (60%)]\tLoss: 0.582255\n",
      "Train Epoch: 1 [30400/50000 (61%)]\tLoss: 1.280931\n",
      "Train Epoch: 1 [30800/50000 (62%)]\tLoss: 1.376381\n",
      "Train Epoch: 1 [31200/50000 (62%)]\tLoss: 0.964430\n",
      "Train Epoch: 1 [31600/50000 (63%)]\tLoss: 1.351798\n",
      "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 2.641333\n",
      "Train Epoch: 1 [32400/50000 (65%)]\tLoss: 1.299518\n",
      "Train Epoch: 1 [32800/50000 (66%)]\tLoss: 1.044415\n",
      "Train Epoch: 1 [33200/50000 (66%)]\tLoss: 0.204864\n",
      "Train Epoch: 1 [33600/50000 (67%)]\tLoss: 1.605137\n",
      "Train Epoch: 1 [34000/50000 (68%)]\tLoss: 3.056367\n",
      "Train Epoch: 1 [34400/50000 (69%)]\tLoss: 0.986478\n",
      "Train Epoch: 1 [34800/50000 (70%)]\tLoss: 0.040665\n",
      "Train Epoch: 1 [35200/50000 (70%)]\tLoss: 1.314294\n",
      "Train Epoch: 1 [35600/50000 (71%)]\tLoss: 0.923594\n",
      "Train Epoch: 1 [36000/50000 (72%)]\tLoss: 1.475854\n",
      "Train Epoch: 1 [36400/50000 (73%)]\tLoss: 1.921725\n",
      "Train Epoch: 1 [36800/50000 (74%)]\tLoss: 0.981871\n",
      "Train Epoch: 1 [37200/50000 (74%)]\tLoss: 1.441518\n",
      "Train Epoch: 1 [37600/50000 (75%)]\tLoss: 0.509275\n",
      "Train Epoch: 1 [38000/50000 (76%)]\tLoss: 0.862494\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 1.285230\n",
      "Train Epoch: 1 [38800/50000 (78%)]\tLoss: 1.573528\n",
      "Train Epoch: 1 [39200/50000 (78%)]\tLoss: 1.334621\n",
      "Train Epoch: 1 [39600/50000 (79%)]\tLoss: 1.705532\n",
      "Train Epoch: 1 [40000/50000 (80%)]\tLoss: 1.644783\n",
      "Train Epoch: 1 [40400/50000 (81%)]\tLoss: 2.411548\n",
      "Train Epoch: 1 [40800/50000 (82%)]\tLoss: 2.226286\n",
      "Train Epoch: 1 [41200/50000 (82%)]\tLoss: 1.433118\n",
      "Train Epoch: 1 [41600/50000 (83%)]\tLoss: 1.081208\n",
      "Train Epoch: 1 [42000/50000 (84%)]\tLoss: 1.957886\n",
      "Train Epoch: 1 [42400/50000 (85%)]\tLoss: 0.852026\n",
      "Train Epoch: 1 [42800/50000 (86%)]\tLoss: 2.552001\n",
      "Train Epoch: 1 [43200/50000 (86%)]\tLoss: 1.324707\n",
      "Train Epoch: 1 [43600/50000 (87%)]\tLoss: 1.279266\n",
      "Train Epoch: 1 [44000/50000 (88%)]\tLoss: 0.595704\n",
      "Train Epoch: 1 [44400/50000 (89%)]\tLoss: 0.639602\n",
      "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 0.930298\n",
      "Train Epoch: 1 [45200/50000 (90%)]\tLoss: 0.811203\n",
      "Train Epoch: 1 [45600/50000 (91%)]\tLoss: 2.932841\n",
      "Train Epoch: 1 [46000/50000 (92%)]\tLoss: 1.407010\n",
      "Train Epoch: 1 [46400/50000 (93%)]\tLoss: 1.421382\n",
      "Train Epoch: 1 [46800/50000 (94%)]\tLoss: 0.834516\n",
      "Train Epoch: 1 [47200/50000 (94%)]\tLoss: 1.838388\n",
      "Train Epoch: 1 [47600/50000 (95%)]\tLoss: 1.479380\n",
      "Train Epoch: 1 [48000/50000 (96%)]\tLoss: 1.503880\n",
      "Train Epoch: 1 [48400/50000 (97%)]\tLoss: 0.325029\n",
      "Train Epoch: 1 [48800/50000 (98%)]\tLoss: 0.625590\n",
      "Train Epoch: 1 [49200/50000 (98%)]\tLoss: 1.115695\n",
      "Train Epoch: 1 [49600/50000 (99%)]\tLoss: 1.577487\n",
      "\n",
      "Test set: Average loss: 0.2954, Accuracy: 5834/10000 (58%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 0.634153\n",
      "Train Epoch: 2 [400/50000 (1%)]\tLoss: 0.945549\n",
      "Train Epoch: 2 [800/50000 (2%)]\tLoss: 0.800038\n",
      "Train Epoch: 2 [1200/50000 (2%)]\tLoss: 0.908667\n",
      "Train Epoch: 2 [1600/50000 (3%)]\tLoss: 1.201141\n",
      "Train Epoch: 2 [2000/50000 (4%)]\tLoss: 1.140211\n",
      "Train Epoch: 2 [2400/50000 (5%)]\tLoss: 0.277012\n",
      "Train Epoch: 2 [2800/50000 (6%)]\tLoss: 1.319224\n",
      "Train Epoch: 2 [3200/50000 (6%)]\tLoss: 1.877651\n",
      "Train Epoch: 2 [3600/50000 (7%)]\tLoss: 0.632735\n",
      "Train Epoch: 2 [4000/50000 (8%)]\tLoss: 0.623078\n",
      "Train Epoch: 2 [4400/50000 (9%)]\tLoss: 0.719717\n",
      "Train Epoch: 2 [4800/50000 (10%)]\tLoss: 0.829091\n",
      "Train Epoch: 2 [5200/50000 (10%)]\tLoss: 1.159571\n",
      "Train Epoch: 2 [5600/50000 (11%)]\tLoss: 2.458118\n",
      "Train Epoch: 2 [6000/50000 (12%)]\tLoss: 1.227087\n",
      "Train Epoch: 2 [6400/50000 (13%)]\tLoss: 2.587718\n",
      "Train Epoch: 2 [6800/50000 (14%)]\tLoss: 1.397144\n",
      "Train Epoch: 2 [7200/50000 (14%)]\tLoss: 0.377206\n",
      "Train Epoch: 2 [7600/50000 (15%)]\tLoss: 0.185845\n",
      "Train Epoch: 2 [8000/50000 (16%)]\tLoss: 1.913597\n",
      "Train Epoch: 2 [8400/50000 (17%)]\tLoss: 1.732151\n",
      "Train Epoch: 2 [8800/50000 (18%)]\tLoss: 0.782439\n",
      "Train Epoch: 2 [9200/50000 (18%)]\tLoss: 1.505063\n",
      "Train Epoch: 2 [9600/50000 (19%)]\tLoss: 1.899166\n",
      "Train Epoch: 2 [10000/50000 (20%)]\tLoss: 0.508809\n",
      "Train Epoch: 2 [10400/50000 (21%)]\tLoss: 0.831857\n",
      "Train Epoch: 2 [10800/50000 (22%)]\tLoss: 0.415789\n",
      "Train Epoch: 2 [11200/50000 (22%)]\tLoss: 0.818894\n",
      "Train Epoch: 2 [11600/50000 (23%)]\tLoss: 1.230005\n",
      "Train Epoch: 2 [12000/50000 (24%)]\tLoss: 0.782473\n",
      "Train Epoch: 2 [12400/50000 (25%)]\tLoss: 0.151782\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 0.888765\n",
      "Train Epoch: 2 [13200/50000 (26%)]\tLoss: 0.441594\n",
      "Train Epoch: 2 [13600/50000 (27%)]\tLoss: 0.843513\n",
      "Train Epoch: 2 [14000/50000 (28%)]\tLoss: 1.273950\n",
      "Train Epoch: 2 [14400/50000 (29%)]\tLoss: 0.679932\n",
      "Train Epoch: 2 [14800/50000 (30%)]\tLoss: 0.288027\n",
      "Train Epoch: 2 [15200/50000 (30%)]\tLoss: 0.873739\n",
      "Train Epoch: 2 [15600/50000 (31%)]\tLoss: 0.930421\n",
      "Train Epoch: 2 [16000/50000 (32%)]\tLoss: 1.444440\n",
      "Train Epoch: 2 [16400/50000 (33%)]\tLoss: 0.692921\n",
      "Train Epoch: 2 [16800/50000 (34%)]\tLoss: 1.197605\n",
      "Train Epoch: 2 [17200/50000 (34%)]\tLoss: 0.614631\n",
      "Train Epoch: 2 [17600/50000 (35%)]\tLoss: 0.174191\n",
      "Train Epoch: 2 [18000/50000 (36%)]\tLoss: 2.390523\n",
      "Train Epoch: 2 [18400/50000 (37%)]\tLoss: 1.072592\n",
      "Train Epoch: 2 [18800/50000 (38%)]\tLoss: 1.096217\n",
      "Train Epoch: 2 [19200/50000 (38%)]\tLoss: 1.922917\n",
      "Train Epoch: 2 [19600/50000 (39%)]\tLoss: 2.163667\n",
      "Train Epoch: 2 [20000/50000 (40%)]\tLoss: 0.911534\n",
      "Train Epoch: 2 [20400/50000 (41%)]\tLoss: 0.351886\n",
      "Train Epoch: 2 [20800/50000 (42%)]\tLoss: 1.063904\n",
      "Train Epoch: 2 [21200/50000 (42%)]\tLoss: 0.585964\n",
      "Train Epoch: 2 [21600/50000 (43%)]\tLoss: 0.694762\n",
      "Train Epoch: 2 [22000/50000 (44%)]\tLoss: 1.670739\n",
      "Train Epoch: 2 [22400/50000 (45%)]\tLoss: 0.344832\n",
      "Train Epoch: 2 [22800/50000 (46%)]\tLoss: 1.191152\n",
      "Train Epoch: 2 [23200/50000 (46%)]\tLoss: 0.636329\n",
      "Train Epoch: 2 [23600/50000 (47%)]\tLoss: 1.755931\n",
      "Train Epoch: 2 [24000/50000 (48%)]\tLoss: 0.966040\n",
      "Train Epoch: 2 [24400/50000 (49%)]\tLoss: 1.736761\n",
      "Train Epoch: 2 [24800/50000 (50%)]\tLoss: 1.337900\n",
      "Train Epoch: 2 [25200/50000 (50%)]\tLoss: 1.067493\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 1.626406\n",
      "Train Epoch: 2 [26000/50000 (52%)]\tLoss: 0.586319\n",
      "Train Epoch: 2 [26400/50000 (53%)]\tLoss: 0.630930\n",
      "Train Epoch: 2 [26800/50000 (54%)]\tLoss: 1.162325\n",
      "Train Epoch: 2 [27200/50000 (54%)]\tLoss: 1.449885\n",
      "Train Epoch: 2 [27600/50000 (55%)]\tLoss: 0.733472\n",
      "Train Epoch: 2 [28000/50000 (56%)]\tLoss: 0.121622\n",
      "Train Epoch: 2 [28400/50000 (57%)]\tLoss: 0.841201\n",
      "Train Epoch: 2 [28800/50000 (58%)]\tLoss: 0.819236\n",
      "Train Epoch: 2 [29200/50000 (58%)]\tLoss: 0.352898\n",
      "Train Epoch: 2 [29600/50000 (59%)]\tLoss: 0.427884\n",
      "Train Epoch: 2 [30000/50000 (60%)]\tLoss: 0.262696\n",
      "Train Epoch: 2 [30400/50000 (61%)]\tLoss: 0.724263\n",
      "Train Epoch: 2 [30800/50000 (62%)]\tLoss: 1.089515\n",
      "Train Epoch: 2 [31200/50000 (62%)]\tLoss: 1.050857\n",
      "Train Epoch: 2 [31600/50000 (63%)]\tLoss: 0.254961\n",
      "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 0.848162\n",
      "Train Epoch: 2 [32400/50000 (65%)]\tLoss: 1.547316\n",
      "Train Epoch: 2 [32800/50000 (66%)]\tLoss: 0.667712\n",
      "Train Epoch: 2 [33200/50000 (66%)]\tLoss: 1.335221\n",
      "Train Epoch: 2 [33600/50000 (67%)]\tLoss: 0.191529\n",
      "Train Epoch: 2 [34000/50000 (68%)]\tLoss: 0.083188\n",
      "Train Epoch: 2 [34400/50000 (69%)]\tLoss: 0.975178\n",
      "Train Epoch: 2 [34800/50000 (70%)]\tLoss: 1.281095\n",
      "Train Epoch: 2 [35200/50000 (70%)]\tLoss: 0.520163\n",
      "Train Epoch: 2 [35600/50000 (71%)]\tLoss: 1.868284\n",
      "Train Epoch: 2 [36000/50000 (72%)]\tLoss: 0.566540\n",
      "Train Epoch: 2 [36400/50000 (73%)]\tLoss: 1.368244\n",
      "Train Epoch: 2 [36800/50000 (74%)]\tLoss: 1.590727\n",
      "Train Epoch: 2 [37200/50000 (74%)]\tLoss: 1.021349\n",
      "Train Epoch: 2 [37600/50000 (75%)]\tLoss: 1.394359\n",
      "Train Epoch: 2 [38000/50000 (76%)]\tLoss: 0.698011\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 1.815057\n",
      "Train Epoch: 2 [38800/50000 (78%)]\tLoss: 0.395743\n",
      "Train Epoch: 2 [39200/50000 (78%)]\tLoss: 1.706111\n",
      "Train Epoch: 2 [39600/50000 (79%)]\tLoss: 2.355126\n",
      "Train Epoch: 2 [40000/50000 (80%)]\tLoss: 0.854905\n",
      "Train Epoch: 2 [40400/50000 (81%)]\tLoss: 1.649081\n",
      "Train Epoch: 2 [40800/50000 (82%)]\tLoss: 0.469931\n",
      "Train Epoch: 2 [41200/50000 (82%)]\tLoss: 0.332404\n",
      "Train Epoch: 2 [41600/50000 (83%)]\tLoss: 1.411354\n",
      "Train Epoch: 2 [42000/50000 (84%)]\tLoss: 1.071921\n",
      "Train Epoch: 2 [42400/50000 (85%)]\tLoss: 0.926545\n",
      "Train Epoch: 2 [42800/50000 (86%)]\tLoss: 1.184023\n",
      "Train Epoch: 2 [43200/50000 (86%)]\tLoss: 1.936676\n",
      "Train Epoch: 2 [43600/50000 (87%)]\tLoss: 0.762223\n",
      "Train Epoch: 2 [44000/50000 (88%)]\tLoss: 0.696601\n",
      "Train Epoch: 2 [44400/50000 (89%)]\tLoss: 1.408660\n",
      "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 0.568191\n",
      "Train Epoch: 2 [45200/50000 (90%)]\tLoss: 1.072906\n",
      "Train Epoch: 2 [45600/50000 (91%)]\tLoss: 1.684189\n",
      "Train Epoch: 2 [46000/50000 (92%)]\tLoss: 1.384329\n",
      "Train Epoch: 2 [46400/50000 (93%)]\tLoss: 1.288565\n",
      "Train Epoch: 2 [46800/50000 (94%)]\tLoss: 1.748843\n",
      "Train Epoch: 2 [47200/50000 (94%)]\tLoss: 1.074127\n",
      "Train Epoch: 2 [47600/50000 (95%)]\tLoss: 2.423163\n",
      "Train Epoch: 2 [48000/50000 (96%)]\tLoss: 1.989884\n",
      "Train Epoch: 2 [48400/50000 (97%)]\tLoss: 0.857368\n",
      "Train Epoch: 2 [48800/50000 (98%)]\tLoss: 1.226827\n",
      "Train Epoch: 2 [49200/50000 (98%)]\tLoss: 2.705805\n",
      "Train Epoch: 2 [49600/50000 (99%)]\tLoss: 0.912897\n",
      "\n",
      "Test set: Average loss: 0.2846, Accuracy: 6071/10000 (61%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1.413677\n",
      "Train Epoch: 3 [400/50000 (1%)]\tLoss: 0.490937\n",
      "Train Epoch: 3 [800/50000 (2%)]\tLoss: 0.878622\n",
      "Train Epoch: 3 [1200/50000 (2%)]\tLoss: 0.957929\n",
      "Train Epoch: 3 [1600/50000 (3%)]\tLoss: 0.482203\n",
      "Train Epoch: 3 [2000/50000 (4%)]\tLoss: 0.116199\n",
      "Train Epoch: 3 [2400/50000 (5%)]\tLoss: 0.871605\n",
      "Train Epoch: 3 [2800/50000 (6%)]\tLoss: 0.226421\n",
      "Train Epoch: 3 [3200/50000 (6%)]\tLoss: 0.560857\n",
      "Train Epoch: 3 [3600/50000 (7%)]\tLoss: 0.702931\n",
      "Train Epoch: 3 [4000/50000 (8%)]\tLoss: 1.181310\n",
      "Train Epoch: 3 [4400/50000 (9%)]\tLoss: 1.190559\n",
      "Train Epoch: 3 [4800/50000 (10%)]\tLoss: 0.526974\n",
      "Train Epoch: 3 [5200/50000 (10%)]\tLoss: 0.196021\n",
      "Train Epoch: 3 [5600/50000 (11%)]\tLoss: 0.951014\n",
      "Train Epoch: 3 [6000/50000 (12%)]\tLoss: 1.469029\n",
      "Train Epoch: 3 [6400/50000 (13%)]\tLoss: 0.140588\n",
      "Train Epoch: 3 [6800/50000 (14%)]\tLoss: 1.589628\n",
      "Train Epoch: 3 [7200/50000 (14%)]\tLoss: 0.384879\n",
      "Train Epoch: 3 [7600/50000 (15%)]\tLoss: 0.315868\n",
      "Train Epoch: 3 [8000/50000 (16%)]\tLoss: 0.990932\n",
      "Train Epoch: 3 [8400/50000 (17%)]\tLoss: 0.688200\n",
      "Train Epoch: 3 [8800/50000 (18%)]\tLoss: 0.999332\n",
      "Train Epoch: 3 [9200/50000 (18%)]\tLoss: 2.675990\n",
      "Train Epoch: 3 [9600/50000 (19%)]\tLoss: 1.604418\n",
      "Train Epoch: 3 [10000/50000 (20%)]\tLoss: 1.981497\n",
      "Train Epoch: 3 [10400/50000 (21%)]\tLoss: 1.491949\n",
      "Train Epoch: 3 [10800/50000 (22%)]\tLoss: 0.791473\n",
      "Train Epoch: 3 [11200/50000 (22%)]\tLoss: 0.612021\n",
      "Train Epoch: 3 [11600/50000 (23%)]\tLoss: 0.964102\n",
      "Train Epoch: 3 [12000/50000 (24%)]\tLoss: 1.320456\n",
      "Train Epoch: 3 [12400/50000 (25%)]\tLoss: 1.343645\n",
      "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 1.487952\n",
      "Train Epoch: 3 [13200/50000 (26%)]\tLoss: 1.207353\n",
      "Train Epoch: 3 [13600/50000 (27%)]\tLoss: 2.317933\n",
      "Train Epoch: 3 [14000/50000 (28%)]\tLoss: 1.655758\n",
      "Train Epoch: 3 [14400/50000 (29%)]\tLoss: 1.169261\n",
      "Train Epoch: 3 [14800/50000 (30%)]\tLoss: 1.410713\n",
      "Train Epoch: 3 [15200/50000 (30%)]\tLoss: 1.364602\n",
      "Train Epoch: 3 [15600/50000 (31%)]\tLoss: 0.997239\n",
      "Train Epoch: 3 [16000/50000 (32%)]\tLoss: 0.583601\n",
      "Train Epoch: 3 [16400/50000 (33%)]\tLoss: 2.160720\n",
      "Train Epoch: 3 [16800/50000 (34%)]\tLoss: 0.071512\n",
      "Train Epoch: 3 [17200/50000 (34%)]\tLoss: 0.344843\n",
      "Train Epoch: 3 [17600/50000 (35%)]\tLoss: 1.271839\n",
      "Train Epoch: 3 [18000/50000 (36%)]\tLoss: 0.433407\n",
      "Train Epoch: 3 [18400/50000 (37%)]\tLoss: 1.474226\n",
      "Train Epoch: 3 [18800/50000 (38%)]\tLoss: 0.479391\n",
      "Train Epoch: 3 [19200/50000 (38%)]\tLoss: 0.791935\n",
      "Train Epoch: 3 [19600/50000 (39%)]\tLoss: 0.684103\n",
      "Train Epoch: 3 [20000/50000 (40%)]\tLoss: 1.569633\n",
      "Train Epoch: 3 [20400/50000 (41%)]\tLoss: 0.591642\n",
      "Train Epoch: 3 [20800/50000 (42%)]\tLoss: 2.030723\n",
      "Train Epoch: 3 [21200/50000 (42%)]\tLoss: 1.064722\n",
      "Train Epoch: 3 [21600/50000 (43%)]\tLoss: 0.519080\n",
      "Train Epoch: 3 [22000/50000 (44%)]\tLoss: 0.292856\n",
      "Train Epoch: 3 [22400/50000 (45%)]\tLoss: 0.219159\n",
      "Train Epoch: 3 [22800/50000 (46%)]\tLoss: 0.767122\n",
      "Train Epoch: 3 [23200/50000 (46%)]\tLoss: 0.457490\n",
      "Train Epoch: 3 [23600/50000 (47%)]\tLoss: 1.083097\n",
      "Train Epoch: 3 [24000/50000 (48%)]\tLoss: 0.540656\n",
      "Train Epoch: 3 [24400/50000 (49%)]\tLoss: 1.078146\n",
      "Train Epoch: 3 [24800/50000 (50%)]\tLoss: 0.963154\n",
      "Train Epoch: 3 [25200/50000 (50%)]\tLoss: 0.636283\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 0.720682\n",
      "Train Epoch: 3 [26000/50000 (52%)]\tLoss: 1.441763\n",
      "Train Epoch: 3 [26400/50000 (53%)]\tLoss: 1.604844\n",
      "Train Epoch: 3 [26800/50000 (54%)]\tLoss: 0.721116\n",
      "Train Epoch: 3 [27200/50000 (54%)]\tLoss: 1.441919\n",
      "Train Epoch: 3 [27600/50000 (55%)]\tLoss: 0.335788\n",
      "Train Epoch: 3 [28000/50000 (56%)]\tLoss: 0.927745\n",
      "Train Epoch: 3 [28400/50000 (57%)]\tLoss: 0.275346\n",
      "Train Epoch: 3 [28800/50000 (58%)]\tLoss: 1.867879\n",
      "Train Epoch: 3 [29200/50000 (58%)]\tLoss: 0.102808\n",
      "Train Epoch: 3 [29600/50000 (59%)]\tLoss: 1.638356\n",
      "Train Epoch: 3 [30000/50000 (60%)]\tLoss: 0.982839\n",
      "Train Epoch: 3 [30400/50000 (61%)]\tLoss: 2.284993\n",
      "Train Epoch: 3 [30800/50000 (62%)]\tLoss: 1.156237\n",
      "Train Epoch: 3 [31200/50000 (62%)]\tLoss: 0.780809\n",
      "Train Epoch: 3 [31600/50000 (63%)]\tLoss: 1.084927\n",
      "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 0.346111\n",
      "Train Epoch: 3 [32400/50000 (65%)]\tLoss: 0.269109\n",
      "Train Epoch: 3 [32800/50000 (66%)]\tLoss: 0.064937\n",
      "Train Epoch: 3 [33200/50000 (66%)]\tLoss: 0.414554\n",
      "Train Epoch: 3 [33600/50000 (67%)]\tLoss: 1.267140\n",
      "Train Epoch: 3 [34000/50000 (68%)]\tLoss: 1.091123\n",
      "Train Epoch: 3 [34400/50000 (69%)]\tLoss: 0.717234\n",
      "Train Epoch: 3 [34800/50000 (70%)]\tLoss: 0.590991\n",
      "Train Epoch: 3 [35200/50000 (70%)]\tLoss: 0.847174\n",
      "Train Epoch: 3 [35600/50000 (71%)]\tLoss: 0.832462\n",
      "Train Epoch: 3 [36000/50000 (72%)]\tLoss: 0.826105\n",
      "Train Epoch: 3 [36400/50000 (73%)]\tLoss: 0.937335\n",
      "Train Epoch: 3 [36800/50000 (74%)]\tLoss: 1.964878\n",
      "Train Epoch: 3 [37200/50000 (74%)]\tLoss: 1.171074\n",
      "Train Epoch: 3 [37600/50000 (75%)]\tLoss: 0.926798\n",
      "Train Epoch: 3 [38000/50000 (76%)]\tLoss: 2.661170\n",
      "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 2.040574\n",
      "Train Epoch: 3 [38800/50000 (78%)]\tLoss: 0.473887\n",
      "Train Epoch: 3 [39200/50000 (78%)]\tLoss: 1.304718\n",
      "Train Epoch: 3 [39600/50000 (79%)]\tLoss: 0.697361\n",
      "Train Epoch: 3 [40000/50000 (80%)]\tLoss: 0.673357\n",
      "Train Epoch: 3 [40400/50000 (81%)]\tLoss: 0.246002\n",
      "Train Epoch: 3 [40800/50000 (82%)]\tLoss: 1.392980\n",
      "Train Epoch: 3 [41200/50000 (82%)]\tLoss: 0.735528\n",
      "Train Epoch: 3 [41600/50000 (83%)]\tLoss: 0.554360\n",
      "Train Epoch: 3 [42000/50000 (84%)]\tLoss: 0.923594\n",
      "Train Epoch: 3 [42400/50000 (85%)]\tLoss: 0.196975\n",
      "Train Epoch: 3 [42800/50000 (86%)]\tLoss: 1.223106\n",
      "Train Epoch: 3 [43200/50000 (86%)]\tLoss: 1.009216\n",
      "Train Epoch: 3 [43600/50000 (87%)]\tLoss: 1.604119\n",
      "Train Epoch: 3 [44000/50000 (88%)]\tLoss: 2.443332\n",
      "Train Epoch: 3 [44400/50000 (89%)]\tLoss: 3.273856\n",
      "Train Epoch: 3 [44800/50000 (90%)]\tLoss: 1.926926\n",
      "Train Epoch: 3 [45200/50000 (90%)]\tLoss: 0.546540\n",
      "Train Epoch: 3 [45600/50000 (91%)]\tLoss: 1.457373\n",
      "Train Epoch: 3 [46000/50000 (92%)]\tLoss: 1.139868\n",
      "Train Epoch: 3 [46400/50000 (93%)]\tLoss: 0.889521\n",
      "Train Epoch: 3 [46800/50000 (94%)]\tLoss: 0.480839\n",
      "Train Epoch: 3 [47200/50000 (94%)]\tLoss: 0.440429\n",
      "Train Epoch: 3 [47600/50000 (95%)]\tLoss: 1.137162\n",
      "Train Epoch: 3 [48000/50000 (96%)]\tLoss: 0.506748\n",
      "Train Epoch: 3 [48400/50000 (97%)]\tLoss: 0.944784\n",
      "Train Epoch: 3 [48800/50000 (98%)]\tLoss: 1.569272\n",
      "Train Epoch: 3 [49200/50000 (98%)]\tLoss: 0.461878\n",
      "Train Epoch: 3 [49600/50000 (99%)]\tLoss: 1.445742\n",
      "\n",
      "Test set: Average loss: 0.2743, Accuracy: 6265/10000 (63%)\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 0.994750\n",
      "Train Epoch: 4 [400/50000 (1%)]\tLoss: 0.456346\n",
      "Train Epoch: 4 [800/50000 (2%)]\tLoss: 0.506287\n",
      "Train Epoch: 4 [1200/50000 (2%)]\tLoss: 0.415759\n",
      "Train Epoch: 4 [1600/50000 (3%)]\tLoss: 0.300457\n",
      "Train Epoch: 4 [2000/50000 (4%)]\tLoss: 0.695279\n",
      "Train Epoch: 4 [2400/50000 (5%)]\tLoss: 1.047024\n",
      "Train Epoch: 4 [2800/50000 (6%)]\tLoss: 1.337418\n",
      "Train Epoch: 4 [3200/50000 (6%)]\tLoss: 0.364282\n",
      "Train Epoch: 4 [3600/50000 (7%)]\tLoss: 0.833930\n",
      "Train Epoch: 4 [4000/50000 (8%)]\tLoss: 0.708332\n",
      "Train Epoch: 4 [4400/50000 (9%)]\tLoss: 1.203020\n",
      "Train Epoch: 4 [4800/50000 (10%)]\tLoss: 1.198079\n",
      "Train Epoch: 4 [5200/50000 (10%)]\tLoss: 1.538640\n",
      "Train Epoch: 4 [5600/50000 (11%)]\tLoss: 0.047279\n",
      "Train Epoch: 4 [6000/50000 (12%)]\tLoss: 0.930735\n",
      "Train Epoch: 4 [6400/50000 (13%)]\tLoss: 0.350772\n",
      "Train Epoch: 4 [6800/50000 (14%)]\tLoss: 0.169738\n",
      "Train Epoch: 4 [7200/50000 (14%)]\tLoss: 1.858610\n",
      "Train Epoch: 4 [7600/50000 (15%)]\tLoss: 0.635736\n",
      "Train Epoch: 4 [8000/50000 (16%)]\tLoss: 1.441677\n",
      "Train Epoch: 4 [8400/50000 (17%)]\tLoss: 0.589265\n",
      "Train Epoch: 4 [8800/50000 (18%)]\tLoss: 1.210045\n",
      "Train Epoch: 4 [9200/50000 (18%)]\tLoss: 0.948659\n",
      "Train Epoch: 4 [9600/50000 (19%)]\tLoss: 1.133151\n",
      "Train Epoch: 4 [10000/50000 (20%)]\tLoss: 0.367595\n",
      "Train Epoch: 4 [10400/50000 (21%)]\tLoss: 1.446501\n",
      "Train Epoch: 4 [10800/50000 (22%)]\tLoss: 1.411542\n",
      "Train Epoch: 4 [11200/50000 (22%)]\tLoss: 0.687866\n",
      "Train Epoch: 4 [11600/50000 (23%)]\tLoss: 2.722994\n",
      "Train Epoch: 4 [12000/50000 (24%)]\tLoss: 1.156703\n",
      "Train Epoch: 4 [12400/50000 (25%)]\tLoss: 1.294302\n",
      "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 1.084638\n",
      "Train Epoch: 4 [13200/50000 (26%)]\tLoss: 0.363858\n",
      "Train Epoch: 4 [13600/50000 (27%)]\tLoss: 1.739832\n",
      "Train Epoch: 4 [14000/50000 (28%)]\tLoss: 0.602490\n",
      "Train Epoch: 4 [14400/50000 (29%)]\tLoss: 0.981018\n",
      "Train Epoch: 4 [14800/50000 (30%)]\tLoss: 0.329844\n",
      "Train Epoch: 4 [15200/50000 (30%)]\tLoss: 0.639091\n",
      "Train Epoch: 4 [15600/50000 (31%)]\tLoss: 1.635760\n",
      "Train Epoch: 4 [16000/50000 (32%)]\tLoss: 2.193053\n",
      "Train Epoch: 4 [16400/50000 (33%)]\tLoss: 2.541202\n",
      "Train Epoch: 4 [16800/50000 (34%)]\tLoss: 1.246898\n",
      "Train Epoch: 4 [17200/50000 (34%)]\tLoss: 0.784056\n",
      "Train Epoch: 4 [17600/50000 (35%)]\tLoss: 1.299879\n",
      "Train Epoch: 4 [18000/50000 (36%)]\tLoss: 1.064459\n",
      "Train Epoch: 4 [18400/50000 (37%)]\tLoss: 0.121009\n",
      "Train Epoch: 4 [18800/50000 (38%)]\tLoss: 0.436769\n",
      "Train Epoch: 4 [19200/50000 (38%)]\tLoss: 1.754198\n",
      "Train Epoch: 4 [19600/50000 (39%)]\tLoss: 0.592324\n",
      "Train Epoch: 4 [20000/50000 (40%)]\tLoss: 0.628531\n",
      "Train Epoch: 4 [20400/50000 (41%)]\tLoss: 1.197099\n",
      "Train Epoch: 4 [20800/50000 (42%)]\tLoss: 1.657199\n",
      "Train Epoch: 4 [21200/50000 (42%)]\tLoss: 0.602012\n",
      "Train Epoch: 4 [21600/50000 (43%)]\tLoss: 0.533109\n",
      "Train Epoch: 4 [22000/50000 (44%)]\tLoss: 0.190400\n",
      "Train Epoch: 4 [22400/50000 (45%)]\tLoss: 0.441265\n",
      "Train Epoch: 4 [22800/50000 (46%)]\tLoss: 2.659477\n",
      "Train Epoch: 4 [23200/50000 (46%)]\tLoss: 0.662400\n",
      "Train Epoch: 4 [23600/50000 (47%)]\tLoss: 1.744549\n",
      "Train Epoch: 4 [24000/50000 (48%)]\tLoss: 0.491492\n",
      "Train Epoch: 4 [24400/50000 (49%)]\tLoss: 0.271534\n",
      "Train Epoch: 4 [24800/50000 (50%)]\tLoss: 2.328280\n",
      "Train Epoch: 4 [25200/50000 (50%)]\tLoss: 0.191917\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 1.043130\n",
      "Train Epoch: 4 [26000/50000 (52%)]\tLoss: 0.933070\n",
      "Train Epoch: 4 [26400/50000 (53%)]\tLoss: 0.742229\n",
      "Train Epoch: 4 [26800/50000 (54%)]\tLoss: 0.712156\n",
      "Train Epoch: 4 [27200/50000 (54%)]\tLoss: 0.770441\n",
      "Train Epoch: 4 [27600/50000 (55%)]\tLoss: 1.159435\n",
      "Train Epoch: 4 [28000/50000 (56%)]\tLoss: 1.645878\n",
      "Train Epoch: 4 [28400/50000 (57%)]\tLoss: 1.586774\n",
      "Train Epoch: 4 [28800/50000 (58%)]\tLoss: 1.544283\n",
      "Train Epoch: 4 [29200/50000 (58%)]\tLoss: 0.776875\n",
      "Train Epoch: 4 [29600/50000 (59%)]\tLoss: 0.780892\n",
      "Train Epoch: 4 [30000/50000 (60%)]\tLoss: 0.196069\n",
      "Train Epoch: 4 [30400/50000 (61%)]\tLoss: 0.334284\n",
      "Train Epoch: 4 [30800/50000 (62%)]\tLoss: 1.149436\n",
      "Train Epoch: 4 [31200/50000 (62%)]\tLoss: 0.173953\n",
      "Train Epoch: 4 [31600/50000 (63%)]\tLoss: 1.496562\n",
      "Train Epoch: 4 [32000/50000 (64%)]\tLoss: 0.212552\n",
      "Train Epoch: 4 [32400/50000 (65%)]\tLoss: 0.689277\n",
      "Train Epoch: 4 [32800/50000 (66%)]\tLoss: 0.705745\n",
      "Train Epoch: 4 [33200/50000 (66%)]\tLoss: 0.263021\n",
      "Train Epoch: 4 [33600/50000 (67%)]\tLoss: 0.390930\n",
      "Train Epoch: 4 [34000/50000 (68%)]\tLoss: 0.260066\n",
      "Train Epoch: 4 [34400/50000 (69%)]\tLoss: 0.251219\n",
      "Train Epoch: 4 [34800/50000 (70%)]\tLoss: 1.618430\n",
      "Train Epoch: 4 [35200/50000 (70%)]\tLoss: 1.040685\n",
      "Train Epoch: 4 [35600/50000 (71%)]\tLoss: 0.123763\n",
      "Train Epoch: 4 [36000/50000 (72%)]\tLoss: 0.150587\n",
      "Train Epoch: 4 [36400/50000 (73%)]\tLoss: 0.164529\n",
      "Train Epoch: 4 [36800/50000 (74%)]\tLoss: 0.113595\n",
      "Train Epoch: 4 [37200/50000 (74%)]\tLoss: 0.710255\n",
      "Train Epoch: 4 [37600/50000 (75%)]\tLoss: 0.289746\n",
      "Train Epoch: 4 [38000/50000 (76%)]\tLoss: 0.451389\n",
      "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 0.424172\n",
      "Train Epoch: 4 [38800/50000 (78%)]\tLoss: 0.733209\n",
      "Train Epoch: 4 [39200/50000 (78%)]\tLoss: 0.589752\n",
      "Train Epoch: 4 [39600/50000 (79%)]\tLoss: 2.139762\n",
      "Train Epoch: 4 [40000/50000 (80%)]\tLoss: 0.502152\n",
      "Train Epoch: 4 [40400/50000 (81%)]\tLoss: 1.039221\n",
      "Train Epoch: 4 [40800/50000 (82%)]\tLoss: 0.591956\n",
      "Train Epoch: 4 [41200/50000 (82%)]\tLoss: 0.345935\n",
      "Train Epoch: 4 [41600/50000 (83%)]\tLoss: 0.609024\n",
      "Train Epoch: 4 [42000/50000 (84%)]\tLoss: 1.407725\n",
      "Train Epoch: 4 [42400/50000 (85%)]\tLoss: 1.627416\n",
      "Train Epoch: 4 [42800/50000 (86%)]\tLoss: 0.986836\n",
      "Train Epoch: 4 [43200/50000 (86%)]\tLoss: 0.634283\n",
      "Train Epoch: 4 [43600/50000 (87%)]\tLoss: 0.902218\n",
      "Train Epoch: 4 [44000/50000 (88%)]\tLoss: 1.079890\n",
      "Train Epoch: 4 [44400/50000 (89%)]\tLoss: 0.322952\n",
      "Train Epoch: 4 [44800/50000 (90%)]\tLoss: 1.409312\n",
      "Train Epoch: 4 [45200/50000 (90%)]\tLoss: 0.292583\n",
      "Train Epoch: 4 [45600/50000 (91%)]\tLoss: 1.117545\n",
      "Train Epoch: 4 [46000/50000 (92%)]\tLoss: 0.261786\n",
      "Train Epoch: 4 [46400/50000 (93%)]\tLoss: 0.252090\n",
      "Train Epoch: 4 [46800/50000 (94%)]\tLoss: 0.492054\n",
      "Train Epoch: 4 [47200/50000 (94%)]\tLoss: 0.707087\n",
      "Train Epoch: 4 [47600/50000 (95%)]\tLoss: 2.632912\n",
      "Train Epoch: 4 [48000/50000 (96%)]\tLoss: 0.597604\n",
      "Train Epoch: 4 [48400/50000 (97%)]\tLoss: 0.672808\n",
      "Train Epoch: 4 [48800/50000 (98%)]\tLoss: 0.667826\n",
      "Train Epoch: 4 [49200/50000 (98%)]\tLoss: 1.225879\n",
      "Train Epoch: 4 [49600/50000 (99%)]\tLoss: 0.744238\n",
      "\n",
      "Test set: Average loss: 0.2702, Accuracy: 6373/10000 (64%)\n",
      "\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 0.860847\n",
      "Train Epoch: 5 [400/50000 (1%)]\tLoss: 0.811147\n",
      "Train Epoch: 5 [800/50000 (2%)]\tLoss: 0.235327\n",
      "Train Epoch: 5 [1200/50000 (2%)]\tLoss: 1.016662\n",
      "Train Epoch: 5 [1600/50000 (3%)]\tLoss: 0.243457\n",
      "Train Epoch: 5 [2000/50000 (4%)]\tLoss: 0.419495\n",
      "Train Epoch: 5 [2400/50000 (5%)]\tLoss: 0.631513\n",
      "Train Epoch: 5 [2800/50000 (6%)]\tLoss: 0.414048\n",
      "Train Epoch: 5 [3200/50000 (6%)]\tLoss: 1.778351\n",
      "Train Epoch: 5 [3600/50000 (7%)]\tLoss: 1.301369\n",
      "Train Epoch: 5 [4000/50000 (8%)]\tLoss: 0.641223\n",
      "Train Epoch: 5 [4400/50000 (9%)]\tLoss: 0.519251\n",
      "Train Epoch: 5 [4800/50000 (10%)]\tLoss: 1.327656\n",
      "Train Epoch: 5 [5200/50000 (10%)]\tLoss: 0.167353\n",
      "Train Epoch: 5 [5600/50000 (11%)]\tLoss: 0.893898\n",
      "Train Epoch: 5 [6000/50000 (12%)]\tLoss: 0.441380\n",
      "Train Epoch: 5 [6400/50000 (13%)]\tLoss: 1.072881\n",
      "Train Epoch: 5 [6800/50000 (14%)]\tLoss: 0.388089\n",
      "Train Epoch: 5 [7200/50000 (14%)]\tLoss: 0.703600\n",
      "Train Epoch: 5 [7600/50000 (15%)]\tLoss: 0.102105\n",
      "Train Epoch: 5 [8000/50000 (16%)]\tLoss: 0.665188\n",
      "Train Epoch: 5 [8400/50000 (17%)]\tLoss: 0.692778\n",
      "Train Epoch: 5 [8800/50000 (18%)]\tLoss: 1.807816\n",
      "Train Epoch: 5 [9200/50000 (18%)]\tLoss: 0.476913\n",
      "Train Epoch: 5 [9600/50000 (19%)]\tLoss: 0.859166\n",
      "Train Epoch: 5 [10000/50000 (20%)]\tLoss: 0.817602\n",
      "Train Epoch: 5 [10400/50000 (21%)]\tLoss: 1.176450\n",
      "Train Epoch: 5 [10800/50000 (22%)]\tLoss: 1.793965\n",
      "Train Epoch: 5 [11200/50000 (22%)]\tLoss: 0.365233\n",
      "Train Epoch: 5 [11600/50000 (23%)]\tLoss: 0.932422\n",
      "Train Epoch: 5 [12000/50000 (24%)]\tLoss: 0.339695\n",
      "Train Epoch: 5 [12400/50000 (25%)]\tLoss: 1.238096\n",
      "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 1.294010\n",
      "Train Epoch: 5 [13200/50000 (26%)]\tLoss: 1.574224\n",
      "Train Epoch: 5 [13600/50000 (27%)]\tLoss: 2.718481\n",
      "Train Epoch: 5 [14000/50000 (28%)]\tLoss: 1.031281\n",
      "Train Epoch: 5 [14400/50000 (29%)]\tLoss: 1.242952\n",
      "Train Epoch: 5 [14800/50000 (30%)]\tLoss: 1.021312\n",
      "Train Epoch: 5 [15200/50000 (30%)]\tLoss: 0.417613\n",
      "Train Epoch: 5 [15600/50000 (31%)]\tLoss: 0.714241\n",
      "Train Epoch: 5 [16000/50000 (32%)]\tLoss: 1.141946\n",
      "Train Epoch: 5 [16400/50000 (33%)]\tLoss: 1.398469\n",
      "Train Epoch: 5 [16800/50000 (34%)]\tLoss: 0.770583\n",
      "Train Epoch: 5 [17200/50000 (34%)]\tLoss: 0.927321\n",
      "Train Epoch: 5 [17600/50000 (35%)]\tLoss: 0.073829\n",
      "Train Epoch: 5 [18000/50000 (36%)]\tLoss: 0.590048\n",
      "Train Epoch: 5 [18400/50000 (37%)]\tLoss: 0.551838\n",
      "Train Epoch: 5 [18800/50000 (38%)]\tLoss: 0.345378\n",
      "Train Epoch: 5 [19200/50000 (38%)]\tLoss: 2.488051\n",
      "Train Epoch: 5 [19600/50000 (39%)]\tLoss: 1.236235\n",
      "Train Epoch: 5 [20000/50000 (40%)]\tLoss: 1.222026\n",
      "Train Epoch: 5 [20400/50000 (41%)]\tLoss: 2.332519\n",
      "Train Epoch: 5 [20800/50000 (42%)]\tLoss: 0.701798\n",
      "Train Epoch: 5 [21200/50000 (42%)]\tLoss: 0.542075\n",
      "Train Epoch: 5 [21600/50000 (43%)]\tLoss: 0.864996\n",
      "Train Epoch: 5 [22000/50000 (44%)]\tLoss: 2.020771\n",
      "Train Epoch: 5 [22400/50000 (45%)]\tLoss: 1.160695\n",
      "Train Epoch: 5 [22800/50000 (46%)]\tLoss: 0.695573\n",
      "Train Epoch: 5 [23200/50000 (46%)]\tLoss: 0.274620\n",
      "Train Epoch: 5 [23600/50000 (47%)]\tLoss: 0.835260\n",
      "Train Epoch: 5 [24000/50000 (48%)]\tLoss: 0.243763\n",
      "Train Epoch: 5 [24400/50000 (49%)]\tLoss: 1.132029\n",
      "Train Epoch: 5 [24800/50000 (50%)]\tLoss: 0.377035\n",
      "Train Epoch: 5 [25200/50000 (50%)]\tLoss: 0.450796\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 0.710919\n",
      "Train Epoch: 5 [26000/50000 (52%)]\tLoss: 0.249274\n",
      "Train Epoch: 5 [26400/50000 (53%)]\tLoss: 1.130886\n",
      "Train Epoch: 5 [26800/50000 (54%)]\tLoss: 0.687766\n",
      "Train Epoch: 5 [27200/50000 (54%)]\tLoss: 1.098918\n",
      "Train Epoch: 5 [27600/50000 (55%)]\tLoss: 0.216445\n",
      "Train Epoch: 5 [28000/50000 (56%)]\tLoss: 0.874991\n",
      "Train Epoch: 5 [28400/50000 (57%)]\tLoss: 0.913175\n",
      "Train Epoch: 5 [28800/50000 (58%)]\tLoss: 2.235407\n",
      "Train Epoch: 5 [29200/50000 (58%)]\tLoss: 0.660655\n",
      "Train Epoch: 5 [29600/50000 (59%)]\tLoss: 0.747527\n",
      "Train Epoch: 5 [30000/50000 (60%)]\tLoss: 1.762910\n",
      "Train Epoch: 5 [30400/50000 (61%)]\tLoss: 0.062751\n",
      "Train Epoch: 5 [30800/50000 (62%)]\tLoss: 1.716025\n",
      "Train Epoch: 5 [31200/50000 (62%)]\tLoss: 0.745598\n",
      "Train Epoch: 5 [31600/50000 (63%)]\tLoss: 0.912675\n",
      "Train Epoch: 5 [32000/50000 (64%)]\tLoss: 0.968680\n",
      "Train Epoch: 5 [32400/50000 (65%)]\tLoss: 0.861027\n",
      "Train Epoch: 5 [32800/50000 (66%)]\tLoss: 0.169281\n",
      "Train Epoch: 5 [33200/50000 (66%)]\tLoss: 0.930915\n",
      "Train Epoch: 5 [33600/50000 (67%)]\tLoss: 1.792486\n",
      "Train Epoch: 5 [34000/50000 (68%)]\tLoss: 1.246330\n",
      "Train Epoch: 5 [34400/50000 (69%)]\tLoss: 0.638628\n",
      "Train Epoch: 5 [34800/50000 (70%)]\tLoss: 0.092232\n",
      "Train Epoch: 5 [35200/50000 (70%)]\tLoss: 2.035733\n",
      "Train Epoch: 5 [35600/50000 (71%)]\tLoss: 0.889800\n",
      "Train Epoch: 5 [36000/50000 (72%)]\tLoss: 0.942623\n",
      "Train Epoch: 5 [36400/50000 (73%)]\tLoss: 0.952403\n",
      "Train Epoch: 5 [36800/50000 (74%)]\tLoss: 0.781019\n",
      "Train Epoch: 5 [37200/50000 (74%)]\tLoss: 0.711681\n",
      "Train Epoch: 5 [37600/50000 (75%)]\tLoss: 0.504607\n",
      "Train Epoch: 5 [38000/50000 (76%)]\tLoss: 0.064258\n",
      "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 1.015792\n",
      "Train Epoch: 5 [38800/50000 (78%)]\tLoss: 0.687012\n",
      "Train Epoch: 5 [39200/50000 (78%)]\tLoss: 0.545087\n",
      "Train Epoch: 5 [39600/50000 (79%)]\tLoss: 1.012640\n",
      "Train Epoch: 5 [40000/50000 (80%)]\tLoss: 0.714163\n",
      "Train Epoch: 5 [40400/50000 (81%)]\tLoss: 0.242924\n",
      "Train Epoch: 5 [40800/50000 (82%)]\tLoss: 1.468732\n",
      "Train Epoch: 5 [41200/50000 (82%)]\tLoss: 1.207551\n",
      "Train Epoch: 5 [41600/50000 (83%)]\tLoss: 1.250767\n",
      "Train Epoch: 5 [42000/50000 (84%)]\tLoss: 0.629116\n",
      "Train Epoch: 5 [42400/50000 (85%)]\tLoss: 1.149291\n",
      "Train Epoch: 5 [42800/50000 (86%)]\tLoss: 0.785499\n",
      "Train Epoch: 5 [43200/50000 (86%)]\tLoss: 0.830026\n",
      "Train Epoch: 5 [43600/50000 (87%)]\tLoss: 0.657507\n",
      "Train Epoch: 5 [44000/50000 (88%)]\tLoss: 1.227898\n",
      "Train Epoch: 5 [44400/50000 (89%)]\tLoss: 0.623206\n",
      "Train Epoch: 5 [44800/50000 (90%)]\tLoss: 1.672975\n",
      "Train Epoch: 5 [45200/50000 (90%)]\tLoss: 0.089041\n",
      "Train Epoch: 5 [45600/50000 (91%)]\tLoss: 0.273555\n",
      "Train Epoch: 5 [46000/50000 (92%)]\tLoss: 1.679099\n",
      "Train Epoch: 5 [46400/50000 (93%)]\tLoss: 1.755646\n",
      "Train Epoch: 5 [46800/50000 (94%)]\tLoss: 1.152006\n",
      "Train Epoch: 5 [47200/50000 (94%)]\tLoss: 0.347963\n",
      "Train Epoch: 5 [47600/50000 (95%)]\tLoss: 1.150223\n",
      "Train Epoch: 5 [48000/50000 (96%)]\tLoss: 0.321223\n",
      "Train Epoch: 5 [48400/50000 (97%)]\tLoss: 1.901335\n",
      "Train Epoch: 5 [48800/50000 (98%)]\tLoss: 0.488342\n",
      "Train Epoch: 5 [49200/50000 (98%)]\tLoss: 0.538322\n",
      "Train Epoch: 5 [49600/50000 (99%)]\tLoss: 0.670610\n",
      "\n",
      "Test set: Average loss: 0.2865, Accuracy: 6250/10000 (62%)\n",
      "\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 0.296459\n",
      "Train Epoch: 6 [400/50000 (1%)]\tLoss: 0.233145\n",
      "Train Epoch: 6 [800/50000 (2%)]\tLoss: 0.163968\n",
      "Train Epoch: 6 [1200/50000 (2%)]\tLoss: 0.476366\n",
      "Train Epoch: 6 [1600/50000 (3%)]\tLoss: 0.511833\n",
      "Train Epoch: 6 [2000/50000 (4%)]\tLoss: 0.689156\n",
      "Train Epoch: 6 [2400/50000 (5%)]\tLoss: 1.779427\n",
      "Train Epoch: 6 [2800/50000 (6%)]\tLoss: 0.974408\n",
      "Train Epoch: 6 [3200/50000 (6%)]\tLoss: 0.739839\n",
      "Train Epoch: 6 [3600/50000 (7%)]\tLoss: 0.778996\n",
      "Train Epoch: 6 [4000/50000 (8%)]\tLoss: 0.596142\n",
      "Train Epoch: 6 [4400/50000 (9%)]\tLoss: 0.575329\n",
      "Train Epoch: 6 [4800/50000 (10%)]\tLoss: 0.872406\n",
      "Train Epoch: 6 [5200/50000 (10%)]\tLoss: 0.774816\n",
      "Train Epoch: 6 [5600/50000 (11%)]\tLoss: 0.483634\n",
      "Train Epoch: 6 [6000/50000 (12%)]\tLoss: 1.578699\n",
      "Train Epoch: 6 [6400/50000 (13%)]\tLoss: 0.367018\n",
      "Train Epoch: 6 [6800/50000 (14%)]\tLoss: 1.287671\n",
      "Train Epoch: 6 [7200/50000 (14%)]\tLoss: 1.206331\n",
      "Train Epoch: 6 [7600/50000 (15%)]\tLoss: 0.688741\n",
      "Train Epoch: 6 [8000/50000 (16%)]\tLoss: 0.707315\n",
      "Train Epoch: 6 [8400/50000 (17%)]\tLoss: 1.335186\n",
      "Train Epoch: 6 [8800/50000 (18%)]\tLoss: 0.786849\n",
      "Train Epoch: 6 [9200/50000 (18%)]\tLoss: 1.351442\n",
      "Train Epoch: 6 [9600/50000 (19%)]\tLoss: 1.111783\n",
      "Train Epoch: 6 [10000/50000 (20%)]\tLoss: 2.408024\n",
      "Train Epoch: 6 [10400/50000 (21%)]\tLoss: 1.377788\n",
      "Train Epoch: 6 [10800/50000 (22%)]\tLoss: 0.704992\n",
      "Train Epoch: 6 [11200/50000 (22%)]\tLoss: 0.584478\n",
      "Train Epoch: 6 [11600/50000 (23%)]\tLoss: 0.178088\n",
      "Train Epoch: 6 [12000/50000 (24%)]\tLoss: 0.285674\n",
      "Train Epoch: 6 [12400/50000 (25%)]\tLoss: 0.332608\n",
      "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 0.823685\n",
      "Train Epoch: 6 [13200/50000 (26%)]\tLoss: 0.143442\n",
      "Train Epoch: 6 [13600/50000 (27%)]\tLoss: 0.235028\n",
      "Train Epoch: 6 [14000/50000 (28%)]\tLoss: 1.168262\n",
      "Train Epoch: 6 [14400/50000 (29%)]\tLoss: 0.979281\n",
      "Train Epoch: 6 [14800/50000 (30%)]\tLoss: 1.254515\n",
      "Train Epoch: 6 [15200/50000 (30%)]\tLoss: 1.271706\n",
      "Train Epoch: 6 [15600/50000 (31%)]\tLoss: 0.223348\n",
      "Train Epoch: 6 [16000/50000 (32%)]\tLoss: 0.861104\n",
      "Train Epoch: 6 [16400/50000 (33%)]\tLoss: 1.258227\n",
      "Train Epoch: 6 [16800/50000 (34%)]\tLoss: 0.276343\n",
      "Train Epoch: 6 [17200/50000 (34%)]\tLoss: 0.500868\n",
      "Train Epoch: 6 [17600/50000 (35%)]\tLoss: 0.258909\n",
      "Train Epoch: 6 [18000/50000 (36%)]\tLoss: 0.372769\n",
      "Train Epoch: 6 [18400/50000 (37%)]\tLoss: 0.073493\n",
      "Train Epoch: 6 [18800/50000 (38%)]\tLoss: 1.186478\n",
      "Train Epoch: 6 [19200/50000 (38%)]\tLoss: 0.030618\n",
      "Train Epoch: 6 [19600/50000 (39%)]\tLoss: 0.160303\n",
      "Train Epoch: 6 [20000/50000 (40%)]\tLoss: 0.311279\n",
      "Train Epoch: 6 [20400/50000 (41%)]\tLoss: 0.703181\n",
      "Train Epoch: 6 [20800/50000 (42%)]\tLoss: 0.589228\n",
      "Train Epoch: 6 [21200/50000 (42%)]\tLoss: 0.383347\n",
      "Train Epoch: 6 [21600/50000 (43%)]\tLoss: 0.620897\n",
      "Train Epoch: 6 [22000/50000 (44%)]\tLoss: 0.098219\n",
      "Train Epoch: 6 [22400/50000 (45%)]\tLoss: 0.172410\n",
      "Train Epoch: 6 [22800/50000 (46%)]\tLoss: 1.332742\n",
      "Train Epoch: 6 [23200/50000 (46%)]\tLoss: 0.748311\n",
      "Train Epoch: 6 [23600/50000 (47%)]\tLoss: 0.779566\n",
      "Train Epoch: 6 [24000/50000 (48%)]\tLoss: 0.275131\n",
      "Train Epoch: 6 [24400/50000 (49%)]\tLoss: 0.995430\n",
      "Train Epoch: 6 [24800/50000 (50%)]\tLoss: 0.225072\n",
      "Train Epoch: 6 [25200/50000 (50%)]\tLoss: 0.946734\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 0.997919\n",
      "Train Epoch: 6 [26000/50000 (52%)]\tLoss: 1.274837\n",
      "Train Epoch: 6 [26400/50000 (53%)]\tLoss: 1.141953\n",
      "Train Epoch: 6 [26800/50000 (54%)]\tLoss: 0.553761\n",
      "Train Epoch: 6 [27200/50000 (54%)]\tLoss: 2.214859\n",
      "Train Epoch: 6 [27600/50000 (55%)]\tLoss: 0.835262\n",
      "Train Epoch: 6 [28000/50000 (56%)]\tLoss: 1.828106\n",
      "Train Epoch: 6 [28400/50000 (57%)]\tLoss: 0.677640\n",
      "Train Epoch: 6 [28800/50000 (58%)]\tLoss: 0.691403\n",
      "Train Epoch: 6 [29200/50000 (58%)]\tLoss: 1.894922\n",
      "Train Epoch: 6 [29600/50000 (59%)]\tLoss: 0.234074\n",
      "Train Epoch: 6 [30000/50000 (60%)]\tLoss: 0.301106\n",
      "Train Epoch: 6 [30400/50000 (61%)]\tLoss: 1.638087\n",
      "Train Epoch: 6 [30800/50000 (62%)]\tLoss: 0.593959\n",
      "Train Epoch: 6 [31200/50000 (62%)]\tLoss: 2.182842\n",
      "Train Epoch: 6 [31600/50000 (63%)]\tLoss: 1.824717\n",
      "Train Epoch: 6 [32000/50000 (64%)]\tLoss: 1.106802\n",
      "Train Epoch: 6 [32400/50000 (65%)]\tLoss: 1.012080\n",
      "Train Epoch: 6 [32800/50000 (66%)]\tLoss: 0.031670\n",
      "Train Epoch: 6 [33200/50000 (66%)]\tLoss: 0.755958\n",
      "Train Epoch: 6 [33600/50000 (67%)]\tLoss: 0.040741\n",
      "Train Epoch: 6 [34000/50000 (68%)]\tLoss: 0.216567\n",
      "Train Epoch: 6 [34400/50000 (69%)]\tLoss: 0.090065\n",
      "Train Epoch: 6 [34800/50000 (70%)]\tLoss: 0.688045\n",
      "Train Epoch: 6 [35200/50000 (70%)]\tLoss: 0.592881\n",
      "Train Epoch: 6 [35600/50000 (71%)]\tLoss: 2.490327\n",
      "Train Epoch: 6 [36000/50000 (72%)]\tLoss: 0.296848\n",
      "Train Epoch: 6 [36400/50000 (73%)]\tLoss: 0.788054\n",
      "Train Epoch: 6 [36800/50000 (74%)]\tLoss: 0.647872\n",
      "Train Epoch: 6 [37200/50000 (74%)]\tLoss: 0.485504\n",
      "Train Epoch: 6 [37600/50000 (75%)]\tLoss: 0.631391\n",
      "Train Epoch: 6 [38000/50000 (76%)]\tLoss: 0.702673\n",
      "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 1.519165\n",
      "Train Epoch: 6 [38800/50000 (78%)]\tLoss: 0.966964\n",
      "Train Epoch: 6 [39200/50000 (78%)]\tLoss: 2.290581\n",
      "Train Epoch: 6 [39600/50000 (79%)]\tLoss: 0.245765\n",
      "Train Epoch: 6 [40000/50000 (80%)]\tLoss: 1.600363\n",
      "Train Epoch: 6 [40400/50000 (81%)]\tLoss: 0.207344\n",
      "Train Epoch: 6 [40800/50000 (82%)]\tLoss: 1.396018\n",
      "Train Epoch: 6 [41200/50000 (82%)]\tLoss: 0.649809\n",
      "Train Epoch: 6 [41600/50000 (83%)]\tLoss: 0.860059\n",
      "Train Epoch: 6 [42000/50000 (84%)]\tLoss: 0.489796\n",
      "Train Epoch: 6 [42400/50000 (85%)]\tLoss: 0.533240\n",
      "Train Epoch: 6 [42800/50000 (86%)]\tLoss: 0.872910\n",
      "Train Epoch: 6 [43200/50000 (86%)]\tLoss: 0.124775\n",
      "Train Epoch: 6 [43600/50000 (87%)]\tLoss: 0.125588\n",
      "Train Epoch: 6 [44000/50000 (88%)]\tLoss: 1.294253\n",
      "Train Epoch: 6 [44400/50000 (89%)]\tLoss: 0.337667\n",
      "Train Epoch: 6 [44800/50000 (90%)]\tLoss: 0.965845\n",
      "Train Epoch: 6 [45200/50000 (90%)]\tLoss: 0.666126\n",
      "Train Epoch: 6 [45600/50000 (91%)]\tLoss: 1.389079\n",
      "Train Epoch: 6 [46000/50000 (92%)]\tLoss: 0.618774\n",
      "Train Epoch: 6 [46400/50000 (93%)]\tLoss: 0.751223\n",
      "Train Epoch: 6 [46800/50000 (94%)]\tLoss: 0.342885\n",
      "Train Epoch: 6 [47200/50000 (94%)]\tLoss: 0.494243\n",
      "Train Epoch: 6 [47600/50000 (95%)]\tLoss: 0.734823\n",
      "Train Epoch: 6 [48000/50000 (96%)]\tLoss: 1.274444\n",
      "Train Epoch: 6 [48400/50000 (97%)]\tLoss: 1.924091\n",
      "Train Epoch: 6 [48800/50000 (98%)]\tLoss: 0.191501\n",
      "Train Epoch: 6 [49200/50000 (98%)]\tLoss: 0.409392\n",
      "Train Epoch: 6 [49600/50000 (99%)]\tLoss: 0.234684\n",
      "\n",
      "Test set: Average loss: 0.2887, Accuracy: 6363/10000 (64%)\n",
      "\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 0.037789\n",
      "Train Epoch: 7 [400/50000 (1%)]\tLoss: 0.278887\n",
      "Train Epoch: 7 [800/50000 (2%)]\tLoss: 0.644387\n",
      "Train Epoch: 7 [1200/50000 (2%)]\tLoss: 0.413329\n",
      "Train Epoch: 7 [1600/50000 (3%)]\tLoss: 0.503609\n",
      "Train Epoch: 7 [2000/50000 (4%)]\tLoss: 0.231603\n",
      "Train Epoch: 7 [2400/50000 (5%)]\tLoss: 0.243249\n",
      "Train Epoch: 7 [2800/50000 (6%)]\tLoss: 0.581274\n",
      "Train Epoch: 7 [3200/50000 (6%)]\tLoss: 0.185025\n",
      "Train Epoch: 7 [3600/50000 (7%)]\tLoss: 0.379250\n",
      "Train Epoch: 7 [4000/50000 (8%)]\tLoss: 0.334609\n",
      "Train Epoch: 7 [4400/50000 (9%)]\tLoss: 0.812064\n",
      "Train Epoch: 7 [4800/50000 (10%)]\tLoss: 1.409850\n",
      "Train Epoch: 7 [5200/50000 (10%)]\tLoss: 1.267713\n",
      "Train Epoch: 7 [5600/50000 (11%)]\tLoss: 1.350666\n",
      "Train Epoch: 7 [6000/50000 (12%)]\tLoss: 0.311353\n",
      "Train Epoch: 7 [6400/50000 (13%)]\tLoss: 2.228933\n",
      "Train Epoch: 7 [6800/50000 (14%)]\tLoss: 0.065380\n",
      "Train Epoch: 7 [7200/50000 (14%)]\tLoss: 0.504555\n",
      "Train Epoch: 7 [7600/50000 (15%)]\tLoss: 0.672971\n",
      "Train Epoch: 7 [8000/50000 (16%)]\tLoss: 0.463132\n",
      "Train Epoch: 7 [8400/50000 (17%)]\tLoss: 0.420092\n",
      "Train Epoch: 7 [8800/50000 (18%)]\tLoss: 0.219511\n",
      "Train Epoch: 7 [9200/50000 (18%)]\tLoss: 0.062221\n",
      "Train Epoch: 7 [9600/50000 (19%)]\tLoss: 0.219420\n",
      "Train Epoch: 7 [10000/50000 (20%)]\tLoss: 1.309413\n",
      "Train Epoch: 7 [10400/50000 (21%)]\tLoss: 0.406065\n",
      "Train Epoch: 7 [10800/50000 (22%)]\tLoss: 0.825130\n",
      "Train Epoch: 7 [11200/50000 (22%)]\tLoss: 0.148847\n",
      "Train Epoch: 7 [11600/50000 (23%)]\tLoss: 0.697569\n",
      "Train Epoch: 7 [12000/50000 (24%)]\tLoss: 0.321981\n",
      "Train Epoch: 7 [12400/50000 (25%)]\tLoss: 1.059784\n",
      "Train Epoch: 7 [12800/50000 (26%)]\tLoss: 0.533510\n",
      "Train Epoch: 7 [13200/50000 (26%)]\tLoss: 0.200839\n",
      "Train Epoch: 7 [13600/50000 (27%)]\tLoss: 0.318157\n",
      "Train Epoch: 7 [14000/50000 (28%)]\tLoss: 0.305441\n",
      "Train Epoch: 7 [14400/50000 (29%)]\tLoss: 1.148237\n",
      "Train Epoch: 7 [14800/50000 (30%)]\tLoss: 0.446503\n",
      "Train Epoch: 7 [15200/50000 (30%)]\tLoss: 0.893389\n",
      "Train Epoch: 7 [15600/50000 (31%)]\tLoss: 0.974041\n",
      "Train Epoch: 7 [16000/50000 (32%)]\tLoss: 0.356453\n",
      "Train Epoch: 7 [16400/50000 (33%)]\tLoss: 0.307880\n",
      "Train Epoch: 7 [16800/50000 (34%)]\tLoss: 0.533911\n",
      "Train Epoch: 7 [17200/50000 (34%)]\tLoss: 0.706698\n",
      "Train Epoch: 7 [17600/50000 (35%)]\tLoss: 0.269839\n",
      "Train Epoch: 7 [18000/50000 (36%)]\tLoss: 0.815084\n",
      "Train Epoch: 7 [18400/50000 (37%)]\tLoss: 0.373084\n",
      "Train Epoch: 7 [18800/50000 (38%)]\tLoss: 1.775502\n",
      "Train Epoch: 7 [19200/50000 (38%)]\tLoss: 0.052219\n",
      "Train Epoch: 7 [19600/50000 (39%)]\tLoss: 1.713362\n",
      "Train Epoch: 7 [20000/50000 (40%)]\tLoss: 0.167880\n",
      "Train Epoch: 7 [20400/50000 (41%)]\tLoss: 0.377662\n",
      "Train Epoch: 7 [20800/50000 (42%)]\tLoss: 0.860891\n",
      "Train Epoch: 7 [21200/50000 (42%)]\tLoss: 1.052433\n",
      "Train Epoch: 7 [21600/50000 (43%)]\tLoss: 0.967507\n",
      "Train Epoch: 7 [22000/50000 (44%)]\tLoss: 0.172147\n",
      "Train Epoch: 7 [22400/50000 (45%)]\tLoss: 0.611635\n",
      "Train Epoch: 7 [22800/50000 (46%)]\tLoss: 0.089853\n",
      "Train Epoch: 7 [23200/50000 (46%)]\tLoss: 0.524152\n",
      "Train Epoch: 7 [23600/50000 (47%)]\tLoss: 0.545607\n",
      "Train Epoch: 7 [24000/50000 (48%)]\tLoss: 0.572678\n",
      "Train Epoch: 7 [24400/50000 (49%)]\tLoss: 0.646368\n",
      "Train Epoch: 7 [24800/50000 (50%)]\tLoss: 1.873086\n",
      "Train Epoch: 7 [25200/50000 (50%)]\tLoss: 0.625330\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 0.819702\n",
      "Train Epoch: 7 [26000/50000 (52%)]\tLoss: 0.290198\n",
      "Train Epoch: 7 [26400/50000 (53%)]\tLoss: 0.883165\n",
      "Train Epoch: 7 [26800/50000 (54%)]\tLoss: 0.183361\n",
      "Train Epoch: 7 [27200/50000 (54%)]\tLoss: 0.214482\n",
      "Train Epoch: 7 [27600/50000 (55%)]\tLoss: 1.007905\n",
      "Train Epoch: 7 [28000/50000 (56%)]\tLoss: 0.316232\n",
      "Train Epoch: 7 [28400/50000 (57%)]\tLoss: 1.597508\n",
      "Train Epoch: 7 [28800/50000 (58%)]\tLoss: 1.859141\n",
      "Train Epoch: 7 [29200/50000 (58%)]\tLoss: 0.821149\n",
      "Train Epoch: 7 [29600/50000 (59%)]\tLoss: 0.299903\n",
      "Train Epoch: 7 [30000/50000 (60%)]\tLoss: 0.284372\n",
      "Train Epoch: 7 [30400/50000 (61%)]\tLoss: 1.803681\n",
      "Train Epoch: 7 [30800/50000 (62%)]\tLoss: 0.361590\n",
      "Train Epoch: 7 [31200/50000 (62%)]\tLoss: 0.482576\n",
      "Train Epoch: 7 [31600/50000 (63%)]\tLoss: 1.666551\n",
      "Train Epoch: 7 [32000/50000 (64%)]\tLoss: 1.061884\n",
      "Train Epoch: 7 [32400/50000 (65%)]\tLoss: 1.478204\n",
      "Train Epoch: 7 [32800/50000 (66%)]\tLoss: 2.735576\n",
      "Train Epoch: 7 [33200/50000 (66%)]\tLoss: 2.358425\n",
      "Train Epoch: 7 [33600/50000 (67%)]\tLoss: 0.930795\n",
      "Train Epoch: 7 [34000/50000 (68%)]\tLoss: 1.029807\n",
      "Train Epoch: 7 [34400/50000 (69%)]\tLoss: 0.961797\n",
      "Train Epoch: 7 [34800/50000 (70%)]\tLoss: 1.443820\n",
      "Train Epoch: 7 [35200/50000 (70%)]\tLoss: 1.993374\n",
      "Train Epoch: 7 [35600/50000 (71%)]\tLoss: 0.191689\n",
      "Train Epoch: 7 [36000/50000 (72%)]\tLoss: 1.269411\n",
      "Train Epoch: 7 [36400/50000 (73%)]\tLoss: 1.390282\n",
      "Train Epoch: 7 [36800/50000 (74%)]\tLoss: 1.036428\n",
      "Train Epoch: 7 [37200/50000 (74%)]\tLoss: 0.232641\n",
      "Train Epoch: 7 [37600/50000 (75%)]\tLoss: 0.557054\n",
      "Train Epoch: 7 [38000/50000 (76%)]\tLoss: 0.463357\n",
      "Train Epoch: 7 [38400/50000 (77%)]\tLoss: 0.767089\n",
      "Train Epoch: 7 [38800/50000 (78%)]\tLoss: 0.640243\n",
      "Train Epoch: 7 [39200/50000 (78%)]\tLoss: 0.879754\n",
      "Train Epoch: 7 [39600/50000 (79%)]\tLoss: 0.272210\n",
      "Train Epoch: 7 [40000/50000 (80%)]\tLoss: 1.403767\n",
      "Train Epoch: 7 [40400/50000 (81%)]\tLoss: 0.393854\n",
      "Train Epoch: 7 [40800/50000 (82%)]\tLoss: 0.439594\n",
      "Train Epoch: 7 [41200/50000 (82%)]\tLoss: 0.664028\n",
      "Train Epoch: 7 [41600/50000 (83%)]\tLoss: 1.203211\n",
      "Train Epoch: 7 [42000/50000 (84%)]\tLoss: 0.712198\n",
      "Train Epoch: 7 [42400/50000 (85%)]\tLoss: 1.436186\n",
      "Train Epoch: 7 [42800/50000 (86%)]\tLoss: 0.788792\n",
      "Train Epoch: 7 [43200/50000 (86%)]\tLoss: 1.414317\n",
      "Train Epoch: 7 [43600/50000 (87%)]\tLoss: 0.311107\n",
      "Train Epoch: 7 [44000/50000 (88%)]\tLoss: 2.173018\n",
      "Train Epoch: 7 [44400/50000 (89%)]\tLoss: 0.177554\n",
      "Train Epoch: 7 [44800/50000 (90%)]\tLoss: 0.242785\n",
      "Train Epoch: 7 [45200/50000 (90%)]\tLoss: 0.027610\n",
      "Train Epoch: 7 [45600/50000 (91%)]\tLoss: 1.506506\n",
      "Train Epoch: 7 [46000/50000 (92%)]\tLoss: 1.383382\n",
      "Train Epoch: 7 [46400/50000 (93%)]\tLoss: 0.558150\n",
      "Train Epoch: 7 [46800/50000 (94%)]\tLoss: 0.482426\n",
      "Train Epoch: 7 [47200/50000 (94%)]\tLoss: 1.373483\n",
      "Train Epoch: 7 [47600/50000 (95%)]\tLoss: 0.649177\n",
      "Train Epoch: 7 [48000/50000 (96%)]\tLoss: 0.778651\n",
      "Train Epoch: 7 [48400/50000 (97%)]\tLoss: 0.735269\n",
      "Train Epoch: 7 [48800/50000 (98%)]\tLoss: 0.309233\n",
      "Train Epoch: 7 [49200/50000 (98%)]\tLoss: 0.371667\n",
      "Train Epoch: 7 [49600/50000 (99%)]\tLoss: 0.175557\n",
      "\n",
      "Test set: Average loss: 0.3165, Accuracy: 6315/10000 (63%)\n",
      "\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 0.559078\n",
      "Train Epoch: 8 [400/50000 (1%)]\tLoss: 0.352930\n",
      "Train Epoch: 8 [800/50000 (2%)]\tLoss: 0.505581\n",
      "Train Epoch: 8 [1200/50000 (2%)]\tLoss: 0.956601\n",
      "Train Epoch: 8 [1600/50000 (3%)]\tLoss: 0.461677\n",
      "Train Epoch: 8 [2000/50000 (4%)]\tLoss: 0.805404\n",
      "Train Epoch: 8 [2400/50000 (5%)]\tLoss: 0.073532\n",
      "Train Epoch: 8 [2800/50000 (6%)]\tLoss: 0.438806\n",
      "Train Epoch: 8 [3200/50000 (6%)]\tLoss: 0.881896\n",
      "Train Epoch: 8 [3600/50000 (7%)]\tLoss: 0.447218\n",
      "Train Epoch: 8 [4000/50000 (8%)]\tLoss: 0.136418\n",
      "Train Epoch: 8 [4400/50000 (9%)]\tLoss: 0.587396\n",
      "Train Epoch: 8 [4800/50000 (10%)]\tLoss: 0.819688\n",
      "Train Epoch: 8 [5200/50000 (10%)]\tLoss: 0.277060\n",
      "Train Epoch: 8 [5600/50000 (11%)]\tLoss: 0.926011\n",
      "Train Epoch: 8 [6000/50000 (12%)]\tLoss: 0.163880\n",
      "Train Epoch: 8 [6400/50000 (13%)]\tLoss: 0.334811\n",
      "Train Epoch: 8 [6800/50000 (14%)]\tLoss: 1.192022\n",
      "Train Epoch: 8 [7200/50000 (14%)]\tLoss: 0.179298\n",
      "Train Epoch: 8 [7600/50000 (15%)]\tLoss: 0.446349\n",
      "Train Epoch: 8 [8000/50000 (16%)]\tLoss: 0.574485\n",
      "Train Epoch: 8 [8400/50000 (17%)]\tLoss: 0.257313\n",
      "Train Epoch: 8 [8800/50000 (18%)]\tLoss: 1.033526\n",
      "Train Epoch: 8 [9200/50000 (18%)]\tLoss: 0.926277\n",
      "Train Epoch: 8 [9600/50000 (19%)]\tLoss: 1.200470\n",
      "Train Epoch: 8 [10000/50000 (20%)]\tLoss: 0.111869\n",
      "Train Epoch: 8 [10400/50000 (21%)]\tLoss: 1.005956\n",
      "Train Epoch: 8 [10800/50000 (22%)]\tLoss: 0.863562\n",
      "Train Epoch: 8 [11200/50000 (22%)]\tLoss: 1.403881\n",
      "Train Epoch: 8 [11600/50000 (23%)]\tLoss: 0.515082\n",
      "Train Epoch: 8 [12000/50000 (24%)]\tLoss: 0.755944\n",
      "Train Epoch: 8 [12400/50000 (25%)]\tLoss: 0.464609\n",
      "Train Epoch: 8 [12800/50000 (26%)]\tLoss: 0.963403\n",
      "Train Epoch: 8 [13200/50000 (26%)]\tLoss: 1.202864\n",
      "Train Epoch: 8 [13600/50000 (27%)]\tLoss: 0.057464\n",
      "Train Epoch: 8 [14000/50000 (28%)]\tLoss: 1.109418\n",
      "Train Epoch: 8 [14400/50000 (29%)]\tLoss: 0.012805\n",
      "Train Epoch: 8 [14800/50000 (30%)]\tLoss: 0.182698\n",
      "Train Epoch: 8 [15200/50000 (30%)]\tLoss: 0.735690\n",
      "Train Epoch: 8 [15600/50000 (31%)]\tLoss: 0.161751\n",
      "Train Epoch: 8 [16000/50000 (32%)]\tLoss: 1.146212\n",
      "Train Epoch: 8 [16400/50000 (33%)]\tLoss: 1.447257\n",
      "Train Epoch: 8 [16800/50000 (34%)]\tLoss: 0.552543\n",
      "Train Epoch: 8 [17200/50000 (34%)]\tLoss: 0.352850\n",
      "Train Epoch: 8 [17600/50000 (35%)]\tLoss: 0.249335\n",
      "Train Epoch: 8 [18000/50000 (36%)]\tLoss: 0.498980\n",
      "Train Epoch: 8 [18400/50000 (37%)]\tLoss: 0.049718\n",
      "Train Epoch: 8 [18800/50000 (38%)]\tLoss: 0.457923\n",
      "Train Epoch: 8 [19200/50000 (38%)]\tLoss: 0.620943\n",
      "Train Epoch: 8 [19600/50000 (39%)]\tLoss: 0.279897\n",
      "Train Epoch: 8 [20000/50000 (40%)]\tLoss: 0.203847\n",
      "Train Epoch: 8 [20400/50000 (41%)]\tLoss: 0.393248\n",
      "Train Epoch: 8 [20800/50000 (42%)]\tLoss: 1.453696\n",
      "Train Epoch: 8 [21200/50000 (42%)]\tLoss: 0.977014\n",
      "Train Epoch: 8 [21600/50000 (43%)]\tLoss: 0.012347\n",
      "Train Epoch: 8 [22000/50000 (44%)]\tLoss: 2.336716\n",
      "Train Epoch: 8 [22400/50000 (45%)]\tLoss: 0.253558\n",
      "Train Epoch: 8 [22800/50000 (46%)]\tLoss: 0.199757\n",
      "Train Epoch: 8 [23200/50000 (46%)]\tLoss: 1.967759\n",
      "Train Epoch: 8 [23600/50000 (47%)]\tLoss: 0.195331\n",
      "Train Epoch: 8 [24000/50000 (48%)]\tLoss: 1.245956\n",
      "Train Epoch: 8 [24400/50000 (49%)]\tLoss: 0.908207\n",
      "Train Epoch: 8 [24800/50000 (50%)]\tLoss: 0.548936\n",
      "Train Epoch: 8 [25200/50000 (50%)]\tLoss: 0.422603\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 0.998264\n",
      "Train Epoch: 8 [26000/50000 (52%)]\tLoss: 0.177869\n",
      "Train Epoch: 8 [26400/50000 (53%)]\tLoss: 0.241191\n",
      "Train Epoch: 8 [26800/50000 (54%)]\tLoss: 0.298573\n",
      "Train Epoch: 8 [27200/50000 (54%)]\tLoss: 0.787389\n",
      "Train Epoch: 8 [27600/50000 (55%)]\tLoss: 0.353912\n",
      "Train Epoch: 8 [28000/50000 (56%)]\tLoss: 0.268706\n",
      "Train Epoch: 8 [28400/50000 (57%)]\tLoss: 0.338348\n",
      "Train Epoch: 8 [28800/50000 (58%)]\tLoss: 0.129227\n",
      "Train Epoch: 8 [29200/50000 (58%)]\tLoss: 0.881923\n",
      "Train Epoch: 8 [29600/50000 (59%)]\tLoss: 0.385713\n",
      "Train Epoch: 8 [30000/50000 (60%)]\tLoss: 0.037325\n",
      "Train Epoch: 8 [30400/50000 (61%)]\tLoss: 0.354818\n",
      "Train Epoch: 8 [30800/50000 (62%)]\tLoss: 0.305515\n",
      "Train Epoch: 8 [31200/50000 (62%)]\tLoss: 0.475340\n",
      "Train Epoch: 8 [31600/50000 (63%)]\tLoss: 0.449660\n",
      "Train Epoch: 8 [32000/50000 (64%)]\tLoss: 0.122874\n",
      "Train Epoch: 8 [32400/50000 (65%)]\tLoss: 0.289646\n",
      "Train Epoch: 8 [32800/50000 (66%)]\tLoss: 0.124608\n",
      "Train Epoch: 8 [33200/50000 (66%)]\tLoss: 0.051209\n",
      "Train Epoch: 8 [33600/50000 (67%)]\tLoss: 0.361747\n",
      "Train Epoch: 8 [34000/50000 (68%)]\tLoss: 0.784441\n",
      "Train Epoch: 8 [34400/50000 (69%)]\tLoss: 0.047749\n",
      "Train Epoch: 8 [34800/50000 (70%)]\tLoss: 0.851047\n",
      "Train Epoch: 8 [35200/50000 (70%)]\tLoss: 2.914480\n",
      "Train Epoch: 8 [35600/50000 (71%)]\tLoss: 0.323462\n",
      "Train Epoch: 8 [36000/50000 (72%)]\tLoss: 0.620426\n",
      "Train Epoch: 8 [36400/50000 (73%)]\tLoss: 0.736267\n",
      "Train Epoch: 8 [36800/50000 (74%)]\tLoss: 0.925664\n",
      "Train Epoch: 8 [37200/50000 (74%)]\tLoss: 0.298478\n",
      "Train Epoch: 8 [37600/50000 (75%)]\tLoss: 0.616111\n",
      "Train Epoch: 8 [38000/50000 (76%)]\tLoss: 0.727668\n",
      "Train Epoch: 8 [38400/50000 (77%)]\tLoss: 1.271652\n",
      "Train Epoch: 8 [38800/50000 (78%)]\tLoss: 0.284449\n",
      "Train Epoch: 8 [39200/50000 (78%)]\tLoss: 0.468937\n",
      "Train Epoch: 8 [39600/50000 (79%)]\tLoss: 0.322800\n",
      "Train Epoch: 8 [40000/50000 (80%)]\tLoss: 0.309183\n",
      "Train Epoch: 8 [40400/50000 (81%)]\tLoss: 1.085443\n",
      "Train Epoch: 8 [40800/50000 (82%)]\tLoss: 0.913836\n",
      "Train Epoch: 8 [41200/50000 (82%)]\tLoss: 0.195305\n",
      "Train Epoch: 8 [41600/50000 (83%)]\tLoss: 1.351141\n",
      "Train Epoch: 8 [42000/50000 (84%)]\tLoss: 0.300639\n",
      "Train Epoch: 8 [42400/50000 (85%)]\tLoss: 0.202428\n",
      "Train Epoch: 8 [42800/50000 (86%)]\tLoss: 0.723794\n",
      "Train Epoch: 8 [43200/50000 (86%)]\tLoss: 0.361447\n",
      "Train Epoch: 8 [43600/50000 (87%)]\tLoss: 0.055128\n",
      "Train Epoch: 8 [44000/50000 (88%)]\tLoss: 0.508813\n",
      "Train Epoch: 8 [44400/50000 (89%)]\tLoss: 0.945116\n",
      "Train Epoch: 8 [44800/50000 (90%)]\tLoss: 0.694591\n",
      "Train Epoch: 8 [45200/50000 (90%)]\tLoss: 0.152459\n",
      "Train Epoch: 8 [45600/50000 (91%)]\tLoss: 0.543968\n",
      "Train Epoch: 8 [46000/50000 (92%)]\tLoss: 0.049935\n",
      "Train Epoch: 8 [46400/50000 (93%)]\tLoss: 0.673491\n",
      "Train Epoch: 8 [46800/50000 (94%)]\tLoss: 0.828691\n",
      "Train Epoch: 8 [47200/50000 (94%)]\tLoss: 0.186143\n",
      "Train Epoch: 8 [47600/50000 (95%)]\tLoss: 0.611358\n",
      "Train Epoch: 8 [48000/50000 (96%)]\tLoss: 0.407699\n",
      "Train Epoch: 8 [48400/50000 (97%)]\tLoss: 3.181584\n",
      "Train Epoch: 8 [48800/50000 (98%)]\tLoss: 1.735824\n",
      "Train Epoch: 8 [49200/50000 (98%)]\tLoss: 0.410363\n",
      "Train Epoch: 8 [49600/50000 (99%)]\tLoss: 0.091404\n",
      "\n",
      "Test set: Average loss: 0.3312, Accuracy: 6378/10000 (64%)\n",
      "\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 0.149893\n",
      "Train Epoch: 9 [400/50000 (1%)]\tLoss: 0.215344\n",
      "Train Epoch: 9 [800/50000 (2%)]\tLoss: 0.789937\n",
      "Train Epoch: 9 [1200/50000 (2%)]\tLoss: 0.411477\n",
      "Train Epoch: 9 [1600/50000 (3%)]\tLoss: 0.615500\n",
      "Train Epoch: 9 [2000/50000 (4%)]\tLoss: 0.415769\n",
      "Train Epoch: 9 [2400/50000 (5%)]\tLoss: 0.931856\n",
      "Train Epoch: 9 [2800/50000 (6%)]\tLoss: 1.362565\n",
      "Train Epoch: 9 [3200/50000 (6%)]\tLoss: 0.627970\n",
      "Train Epoch: 9 [3600/50000 (7%)]\tLoss: 0.344030\n",
      "Train Epoch: 9 [4000/50000 (8%)]\tLoss: 0.383400\n",
      "Train Epoch: 9 [4400/50000 (9%)]\tLoss: 0.141492\n",
      "Train Epoch: 9 [4800/50000 (10%)]\tLoss: 0.055080\n",
      "Train Epoch: 9 [5200/50000 (10%)]\tLoss: 0.032741\n",
      "Train Epoch: 9 [5600/50000 (11%)]\tLoss: 0.017369\n",
      "Train Epoch: 9 [6000/50000 (12%)]\tLoss: 0.565074\n",
      "Train Epoch: 9 [6400/50000 (13%)]\tLoss: 0.109103\n",
      "Train Epoch: 9 [6800/50000 (14%)]\tLoss: 1.015753\n",
      "Train Epoch: 9 [7200/50000 (14%)]\tLoss: 1.090989\n",
      "Train Epoch: 9 [7600/50000 (15%)]\tLoss: 1.950970\n",
      "Train Epoch: 9 [8000/50000 (16%)]\tLoss: 0.814753\n",
      "Train Epoch: 9 [8400/50000 (17%)]\tLoss: 1.321006\n",
      "Train Epoch: 9 [8800/50000 (18%)]\tLoss: 1.176168\n",
      "Train Epoch: 9 [9200/50000 (18%)]\tLoss: 0.184535\n",
      "Train Epoch: 9 [9600/50000 (19%)]\tLoss: 0.029803\n",
      "Train Epoch: 9 [10000/50000 (20%)]\tLoss: 0.510318\n",
      "Train Epoch: 9 [10400/50000 (21%)]\tLoss: 0.399152\n",
      "Train Epoch: 9 [10800/50000 (22%)]\tLoss: 0.664527\n",
      "Train Epoch: 9 [11200/50000 (22%)]\tLoss: 0.347696\n",
      "Train Epoch: 9 [11600/50000 (23%)]\tLoss: 2.827670\n",
      "Train Epoch: 9 [12000/50000 (24%)]\tLoss: 1.936042\n",
      "Train Epoch: 9 [12400/50000 (25%)]\tLoss: 1.568287\n",
      "Train Epoch: 9 [12800/50000 (26%)]\tLoss: 0.029205\n",
      "Train Epoch: 9 [13200/50000 (26%)]\tLoss: 0.090359\n",
      "Train Epoch: 9 [13600/50000 (27%)]\tLoss: 0.044742\n",
      "Train Epoch: 9 [14000/50000 (28%)]\tLoss: 0.641542\n",
      "Train Epoch: 9 [14400/50000 (29%)]\tLoss: 0.038369\n",
      "Train Epoch: 9 [14800/50000 (30%)]\tLoss: 0.509992\n",
      "Train Epoch: 9 [15200/50000 (30%)]\tLoss: 2.896339\n",
      "Train Epoch: 9 [15600/50000 (31%)]\tLoss: 0.441330\n",
      "Train Epoch: 9 [16000/50000 (32%)]\tLoss: 0.578218\n",
      "Train Epoch: 9 [16400/50000 (33%)]\tLoss: 0.828287\n",
      "Train Epoch: 9 [16800/50000 (34%)]\tLoss: 0.110713\n",
      "Train Epoch: 9 [17200/50000 (34%)]\tLoss: 0.943432\n",
      "Train Epoch: 9 [17600/50000 (35%)]\tLoss: 1.184198\n",
      "Train Epoch: 9 [18000/50000 (36%)]\tLoss: 0.684181\n",
      "Train Epoch: 9 [18400/50000 (37%)]\tLoss: 0.166571\n",
      "Train Epoch: 9 [18800/50000 (38%)]\tLoss: 0.262088\n",
      "Train Epoch: 9 [19200/50000 (38%)]\tLoss: 0.185215\n",
      "Train Epoch: 9 [19600/50000 (39%)]\tLoss: 0.093981\n",
      "Train Epoch: 9 [20000/50000 (40%)]\tLoss: 0.606328\n",
      "Train Epoch: 9 [20400/50000 (41%)]\tLoss: 0.942904\n",
      "Train Epoch: 9 [20800/50000 (42%)]\tLoss: 0.776039\n",
      "Train Epoch: 9 [21200/50000 (42%)]\tLoss: 0.343378\n",
      "Train Epoch: 9 [21600/50000 (43%)]\tLoss: 0.103239\n",
      "Train Epoch: 9 [22000/50000 (44%)]\tLoss: 0.370523\n",
      "Train Epoch: 9 [22400/50000 (45%)]\tLoss: 0.273287\n",
      "Train Epoch: 9 [22800/50000 (46%)]\tLoss: 0.418162\n",
      "Train Epoch: 9 [23200/50000 (46%)]\tLoss: 0.820289\n",
      "Train Epoch: 9 [23600/50000 (47%)]\tLoss: 1.132083\n",
      "Train Epoch: 9 [24000/50000 (48%)]\tLoss: 0.394235\n",
      "Train Epoch: 9 [24400/50000 (49%)]\tLoss: 0.171981\n",
      "Train Epoch: 9 [24800/50000 (50%)]\tLoss: 0.686680\n",
      "Train Epoch: 9 [25200/50000 (50%)]\tLoss: 0.990523\n",
      "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 0.225154\n",
      "Train Epoch: 9 [26000/50000 (52%)]\tLoss: 0.931014\n",
      "Train Epoch: 9 [26400/50000 (53%)]\tLoss: 0.954821\n",
      "Train Epoch: 9 [26800/50000 (54%)]\tLoss: 0.064117\n",
      "Train Epoch: 9 [27200/50000 (54%)]\tLoss: 0.825406\n",
      "Train Epoch: 9 [27600/50000 (55%)]\tLoss: 0.952384\n",
      "Train Epoch: 9 [28000/50000 (56%)]\tLoss: 0.384207\n",
      "Train Epoch: 9 [28400/50000 (57%)]\tLoss: 0.472526\n",
      "Train Epoch: 9 [28800/50000 (58%)]\tLoss: 0.988783\n",
      "Train Epoch: 9 [29200/50000 (58%)]\tLoss: 1.427965\n",
      "Train Epoch: 9 [29600/50000 (59%)]\tLoss: 0.803101\n",
      "Train Epoch: 9 [30000/50000 (60%)]\tLoss: 0.257061\n",
      "Train Epoch: 9 [30400/50000 (61%)]\tLoss: 0.201948\n",
      "Train Epoch: 9 [30800/50000 (62%)]\tLoss: 0.702471\n",
      "Train Epoch: 9 [31200/50000 (62%)]\tLoss: 0.968811\n",
      "Train Epoch: 9 [31600/50000 (63%)]\tLoss: 0.013275\n",
      "Train Epoch: 9 [32000/50000 (64%)]\tLoss: 0.443122\n",
      "Train Epoch: 9 [32400/50000 (65%)]\tLoss: 0.432632\n",
      "Train Epoch: 9 [32800/50000 (66%)]\tLoss: 0.513142\n",
      "Train Epoch: 9 [33200/50000 (66%)]\tLoss: 1.053648\n",
      "Train Epoch: 9 [33600/50000 (67%)]\tLoss: 0.601269\n",
      "Train Epoch: 9 [34000/50000 (68%)]\tLoss: 0.785837\n",
      "Train Epoch: 9 [34400/50000 (69%)]\tLoss: 0.043914\n",
      "Train Epoch: 9 [34800/50000 (70%)]\tLoss: 0.075134\n",
      "Train Epoch: 9 [35200/50000 (70%)]\tLoss: 0.676967\n",
      "Train Epoch: 9 [35600/50000 (71%)]\tLoss: 0.390606\n",
      "Train Epoch: 9 [36000/50000 (72%)]\tLoss: 0.370650\n",
      "Train Epoch: 9 [36400/50000 (73%)]\tLoss: 0.274316\n",
      "Train Epoch: 9 [36800/50000 (74%)]\tLoss: 0.377395\n",
      "Train Epoch: 9 [37200/50000 (74%)]\tLoss: 0.214845\n",
      "Train Epoch: 9 [37600/50000 (75%)]\tLoss: 1.347102\n",
      "Train Epoch: 9 [38000/50000 (76%)]\tLoss: 1.823445\n",
      "Train Epoch: 9 [38400/50000 (77%)]\tLoss: 0.837533\n",
      "Train Epoch: 9 [38800/50000 (78%)]\tLoss: 0.742647\n",
      "Train Epoch: 9 [39200/50000 (78%)]\tLoss: 0.557436\n",
      "Train Epoch: 9 [39600/50000 (79%)]\tLoss: 0.679435\n",
      "Train Epoch: 9 [40000/50000 (80%)]\tLoss: 0.049061\n",
      "Train Epoch: 9 [40400/50000 (81%)]\tLoss: 0.279003\n",
      "Train Epoch: 9 [40800/50000 (82%)]\tLoss: 0.580529\n",
      "Train Epoch: 9 [41200/50000 (82%)]\tLoss: 0.650819\n",
      "Train Epoch: 9 [41600/50000 (83%)]\tLoss: 0.731004\n",
      "Train Epoch: 9 [42000/50000 (84%)]\tLoss: 1.035750\n",
      "Train Epoch: 9 [42400/50000 (85%)]\tLoss: 2.324598\n",
      "Train Epoch: 9 [42800/50000 (86%)]\tLoss: 1.370465\n",
      "Train Epoch: 9 [43200/50000 (86%)]\tLoss: 0.514224\n",
      "Train Epoch: 9 [43600/50000 (87%)]\tLoss: 0.796453\n",
      "Train Epoch: 9 [44000/50000 (88%)]\tLoss: 0.736334\n",
      "Train Epoch: 9 [44400/50000 (89%)]\tLoss: 0.133718\n",
      "Train Epoch: 9 [44800/50000 (90%)]\tLoss: 0.443045\n",
      "Train Epoch: 9 [45200/50000 (90%)]\tLoss: 0.063085\n",
      "Train Epoch: 9 [45600/50000 (91%)]\tLoss: 0.470196\n",
      "Train Epoch: 9 [46000/50000 (92%)]\tLoss: 0.807802\n",
      "Train Epoch: 9 [46400/50000 (93%)]\tLoss: 0.943908\n",
      "Train Epoch: 9 [46800/50000 (94%)]\tLoss: 1.535945\n",
      "Train Epoch: 9 [47200/50000 (94%)]\tLoss: 1.463551\n",
      "Train Epoch: 9 [47600/50000 (95%)]\tLoss: 0.854416\n",
      "Train Epoch: 9 [48000/50000 (96%)]\tLoss: 0.391449\n",
      "Train Epoch: 9 [48400/50000 (97%)]\tLoss: 0.055486\n",
      "Train Epoch: 9 [48800/50000 (98%)]\tLoss: 1.047931\n",
      "Train Epoch: 9 [49200/50000 (98%)]\tLoss: 0.023097\n",
      "Train Epoch: 9 [49600/50000 (99%)]\tLoss: 0.517969\n",
      "\n",
      "Test set: Average loss: 0.3263, Accuracy: 6334/10000 (63%)\n",
      "\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLoss: 0.445459\n",
      "Train Epoch: 10 [400/50000 (1%)]\tLoss: 0.639052\n",
      "Train Epoch: 10 [800/50000 (2%)]\tLoss: 0.074227\n",
      "Train Epoch: 10 [1200/50000 (2%)]\tLoss: 0.242420\n",
      "Train Epoch: 10 [1600/50000 (3%)]\tLoss: 0.120047\n",
      "Train Epoch: 10 [2000/50000 (4%)]\tLoss: 0.007816\n",
      "Train Epoch: 10 [2400/50000 (5%)]\tLoss: 0.564865\n",
      "Train Epoch: 10 [2800/50000 (6%)]\tLoss: 0.630374\n",
      "Train Epoch: 10 [3200/50000 (6%)]\tLoss: 4.568283\n",
      "Train Epoch: 10 [3600/50000 (7%)]\tLoss: 0.128687\n",
      "Train Epoch: 10 [4000/50000 (8%)]\tLoss: 0.919505\n",
      "Train Epoch: 10 [4400/50000 (9%)]\tLoss: 1.032026\n",
      "Train Epoch: 10 [4800/50000 (10%)]\tLoss: 0.539220\n",
      "Train Epoch: 10 [5200/50000 (10%)]\tLoss: 0.352814\n",
      "Train Epoch: 10 [5600/50000 (11%)]\tLoss: 0.042962\n",
      "Train Epoch: 10 [6000/50000 (12%)]\tLoss: 0.327271\n",
      "Train Epoch: 10 [6400/50000 (13%)]\tLoss: 1.177894\n",
      "Train Epoch: 10 [6800/50000 (14%)]\tLoss: 0.076809\n",
      "Train Epoch: 10 [7200/50000 (14%)]\tLoss: 0.187484\n",
      "Train Epoch: 10 [7600/50000 (15%)]\tLoss: 0.069771\n",
      "Train Epoch: 10 [8000/50000 (16%)]\tLoss: 0.237266\n",
      "Train Epoch: 10 [8400/50000 (17%)]\tLoss: 0.267943\n",
      "Train Epoch: 10 [8800/50000 (18%)]\tLoss: 0.746464\n",
      "Train Epoch: 10 [9200/50000 (18%)]\tLoss: 0.463683\n",
      "Train Epoch: 10 [9600/50000 (19%)]\tLoss: 0.259971\n",
      "Train Epoch: 10 [10000/50000 (20%)]\tLoss: 0.107469\n",
      "Train Epoch: 10 [10400/50000 (21%)]\tLoss: 1.074459\n",
      "Train Epoch: 10 [10800/50000 (22%)]\tLoss: 1.297605\n",
      "Train Epoch: 10 [11200/50000 (22%)]\tLoss: 0.373099\n",
      "Train Epoch: 10 [11600/50000 (23%)]\tLoss: 0.186916\n",
      "Train Epoch: 10 [12000/50000 (24%)]\tLoss: 1.729889\n",
      "Train Epoch: 10 [12400/50000 (25%)]\tLoss: 0.405930\n",
      "Train Epoch: 10 [12800/50000 (26%)]\tLoss: 0.640224\n",
      "Train Epoch: 10 [13200/50000 (26%)]\tLoss: 0.915875\n",
      "Train Epoch: 10 [13600/50000 (27%)]\tLoss: 0.401436\n",
      "Train Epoch: 10 [14000/50000 (28%)]\tLoss: 2.366493\n",
      "Train Epoch: 10 [14400/50000 (29%)]\tLoss: 1.419765\n",
      "Train Epoch: 10 [14800/50000 (30%)]\tLoss: 0.124471\n",
      "Train Epoch: 10 [15200/50000 (30%)]\tLoss: 0.456870\n",
      "Train Epoch: 10 [15600/50000 (31%)]\tLoss: 0.764200\n",
      "Train Epoch: 10 [16000/50000 (32%)]\tLoss: 0.001451\n",
      "Train Epoch: 10 [16400/50000 (33%)]\tLoss: 0.153654\n",
      "Train Epoch: 10 [16800/50000 (34%)]\tLoss: 0.972856\n",
      "Train Epoch: 10 [17200/50000 (34%)]\tLoss: 0.221696\n",
      "Train Epoch: 10 [17600/50000 (35%)]\tLoss: 0.142714\n",
      "Train Epoch: 10 [18000/50000 (36%)]\tLoss: 0.490005\n",
      "Train Epoch: 10 [18400/50000 (37%)]\tLoss: 0.582229\n",
      "Train Epoch: 10 [18800/50000 (38%)]\tLoss: 0.750959\n",
      "Train Epoch: 10 [19200/50000 (38%)]\tLoss: 0.899488\n",
      "Train Epoch: 10 [19600/50000 (39%)]\tLoss: 0.140700\n",
      "Train Epoch: 10 [20000/50000 (40%)]\tLoss: 0.510771\n",
      "Train Epoch: 10 [20400/50000 (41%)]\tLoss: 1.452556\n",
      "Train Epoch: 10 [20800/50000 (42%)]\tLoss: 0.118531\n",
      "Train Epoch: 10 [21200/50000 (42%)]\tLoss: 0.104192\n",
      "Train Epoch: 10 [21600/50000 (43%)]\tLoss: 0.061058\n",
      "Train Epoch: 10 [22000/50000 (44%)]\tLoss: 0.826781\n",
      "Train Epoch: 10 [22400/50000 (45%)]\tLoss: 0.535695\n",
      "Train Epoch: 10 [22800/50000 (46%)]\tLoss: 0.410786\n",
      "Train Epoch: 10 [23200/50000 (46%)]\tLoss: 0.064000\n",
      "Train Epoch: 10 [23600/50000 (47%)]\tLoss: 0.153088\n",
      "Train Epoch: 10 [24000/50000 (48%)]\tLoss: 1.011744\n",
      "Train Epoch: 10 [24400/50000 (49%)]\tLoss: 0.605764\n",
      "Train Epoch: 10 [24800/50000 (50%)]\tLoss: 1.045882\n",
      "Train Epoch: 10 [25200/50000 (50%)]\tLoss: 0.233945\n",
      "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 0.879472\n",
      "Train Epoch: 10 [26000/50000 (52%)]\tLoss: 0.616579\n",
      "Train Epoch: 10 [26400/50000 (53%)]\tLoss: 0.513282\n",
      "Train Epoch: 10 [26800/50000 (54%)]\tLoss: 2.321187\n",
      "Train Epoch: 10 [27200/50000 (54%)]\tLoss: 0.050892\n",
      "Train Epoch: 10 [27600/50000 (55%)]\tLoss: 0.385401\n",
      "Train Epoch: 10 [28000/50000 (56%)]\tLoss: 0.004372\n",
      "Train Epoch: 10 [28400/50000 (57%)]\tLoss: 0.127410\n",
      "Train Epoch: 10 [28800/50000 (58%)]\tLoss: 0.434162\n",
      "Train Epoch: 10 [29200/50000 (58%)]\tLoss: 0.469560\n",
      "Train Epoch: 10 [29600/50000 (59%)]\tLoss: 0.634857\n",
      "Train Epoch: 10 [30000/50000 (60%)]\tLoss: 1.043321\n",
      "Train Epoch: 10 [30400/50000 (61%)]\tLoss: 0.209037\n",
      "Train Epoch: 10 [30800/50000 (62%)]\tLoss: 0.791214\n",
      "Train Epoch: 10 [31200/50000 (62%)]\tLoss: 1.193572\n",
      "Train Epoch: 10 [31600/50000 (63%)]\tLoss: 1.372724\n",
      "Train Epoch: 10 [32000/50000 (64%)]\tLoss: 0.483111\n",
      "Train Epoch: 10 [32400/50000 (65%)]\tLoss: 0.709923\n",
      "Train Epoch: 10 [32800/50000 (66%)]\tLoss: 0.831425\n",
      "Train Epoch: 10 [33200/50000 (66%)]\tLoss: 1.059076\n",
      "Train Epoch: 10 [33600/50000 (67%)]\tLoss: 0.530770\n",
      "Train Epoch: 10 [34000/50000 (68%)]\tLoss: 0.587223\n",
      "Train Epoch: 10 [34400/50000 (69%)]\tLoss: 1.071843\n",
      "Train Epoch: 10 [34800/50000 (70%)]\tLoss: 0.610728\n",
      "Train Epoch: 10 [35200/50000 (70%)]\tLoss: 1.332777\n",
      "Train Epoch: 10 [35600/50000 (71%)]\tLoss: 0.978392\n",
      "Train Epoch: 10 [36000/50000 (72%)]\tLoss: 0.311955\n",
      "Train Epoch: 10 [36400/50000 (73%)]\tLoss: 0.971797\n",
      "Train Epoch: 10 [36800/50000 (74%)]\tLoss: 0.473647\n",
      "Train Epoch: 10 [37200/50000 (74%)]\tLoss: 0.614549\n",
      "Train Epoch: 10 [37600/50000 (75%)]\tLoss: 1.327403\n",
      "Train Epoch: 10 [38000/50000 (76%)]\tLoss: 0.051425\n",
      "Train Epoch: 10 [38400/50000 (77%)]\tLoss: 0.587193\n",
      "Train Epoch: 10 [38800/50000 (78%)]\tLoss: 0.503082\n",
      "Train Epoch: 10 [39200/50000 (78%)]\tLoss: 0.225826\n",
      "Train Epoch: 10 [39600/50000 (79%)]\tLoss: 0.346271\n",
      "Train Epoch: 10 [40000/50000 (80%)]\tLoss: 0.213358\n",
      "Train Epoch: 10 [40400/50000 (81%)]\tLoss: 0.170708\n",
      "Train Epoch: 10 [40800/50000 (82%)]\tLoss: 0.044774\n",
      "Train Epoch: 10 [41200/50000 (82%)]\tLoss: 2.206115\n",
      "Train Epoch: 10 [41600/50000 (83%)]\tLoss: 0.098280\n",
      "Train Epoch: 10 [42000/50000 (84%)]\tLoss: 0.913492\n",
      "Train Epoch: 10 [42400/50000 (85%)]\tLoss: 0.199294\n",
      "Train Epoch: 10 [42800/50000 (86%)]\tLoss: 1.787966\n",
      "Train Epoch: 10 [43200/50000 (86%)]\tLoss: 0.536959\n",
      "Train Epoch: 10 [43600/50000 (87%)]\tLoss: 0.504843\n",
      "Train Epoch: 10 [44000/50000 (88%)]\tLoss: 0.340521\n",
      "Train Epoch: 10 [44400/50000 (89%)]\tLoss: 0.113641\n",
      "Train Epoch: 10 [44800/50000 (90%)]\tLoss: 0.778598\n",
      "Train Epoch: 10 [45200/50000 (90%)]\tLoss: 0.247385\n",
      "Train Epoch: 10 [45600/50000 (91%)]\tLoss: 0.122421\n",
      "Train Epoch: 10 [46000/50000 (92%)]\tLoss: 2.095204\n",
      "Train Epoch: 10 [46400/50000 (93%)]\tLoss: 0.211800\n",
      "Train Epoch: 10 [46800/50000 (94%)]\tLoss: 0.060643\n",
      "Train Epoch: 10 [47200/50000 (94%)]\tLoss: 0.325877\n",
      "Train Epoch: 10 [47600/50000 (95%)]\tLoss: 0.053679\n",
      "Train Epoch: 10 [48000/50000 (96%)]\tLoss: 0.131239\n",
      "Train Epoch: 10 [48400/50000 (97%)]\tLoss: 0.956603\n",
      "Train Epoch: 10 [48800/50000 (98%)]\tLoss: 0.316893\n",
      "Train Epoch: 10 [49200/50000 (98%)]\tLoss: 2.206340\n",
      "Train Epoch: 10 [49600/50000 (99%)]\tLoss: 0.605009\n",
      "\n",
      "Test set: Average loss: 0.3529, Accuracy: 6216/10000 (62%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run training and testing for ten epochs\n",
    "for epoch in range(1, 11):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Experiment 2 (20/100 points): Changing Architecture**\n",
    "#### Vary the architecture of your baseline model and report how each change impacts the performance. Consider adding more convolutional layers, varying the number of filters in each convolutional layer, including dropout layers to reduce overfitting, and so forth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### I'll be adding another convolutional layer, a dropout layer and an extra dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layers for second experiment\n",
    "convolutional_layer = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1).to(gpu_device)   # 32 filters, 3x3 kernel and ReLU activation function, directed to the gpu processor\n",
    "convolutional_layer2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1).to(gpu_device)    # 128 filters, 3x3 kernel and ReLU activation function, directed to the gpu processor\n",
    "dropout_layer = nn.Dropout(0.25).to(gpu_device)   # Dropout layer with 25% probability, directed to the gpu processor\n",
    "max_pooling_layer = nn.MaxPool2d(2, 2).to(gpu_device)   # Max pooling layer with 2x2 pool size, directed to the gpu processor\n",
    "dense_layer = nn.Linear(64 * 16 * 16, 256).to(gpu_device)   # Dense layer with 256 units and ReLU activation, directed to the gpu processor\n",
    "dense_layer2 = nn.Linear(256, 128).to(gpu_device)   # Dense layer with 128 units and ReLU activation, directed to the gpu processor\n",
    "dense_output_layer = nn.Linear(128, 10).to(gpu_device)  # Dense output layer, transforming the output to a prediction of 10 classes, directed to the gpu processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "loss_criterion = torch.nn.NLLLoss()\n",
    "adam_optimizer = optim.Adam([{'params': convolutional_layer.parameters()},\n",
    "                        {'params': convolutional_layer2.parameters()},\n",
    "                        {'params': dropout_layer.parameters()},\n",
    "                        {'params': dense_layer.parameters()},\n",
    "                        {'params': dense_layer2.parameters()},\n",
    "                        {'params': dense_output_layer.parameters()}], lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "def train(epoch):\n",
    "    print(f'Training model for Experiment 2')\n",
    "    for batch_index, (data, target) in enumerate(cifar_train_loader):\n",
    "        data, target = data.to(gpu_device), target.to(gpu_device)\n",
    "        adam_optimizer.zero_grad()\n",
    "        tensor_x = relu(convolutional_layer(data))\n",
    "        tensor_x = relu(convolutional_layer2(tensor_x))\n",
    "        tensor_x = max_pooling_layer(tensor_x)\n",
    "        tensor_x = tensor_x.view(-1, 64 * 16 * 16)  # Flatten layer\n",
    "        tensor_x = relu(dense_layer(tensor_x))\n",
    "        tensor_x = dropout_layer(tensor_x)\n",
    "        tensor_x = relu(dense_layer2(tensor_x))\n",
    "        tensor_x = dropout_layer(tensor_x)\n",
    "        tensor_x = dense_output_layer(tensor_x)\n",
    "        training_loss = log_softmax(tensor_x, dim=1)  # Apply log-softmax\n",
    "        training_loss = loss_criterion(training_loss, target)\n",
    "        training_loss.backward()\n",
    "        adam_optimizer.step()\n",
    "        if batch_index % 100 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_index * len(data)}/{len(cifar_train_loader.dataset)} ({100. * batch_index / len(cifar_train_loader):.0f}%)]\\tLoss: {training_loss.item():.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the model\n",
    "def test():\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    print(f'Testing model for Experiment 2')\n",
    "    with torch.no_grad():\n",
    "        for data, target in cifar_test_loader:\n",
    "            data, target = data.to(gpu_device), target.to(gpu_device)\n",
    "            tensor_x = relu(convolutional_layer(data))\n",
    "            tensor_x = relu(convolutional_layer2(tensor_x))\n",
    "            tensor_x = max_pooling_layer(tensor_x)\n",
    "            tensor_x = tensor_x.view(-1, 64 * 16 * 16)  # Flatten layer\n",
    "            tensor_x = relu(dense_layer(tensor_x))\n",
    "            tensor_x = dropout_layer(tensor_x)\n",
    "            tensor_x = relu(dense_layer2(tensor_x))\n",
    "            tensor_x = dropout_layer(tensor_x)\n",
    "            tensor_x = dense_output_layer(tensor_x)\n",
    "            test_loss_prob = log_softmax(tensor_x, dim=1)  # Apply log-softmax\n",
    "            test_loss += loss_criterion(test_loss_prob, target).item()\n",
    "            pred = test_loss_prob.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(cifar_test_loader.dataset)\n",
    "    accuracy = 100. * correct / len(cifar_test_loader.dataset)\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(cifar_test_loader.dataset)} ({accuracy:.0f}%)\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Experiment 2\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.329494\n",
      "Train Epoch: 1 [400/50000 (1%)]\tLoss: 2.180754\n",
      "Train Epoch: 1 [800/50000 (2%)]\tLoss: 2.104815\n",
      "Train Epoch: 1 [1200/50000 (2%)]\tLoss: 2.908323\n",
      "Train Epoch: 1 [1600/50000 (3%)]\tLoss: 1.951336\n",
      "Train Epoch: 1 [2000/50000 (4%)]\tLoss: 2.084753\n",
      "Train Epoch: 1 [2400/50000 (5%)]\tLoss: 1.583623\n",
      "Train Epoch: 1 [2800/50000 (6%)]\tLoss: 1.386564\n",
      "Train Epoch: 1 [3200/50000 (6%)]\tLoss: 1.791248\n",
      "Train Epoch: 1 [3600/50000 (7%)]\tLoss: 1.532466\n",
      "Train Epoch: 1 [4000/50000 (8%)]\tLoss: 1.203086\n",
      "Train Epoch: 1 [4400/50000 (9%)]\tLoss: 1.517516\n",
      "Train Epoch: 1 [4800/50000 (10%)]\tLoss: 1.455309\n",
      "Train Epoch: 1 [5200/50000 (10%)]\tLoss: 1.708532\n",
      "Train Epoch: 1 [5600/50000 (11%)]\tLoss: 1.796798\n",
      "Train Epoch: 1 [6000/50000 (12%)]\tLoss: 1.274584\n",
      "Train Epoch: 1 [6400/50000 (13%)]\tLoss: 1.042068\n",
      "Train Epoch: 1 [6800/50000 (14%)]\tLoss: 1.941566\n",
      "Train Epoch: 1 [7200/50000 (14%)]\tLoss: 1.806074\n",
      "Train Epoch: 1 [7600/50000 (15%)]\tLoss: 0.756081\n",
      "Train Epoch: 1 [8000/50000 (16%)]\tLoss: 1.674940\n",
      "Train Epoch: 1 [8400/50000 (17%)]\tLoss: 0.981367\n",
      "Train Epoch: 1 [8800/50000 (18%)]\tLoss: 1.564961\n",
      "Train Epoch: 1 [9200/50000 (18%)]\tLoss: 1.218793\n",
      "Train Epoch: 1 [9600/50000 (19%)]\tLoss: 1.386508\n",
      "Train Epoch: 1 [10000/50000 (20%)]\tLoss: 1.300471\n",
      "Train Epoch: 1 [10400/50000 (21%)]\tLoss: 0.846142\n",
      "Train Epoch: 1 [10800/50000 (22%)]\tLoss: 1.725774\n",
      "Train Epoch: 1 [11200/50000 (22%)]\tLoss: 1.292894\n",
      "Train Epoch: 1 [11600/50000 (23%)]\tLoss: 1.110286\n",
      "Train Epoch: 1 [12000/50000 (24%)]\tLoss: 1.480342\n",
      "Train Epoch: 1 [12400/50000 (25%)]\tLoss: 1.665648\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 1.659080\n",
      "Train Epoch: 1 [13200/50000 (26%)]\tLoss: 0.719374\n",
      "Train Epoch: 1 [13600/50000 (27%)]\tLoss: 1.942411\n",
      "Train Epoch: 1 [14000/50000 (28%)]\tLoss: 1.249031\n",
      "Train Epoch: 1 [14400/50000 (29%)]\tLoss: 1.469503\n",
      "Train Epoch: 1 [14800/50000 (30%)]\tLoss: 1.024944\n",
      "Train Epoch: 1 [15200/50000 (30%)]\tLoss: 1.010431\n",
      "Train Epoch: 1 [15600/50000 (31%)]\tLoss: 1.370628\n",
      "Train Epoch: 1 [16000/50000 (32%)]\tLoss: 1.266869\n",
      "Train Epoch: 1 [16400/50000 (33%)]\tLoss: 1.230278\n",
      "Train Epoch: 1 [16800/50000 (34%)]\tLoss: 1.037121\n",
      "Train Epoch: 1 [17200/50000 (34%)]\tLoss: 0.937321\n",
      "Train Epoch: 1 [17600/50000 (35%)]\tLoss: 1.711222\n",
      "Train Epoch: 1 [18000/50000 (36%)]\tLoss: 2.292149\n",
      "Train Epoch: 1 [18400/50000 (37%)]\tLoss: 0.549084\n",
      "Train Epoch: 1 [18800/50000 (38%)]\tLoss: 2.757884\n",
      "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 1.221265\n",
      "Train Epoch: 1 [19600/50000 (39%)]\tLoss: 2.091519\n",
      "Train Epoch: 1 [20000/50000 (40%)]\tLoss: 1.541635\n",
      "Train Epoch: 1 [20400/50000 (41%)]\tLoss: 1.119315\n",
      "Train Epoch: 1 [20800/50000 (42%)]\tLoss: 2.084475\n",
      "Train Epoch: 1 [21200/50000 (42%)]\tLoss: 1.075161\n",
      "Train Epoch: 1 [21600/50000 (43%)]\tLoss: 1.676064\n",
      "Train Epoch: 1 [22000/50000 (44%)]\tLoss: 1.179146\n",
      "Train Epoch: 1 [22400/50000 (45%)]\tLoss: 1.086320\n",
      "Train Epoch: 1 [22800/50000 (46%)]\tLoss: 0.872241\n",
      "Train Epoch: 1 [23200/50000 (46%)]\tLoss: 0.998039\n",
      "Train Epoch: 1 [23600/50000 (47%)]\tLoss: 1.177810\n",
      "Train Epoch: 1 [24000/50000 (48%)]\tLoss: 0.991282\n",
      "Train Epoch: 1 [24400/50000 (49%)]\tLoss: 0.742910\n",
      "Train Epoch: 1 [24800/50000 (50%)]\tLoss: 0.551194\n",
      "Train Epoch: 1 [25200/50000 (50%)]\tLoss: 2.114708\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 1.347815\n",
      "Train Epoch: 1 [26000/50000 (52%)]\tLoss: 0.618989\n",
      "Train Epoch: 1 [26400/50000 (53%)]\tLoss: 1.676964\n",
      "Train Epoch: 1 [26800/50000 (54%)]\tLoss: 1.587158\n",
      "Train Epoch: 1 [27200/50000 (54%)]\tLoss: 0.761883\n",
      "Train Epoch: 1 [27600/50000 (55%)]\tLoss: 1.395101\n",
      "Train Epoch: 1 [28000/50000 (56%)]\tLoss: 0.306499\n",
      "Train Epoch: 1 [28400/50000 (57%)]\tLoss: 3.746270\n",
      "Train Epoch: 1 [28800/50000 (58%)]\tLoss: 1.256789\n",
      "Train Epoch: 1 [29200/50000 (58%)]\tLoss: 1.194530\n",
      "Train Epoch: 1 [29600/50000 (59%)]\tLoss: 1.250681\n",
      "Train Epoch: 1 [30000/50000 (60%)]\tLoss: 1.044327\n",
      "Train Epoch: 1 [30400/50000 (61%)]\tLoss: 1.019759\n",
      "Train Epoch: 1 [30800/50000 (62%)]\tLoss: 1.009916\n",
      "Train Epoch: 1 [31200/50000 (62%)]\tLoss: 0.085180\n",
      "Train Epoch: 1 [31600/50000 (63%)]\tLoss: 1.170809\n",
      "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 1.669972\n",
      "Train Epoch: 1 [32400/50000 (65%)]\tLoss: 0.656465\n",
      "Train Epoch: 1 [32800/50000 (66%)]\tLoss: 1.414095\n",
      "Train Epoch: 1 [33200/50000 (66%)]\tLoss: 0.791044\n",
      "Train Epoch: 1 [33600/50000 (67%)]\tLoss: 1.166680\n",
      "Train Epoch: 1 [34000/50000 (68%)]\tLoss: 0.577517\n",
      "Train Epoch: 1 [34400/50000 (69%)]\tLoss: 1.113933\n",
      "Train Epoch: 1 [34800/50000 (70%)]\tLoss: 2.422920\n",
      "Train Epoch: 1 [35200/50000 (70%)]\tLoss: 1.223060\n",
      "Train Epoch: 1 [35600/50000 (71%)]\tLoss: 0.946499\n",
      "Train Epoch: 1 [36000/50000 (72%)]\tLoss: 1.042824\n",
      "Train Epoch: 1 [36400/50000 (73%)]\tLoss: 0.967052\n",
      "Train Epoch: 1 [36800/50000 (74%)]\tLoss: 1.390273\n",
      "Train Epoch: 1 [37200/50000 (74%)]\tLoss: 0.957953\n",
      "Train Epoch: 1 [37600/50000 (75%)]\tLoss: 2.113775\n",
      "Train Epoch: 1 [38000/50000 (76%)]\tLoss: 0.903525\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 1.367470\n",
      "Train Epoch: 1 [38800/50000 (78%)]\tLoss: 0.398179\n",
      "Train Epoch: 1 [39200/50000 (78%)]\tLoss: 1.370214\n",
      "Train Epoch: 1 [39600/50000 (79%)]\tLoss: 1.419561\n",
      "Train Epoch: 1 [40000/50000 (80%)]\tLoss: 0.995167\n",
      "Train Epoch: 1 [40400/50000 (81%)]\tLoss: 0.496078\n",
      "Train Epoch: 1 [40800/50000 (82%)]\tLoss: 1.069223\n",
      "Train Epoch: 1 [41200/50000 (82%)]\tLoss: 1.469565\n",
      "Train Epoch: 1 [41600/50000 (83%)]\tLoss: 0.517998\n",
      "Train Epoch: 1 [42000/50000 (84%)]\tLoss: 1.520399\n",
      "Train Epoch: 1 [42400/50000 (85%)]\tLoss: 1.929083\n",
      "Train Epoch: 1 [42800/50000 (86%)]\tLoss: 1.169303\n",
      "Train Epoch: 1 [43200/50000 (86%)]\tLoss: 0.586594\n",
      "Train Epoch: 1 [43600/50000 (87%)]\tLoss: 1.279653\n",
      "Train Epoch: 1 [44000/50000 (88%)]\tLoss: 0.912783\n",
      "Train Epoch: 1 [44400/50000 (89%)]\tLoss: 1.440314\n",
      "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 1.278442\n",
      "Train Epoch: 1 [45200/50000 (90%)]\tLoss: 0.768916\n",
      "Train Epoch: 1 [45600/50000 (91%)]\tLoss: 1.682143\n",
      "Train Epoch: 1 [46000/50000 (92%)]\tLoss: 2.585176\n",
      "Train Epoch: 1 [46400/50000 (93%)]\tLoss: 1.583680\n",
      "Train Epoch: 1 [46800/50000 (94%)]\tLoss: 1.694941\n",
      "Train Epoch: 1 [47200/50000 (94%)]\tLoss: 1.433812\n",
      "Train Epoch: 1 [47600/50000 (95%)]\tLoss: 1.007435\n",
      "Train Epoch: 1 [48000/50000 (96%)]\tLoss: 1.536608\n",
      "Train Epoch: 1 [48400/50000 (97%)]\tLoss: 0.328277\n",
      "Train Epoch: 1 [48800/50000 (98%)]\tLoss: 1.423448\n",
      "Train Epoch: 1 [49200/50000 (98%)]\tLoss: 1.729628\n",
      "Train Epoch: 1 [49600/50000 (99%)]\tLoss: 0.602592\n",
      "Testing model for Experiment 2\n",
      "\n",
      "Test set: Average loss: 0.3131, Accuracy: 5802/10000 (58%)\n",
      "\n",
      "Training model for Experiment 2\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.413790\n",
      "Train Epoch: 2 [400/50000 (1%)]\tLoss: 1.276519\n",
      "Train Epoch: 2 [800/50000 (2%)]\tLoss: 0.547415\n",
      "Train Epoch: 2 [1200/50000 (2%)]\tLoss: 0.864747\n",
      "Train Epoch: 2 [1600/50000 (3%)]\tLoss: 1.180455\n",
      "Train Epoch: 2 [2000/50000 (4%)]\tLoss: 0.789250\n",
      "Train Epoch: 2 [2400/50000 (5%)]\tLoss: 2.882206\n",
      "Train Epoch: 2 [2800/50000 (6%)]\tLoss: 0.864895\n",
      "Train Epoch: 2 [3200/50000 (6%)]\tLoss: 1.269779\n",
      "Train Epoch: 2 [3600/50000 (7%)]\tLoss: 0.936794\n",
      "Train Epoch: 2 [4000/50000 (8%)]\tLoss: 0.554781\n",
      "Train Epoch: 2 [4400/50000 (9%)]\tLoss: 0.998218\n",
      "Train Epoch: 2 [4800/50000 (10%)]\tLoss: 2.624208\n",
      "Train Epoch: 2 [5200/50000 (10%)]\tLoss: 0.871886\n",
      "Train Epoch: 2 [5600/50000 (11%)]\tLoss: 1.299767\n",
      "Train Epoch: 2 [6000/50000 (12%)]\tLoss: 0.498337\n",
      "Train Epoch: 2 [6400/50000 (13%)]\tLoss: 0.445849\n",
      "Train Epoch: 2 [6800/50000 (14%)]\tLoss: 0.536888\n",
      "Train Epoch: 2 [7200/50000 (14%)]\tLoss: 1.433478\n",
      "Train Epoch: 2 [7600/50000 (15%)]\tLoss: 1.585716\n",
      "Train Epoch: 2 [8000/50000 (16%)]\tLoss: 0.659920\n",
      "Train Epoch: 2 [8400/50000 (17%)]\tLoss: 1.363785\n",
      "Train Epoch: 2 [8800/50000 (18%)]\tLoss: 1.169466\n",
      "Train Epoch: 2 [9200/50000 (18%)]\tLoss: 0.715094\n",
      "Train Epoch: 2 [9600/50000 (19%)]\tLoss: 1.249671\n",
      "Train Epoch: 2 [10000/50000 (20%)]\tLoss: 2.545855\n",
      "Train Epoch: 2 [10400/50000 (21%)]\tLoss: 1.009489\n",
      "Train Epoch: 2 [10800/50000 (22%)]\tLoss: 1.707463\n",
      "Train Epoch: 2 [11200/50000 (22%)]\tLoss: 0.636759\n",
      "Train Epoch: 2 [11600/50000 (23%)]\tLoss: 0.220101\n",
      "Train Epoch: 2 [12000/50000 (24%)]\tLoss: 1.839412\n",
      "Train Epoch: 2 [12400/50000 (25%)]\tLoss: 1.489188\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 1.393784\n",
      "Train Epoch: 2 [13200/50000 (26%)]\tLoss: 1.240400\n",
      "Train Epoch: 2 [13600/50000 (27%)]\tLoss: 0.806701\n",
      "Train Epoch: 2 [14000/50000 (28%)]\tLoss: 0.820613\n",
      "Train Epoch: 2 [14400/50000 (29%)]\tLoss: 1.630486\n",
      "Train Epoch: 2 [14800/50000 (30%)]\tLoss: 1.703603\n",
      "Train Epoch: 2 [15200/50000 (30%)]\tLoss: 1.845634\n",
      "Train Epoch: 2 [15600/50000 (31%)]\tLoss: 0.921058\n",
      "Train Epoch: 2 [16000/50000 (32%)]\tLoss: 1.348931\n",
      "Train Epoch: 2 [16400/50000 (33%)]\tLoss: 0.795656\n",
      "Train Epoch: 2 [16800/50000 (34%)]\tLoss: 0.829553\n",
      "Train Epoch: 2 [17200/50000 (34%)]\tLoss: 1.400278\n",
      "Train Epoch: 2 [17600/50000 (35%)]\tLoss: 1.380767\n",
      "Train Epoch: 2 [18000/50000 (36%)]\tLoss: 0.692146\n",
      "Train Epoch: 2 [18400/50000 (37%)]\tLoss: 0.863035\n",
      "Train Epoch: 2 [18800/50000 (38%)]\tLoss: 1.151055\n",
      "Train Epoch: 2 [19200/50000 (38%)]\tLoss: 0.832144\n",
      "Train Epoch: 2 [19600/50000 (39%)]\tLoss: 1.310716\n",
      "Train Epoch: 2 [20000/50000 (40%)]\tLoss: 0.684162\n",
      "Train Epoch: 2 [20400/50000 (41%)]\tLoss: 0.457495\n",
      "Train Epoch: 2 [20800/50000 (42%)]\tLoss: 0.149571\n",
      "Train Epoch: 2 [21200/50000 (42%)]\tLoss: 0.730694\n",
      "Train Epoch: 2 [21600/50000 (43%)]\tLoss: 0.533032\n",
      "Train Epoch: 2 [22000/50000 (44%)]\tLoss: 2.419465\n",
      "Train Epoch: 2 [22400/50000 (45%)]\tLoss: 0.659719\n",
      "Train Epoch: 2 [22800/50000 (46%)]\tLoss: 0.881721\n",
      "Train Epoch: 2 [23200/50000 (46%)]\tLoss: 1.700773\n",
      "Train Epoch: 2 [23600/50000 (47%)]\tLoss: 0.336636\n",
      "Train Epoch: 2 [24000/50000 (48%)]\tLoss: 0.935759\n",
      "Train Epoch: 2 [24400/50000 (49%)]\tLoss: 1.363002\n",
      "Train Epoch: 2 [24800/50000 (50%)]\tLoss: 1.384132\n",
      "Train Epoch: 2 [25200/50000 (50%)]\tLoss: 0.860414\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 0.829900\n",
      "Train Epoch: 2 [26000/50000 (52%)]\tLoss: 1.063101\n",
      "Train Epoch: 2 [26400/50000 (53%)]\tLoss: 0.343868\n",
      "Train Epoch: 2 [26800/50000 (54%)]\tLoss: 0.595704\n",
      "Train Epoch: 2 [27200/50000 (54%)]\tLoss: 1.721926\n",
      "Train Epoch: 2 [27600/50000 (55%)]\tLoss: 1.009830\n",
      "Train Epoch: 2 [28000/50000 (56%)]\tLoss: 1.138442\n",
      "Train Epoch: 2 [28400/50000 (57%)]\tLoss: 1.281741\n",
      "Train Epoch: 2 [28800/50000 (58%)]\tLoss: 1.128325\n",
      "Train Epoch: 2 [29200/50000 (58%)]\tLoss: 1.632643\n",
      "Train Epoch: 2 [29600/50000 (59%)]\tLoss: 1.099977\n",
      "Train Epoch: 2 [30000/50000 (60%)]\tLoss: 1.776506\n",
      "Train Epoch: 2 [30400/50000 (61%)]\tLoss: 0.357515\n",
      "Train Epoch: 2 [30800/50000 (62%)]\tLoss: 1.225750\n",
      "Train Epoch: 2 [31200/50000 (62%)]\tLoss: 1.447499\n",
      "Train Epoch: 2 [31600/50000 (63%)]\tLoss: 1.172044\n",
      "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 1.377912\n",
      "Train Epoch: 2 [32400/50000 (65%)]\tLoss: 0.595766\n",
      "Train Epoch: 2 [32800/50000 (66%)]\tLoss: 0.617871\n",
      "Train Epoch: 2 [33200/50000 (66%)]\tLoss: 0.598311\n",
      "Train Epoch: 2 [33600/50000 (67%)]\tLoss: 0.634205\n",
      "Train Epoch: 2 [34000/50000 (68%)]\tLoss: 1.266078\n",
      "Train Epoch: 2 [34400/50000 (69%)]\tLoss: 1.157516\n",
      "Train Epoch: 2 [34800/50000 (70%)]\tLoss: 2.762565\n",
      "Train Epoch: 2 [35200/50000 (70%)]\tLoss: 0.744353\n",
      "Train Epoch: 2 [35600/50000 (71%)]\tLoss: 1.963770\n",
      "Train Epoch: 2 [36000/50000 (72%)]\tLoss: 1.477425\n",
      "Train Epoch: 2 [36400/50000 (73%)]\tLoss: 1.622204\n",
      "Train Epoch: 2 [36800/50000 (74%)]\tLoss: 1.070178\n",
      "Train Epoch: 2 [37200/50000 (74%)]\tLoss: 1.194100\n",
      "Train Epoch: 2 [37600/50000 (75%)]\tLoss: 2.451030\n",
      "Train Epoch: 2 [38000/50000 (76%)]\tLoss: 0.648095\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 0.893993\n",
      "Train Epoch: 2 [38800/50000 (78%)]\tLoss: 1.197427\n",
      "Train Epoch: 2 [39200/50000 (78%)]\tLoss: 0.760815\n",
      "Train Epoch: 2 [39600/50000 (79%)]\tLoss: 1.113999\n",
      "Train Epoch: 2 [40000/50000 (80%)]\tLoss: 1.625077\n",
      "Train Epoch: 2 [40400/50000 (81%)]\tLoss: 1.664438\n",
      "Train Epoch: 2 [40800/50000 (82%)]\tLoss: 1.063161\n",
      "Train Epoch: 2 [41200/50000 (82%)]\tLoss: 0.842150\n",
      "Train Epoch: 2 [41600/50000 (83%)]\tLoss: 2.257822\n",
      "Train Epoch: 2 [42000/50000 (84%)]\tLoss: 0.825351\n",
      "Train Epoch: 2 [42400/50000 (85%)]\tLoss: 1.205625\n",
      "Train Epoch: 2 [42800/50000 (86%)]\tLoss: 0.817061\n",
      "Train Epoch: 2 [43200/50000 (86%)]\tLoss: 2.163338\n",
      "Train Epoch: 2 [43600/50000 (87%)]\tLoss: 1.552790\n",
      "Train Epoch: 2 [44000/50000 (88%)]\tLoss: 1.335967\n",
      "Train Epoch: 2 [44400/50000 (89%)]\tLoss: 1.111343\n",
      "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 0.988177\n",
      "Train Epoch: 2 [45200/50000 (90%)]\tLoss: 0.626247\n",
      "Train Epoch: 2 [45600/50000 (91%)]\tLoss: 2.045439\n",
      "Train Epoch: 2 [46000/50000 (92%)]\tLoss: 0.776463\n",
      "Train Epoch: 2 [46400/50000 (93%)]\tLoss: 2.584754\n",
      "Train Epoch: 2 [46800/50000 (94%)]\tLoss: 1.896955\n",
      "Train Epoch: 2 [47200/50000 (94%)]\tLoss: 0.776536\n",
      "Train Epoch: 2 [47600/50000 (95%)]\tLoss: 0.960661\n",
      "Train Epoch: 2 [48000/50000 (96%)]\tLoss: 0.401546\n",
      "Train Epoch: 2 [48400/50000 (97%)]\tLoss: 1.723550\n",
      "Train Epoch: 2 [48800/50000 (98%)]\tLoss: 0.910353\n",
      "Train Epoch: 2 [49200/50000 (98%)]\tLoss: 0.389743\n",
      "Train Epoch: 2 [49600/50000 (99%)]\tLoss: 0.850541\n",
      "Testing model for Experiment 2\n",
      "\n",
      "Test set: Average loss: 0.3025, Accuracy: 5817/10000 (58%)\n",
      "\n",
      "Training model for Experiment 2\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 0.761197\n",
      "Train Epoch: 3 [400/50000 (1%)]\tLoss: 0.040810\n",
      "Train Epoch: 3 [800/50000 (2%)]\tLoss: 1.412188\n",
      "Train Epoch: 3 [1200/50000 (2%)]\tLoss: 0.546405\n",
      "Train Epoch: 3 [1600/50000 (3%)]\tLoss: 1.450801\n",
      "Train Epoch: 3 [2000/50000 (4%)]\tLoss: 0.727613\n",
      "Train Epoch: 3 [2400/50000 (5%)]\tLoss: 0.963292\n",
      "Train Epoch: 3 [2800/50000 (6%)]\tLoss: 1.403374\n",
      "Train Epoch: 3 [3200/50000 (6%)]\tLoss: 0.850963\n",
      "Train Epoch: 3 [3600/50000 (7%)]\tLoss: 1.911575\n",
      "Train Epoch: 3 [4000/50000 (8%)]\tLoss: 1.608505\n",
      "Train Epoch: 3 [4400/50000 (9%)]\tLoss: 1.346153\n",
      "Train Epoch: 3 [4800/50000 (10%)]\tLoss: 0.387277\n",
      "Train Epoch: 3 [5200/50000 (10%)]\tLoss: 0.680158\n",
      "Train Epoch: 3 [5600/50000 (11%)]\tLoss: 1.252529\n",
      "Train Epoch: 3 [6000/50000 (12%)]\tLoss: 1.156721\n",
      "Train Epoch: 3 [6400/50000 (13%)]\tLoss: 0.921006\n",
      "Train Epoch: 3 [6800/50000 (14%)]\tLoss: 0.503337\n",
      "Train Epoch: 3 [7200/50000 (14%)]\tLoss: 0.921513\n",
      "Train Epoch: 3 [7600/50000 (15%)]\tLoss: 1.173054\n",
      "Train Epoch: 3 [8000/50000 (16%)]\tLoss: 1.760760\n",
      "Train Epoch: 3 [8400/50000 (17%)]\tLoss: 1.230827\n",
      "Train Epoch: 3 [8800/50000 (18%)]\tLoss: 1.935195\n",
      "Train Epoch: 3 [9200/50000 (18%)]\tLoss: 1.347355\n",
      "Train Epoch: 3 [9600/50000 (19%)]\tLoss: 0.869021\n",
      "Train Epoch: 3 [10000/50000 (20%)]\tLoss: 1.590003\n",
      "Train Epoch: 3 [10400/50000 (21%)]\tLoss: 2.768849\n",
      "Train Epoch: 3 [10800/50000 (22%)]\tLoss: 0.352943\n",
      "Train Epoch: 3 [11200/50000 (22%)]\tLoss: 1.238461\n",
      "Train Epoch: 3 [11600/50000 (23%)]\tLoss: 2.184367\n",
      "Train Epoch: 3 [12000/50000 (24%)]\tLoss: 0.090049\n",
      "Train Epoch: 3 [12400/50000 (25%)]\tLoss: 0.159478\n",
      "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 0.945160\n",
      "Train Epoch: 3 [13200/50000 (26%)]\tLoss: 0.863753\n",
      "Train Epoch: 3 [13600/50000 (27%)]\tLoss: 0.670188\n",
      "Train Epoch: 3 [14000/50000 (28%)]\tLoss: 1.555840\n",
      "Train Epoch: 3 [14400/50000 (29%)]\tLoss: 0.570871\n",
      "Train Epoch: 3 [14800/50000 (30%)]\tLoss: 0.711429\n",
      "Train Epoch: 3 [15200/50000 (30%)]\tLoss: 1.624107\n",
      "Train Epoch: 3 [15600/50000 (31%)]\tLoss: 1.420346\n",
      "Train Epoch: 3 [16000/50000 (32%)]\tLoss: 1.468524\n",
      "Train Epoch: 3 [16400/50000 (33%)]\tLoss: 0.610899\n",
      "Train Epoch: 3 [16800/50000 (34%)]\tLoss: 1.163169\n",
      "Train Epoch: 3 [17200/50000 (34%)]\tLoss: 0.707311\n",
      "Train Epoch: 3 [17600/50000 (35%)]\tLoss: 1.083729\n",
      "Train Epoch: 3 [18000/50000 (36%)]\tLoss: 0.007866\n",
      "Train Epoch: 3 [18400/50000 (37%)]\tLoss: 0.932317\n",
      "Train Epoch: 3 [18800/50000 (38%)]\tLoss: 3.602492\n",
      "Train Epoch: 3 [19200/50000 (38%)]\tLoss: 0.662985\n",
      "Train Epoch: 3 [19600/50000 (39%)]\tLoss: 1.182585\n",
      "Train Epoch: 3 [20000/50000 (40%)]\tLoss: 1.666564\n",
      "Train Epoch: 3 [20400/50000 (41%)]\tLoss: 0.472450\n",
      "Train Epoch: 3 [20800/50000 (42%)]\tLoss: 2.566656\n",
      "Train Epoch: 3 [21200/50000 (42%)]\tLoss: 0.672075\n",
      "Train Epoch: 3 [21600/50000 (43%)]\tLoss: 0.311850\n",
      "Train Epoch: 3 [22000/50000 (44%)]\tLoss: 0.496676\n",
      "Train Epoch: 3 [22400/50000 (45%)]\tLoss: 1.238851\n",
      "Train Epoch: 3 [22800/50000 (46%)]\tLoss: 0.526386\n",
      "Train Epoch: 3 [23200/50000 (46%)]\tLoss: 0.603616\n",
      "Train Epoch: 3 [23600/50000 (47%)]\tLoss: 1.759412\n",
      "Train Epoch: 3 [24000/50000 (48%)]\tLoss: 0.275309\n",
      "Train Epoch: 3 [24400/50000 (49%)]\tLoss: 1.058881\n",
      "Train Epoch: 3 [24800/50000 (50%)]\tLoss: 1.328509\n",
      "Train Epoch: 3 [25200/50000 (50%)]\tLoss: 0.645943\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 0.637590\n",
      "Train Epoch: 3 [26000/50000 (52%)]\tLoss: 0.754200\n",
      "Train Epoch: 3 [26400/50000 (53%)]\tLoss: 0.301192\n",
      "Train Epoch: 3 [26800/50000 (54%)]\tLoss: 1.047443\n",
      "Train Epoch: 3 [27200/50000 (54%)]\tLoss: 0.745378\n",
      "Train Epoch: 3 [27600/50000 (55%)]\tLoss: 2.036578\n",
      "Train Epoch: 3 [28000/50000 (56%)]\tLoss: 0.374610\n",
      "Train Epoch: 3 [28400/50000 (57%)]\tLoss: 0.163532\n",
      "Train Epoch: 3 [28800/50000 (58%)]\tLoss: 0.149430\n",
      "Train Epoch: 3 [29200/50000 (58%)]\tLoss: 0.787323\n",
      "Train Epoch: 3 [29600/50000 (59%)]\tLoss: 0.319109\n",
      "Train Epoch: 3 [30000/50000 (60%)]\tLoss: 0.514955\n",
      "Train Epoch: 3 [30400/50000 (61%)]\tLoss: 0.230053\n",
      "Train Epoch: 3 [30800/50000 (62%)]\tLoss: 1.531896\n",
      "Train Epoch: 3 [31200/50000 (62%)]\tLoss: 1.175133\n",
      "Train Epoch: 3 [31600/50000 (63%)]\tLoss: 0.601905\n",
      "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 1.780083\n",
      "Train Epoch: 3 [32400/50000 (65%)]\tLoss: 0.578386\n",
      "Train Epoch: 3 [32800/50000 (66%)]\tLoss: 0.947471\n",
      "Train Epoch: 3 [33200/50000 (66%)]\tLoss: 1.736011\n",
      "Train Epoch: 3 [33600/50000 (67%)]\tLoss: 1.071306\n",
      "Train Epoch: 3 [34000/50000 (68%)]\tLoss: 0.594344\n",
      "Train Epoch: 3 [34400/50000 (69%)]\tLoss: 0.373057\n",
      "Train Epoch: 3 [34800/50000 (70%)]\tLoss: 0.502809\n",
      "Train Epoch: 3 [35200/50000 (70%)]\tLoss: 2.288283\n",
      "Train Epoch: 3 [35600/50000 (71%)]\tLoss: 1.222986\n",
      "Train Epoch: 3 [36000/50000 (72%)]\tLoss: 0.741810\n",
      "Train Epoch: 3 [36400/50000 (73%)]\tLoss: 0.902133\n",
      "Train Epoch: 3 [36800/50000 (74%)]\tLoss: 0.460208\n",
      "Train Epoch: 3 [37200/50000 (74%)]\tLoss: 1.470023\n",
      "Train Epoch: 3 [37600/50000 (75%)]\tLoss: 1.004436\n",
      "Train Epoch: 3 [38000/50000 (76%)]\tLoss: 0.643941\n",
      "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 0.855761\n",
      "Train Epoch: 3 [38800/50000 (78%)]\tLoss: 0.262014\n",
      "Train Epoch: 3 [39200/50000 (78%)]\tLoss: 2.124935\n",
      "Train Epoch: 3 [39600/50000 (79%)]\tLoss: 1.322976\n",
      "Train Epoch: 3 [40000/50000 (80%)]\tLoss: 0.403278\n",
      "Train Epoch: 3 [40400/50000 (81%)]\tLoss: 0.535896\n",
      "Train Epoch: 3 [40800/50000 (82%)]\tLoss: 1.036665\n",
      "Train Epoch: 3 [41200/50000 (82%)]\tLoss: 0.872847\n",
      "Train Epoch: 3 [41600/50000 (83%)]\tLoss: 0.668504\n",
      "Train Epoch: 3 [42000/50000 (84%)]\tLoss: 0.090414\n",
      "Train Epoch: 3 [42400/50000 (85%)]\tLoss: 1.315120\n",
      "Train Epoch: 3 [42800/50000 (86%)]\tLoss: 1.086051\n",
      "Train Epoch: 3 [43200/50000 (86%)]\tLoss: 0.721376\n",
      "Train Epoch: 3 [43600/50000 (87%)]\tLoss: 0.864769\n",
      "Train Epoch: 3 [44000/50000 (88%)]\tLoss: 1.267336\n",
      "Train Epoch: 3 [44400/50000 (89%)]\tLoss: 0.934094\n",
      "Train Epoch: 3 [44800/50000 (90%)]\tLoss: 1.933394\n",
      "Train Epoch: 3 [45200/50000 (90%)]\tLoss: 1.192779\n",
      "Train Epoch: 3 [45600/50000 (91%)]\tLoss: 1.143913\n",
      "Train Epoch: 3 [46000/50000 (92%)]\tLoss: 0.850235\n",
      "Train Epoch: 3 [46400/50000 (93%)]\tLoss: 1.441660\n",
      "Train Epoch: 3 [46800/50000 (94%)]\tLoss: 0.933792\n",
      "Train Epoch: 3 [47200/50000 (94%)]\tLoss: 0.406255\n",
      "Train Epoch: 3 [47600/50000 (95%)]\tLoss: 0.870450\n",
      "Train Epoch: 3 [48000/50000 (96%)]\tLoss: 1.205309\n",
      "Train Epoch: 3 [48400/50000 (97%)]\tLoss: 0.712219\n",
      "Train Epoch: 3 [48800/50000 (98%)]\tLoss: 0.543717\n",
      "Train Epoch: 3 [49200/50000 (98%)]\tLoss: 1.130105\n",
      "Train Epoch: 3 [49600/50000 (99%)]\tLoss: 1.113633\n",
      "Testing model for Experiment 2\n",
      "\n",
      "Test set: Average loss: 0.2952, Accuracy: 6001/10000 (60%)\n",
      "\n",
      "Training model for Experiment 2\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 1.931412\n",
      "Train Epoch: 4 [400/50000 (1%)]\tLoss: 0.028783\n",
      "Train Epoch: 4 [800/50000 (2%)]\tLoss: 0.550562\n",
      "Train Epoch: 4 [1200/50000 (2%)]\tLoss: 1.127496\n",
      "Train Epoch: 4 [1600/50000 (3%)]\tLoss: 0.518711\n",
      "Train Epoch: 4 [2000/50000 (4%)]\tLoss: 1.042804\n",
      "Train Epoch: 4 [2400/50000 (5%)]\tLoss: 0.573405\n",
      "Train Epoch: 4 [2800/50000 (6%)]\tLoss: 1.695081\n",
      "Train Epoch: 4 [3200/50000 (6%)]\tLoss: 0.150050\n",
      "Train Epoch: 4 [3600/50000 (7%)]\tLoss: 1.647916\n",
      "Train Epoch: 4 [4000/50000 (8%)]\tLoss: 0.654512\n",
      "Train Epoch: 4 [4400/50000 (9%)]\tLoss: 1.335495\n",
      "Train Epoch: 4 [4800/50000 (10%)]\tLoss: 1.548995\n",
      "Train Epoch: 4 [5200/50000 (10%)]\tLoss: 0.081907\n",
      "Train Epoch: 4 [5600/50000 (11%)]\tLoss: 0.121806\n",
      "Train Epoch: 4 [6000/50000 (12%)]\tLoss: 2.385044\n",
      "Train Epoch: 4 [6400/50000 (13%)]\tLoss: 1.518327\n",
      "Train Epoch: 4 [6800/50000 (14%)]\tLoss: 1.103376\n",
      "Train Epoch: 4 [7200/50000 (14%)]\tLoss: 0.410088\n",
      "Train Epoch: 4 [7600/50000 (15%)]\tLoss: 1.007361\n",
      "Train Epoch: 4 [8000/50000 (16%)]\tLoss: 0.822601\n",
      "Train Epoch: 4 [8400/50000 (17%)]\tLoss: 0.451436\n",
      "Train Epoch: 4 [8800/50000 (18%)]\tLoss: 1.252208\n",
      "Train Epoch: 4 [9200/50000 (18%)]\tLoss: 1.882373\n",
      "Train Epoch: 4 [9600/50000 (19%)]\tLoss: 0.108231\n",
      "Train Epoch: 4 [10000/50000 (20%)]\tLoss: 0.605672\n",
      "Train Epoch: 4 [10400/50000 (21%)]\tLoss: 1.120517\n",
      "Train Epoch: 4 [10800/50000 (22%)]\tLoss: 0.537396\n",
      "Train Epoch: 4 [11200/50000 (22%)]\tLoss: 1.032760\n",
      "Train Epoch: 4 [11600/50000 (23%)]\tLoss: 0.659935\n",
      "Train Epoch: 4 [12000/50000 (24%)]\tLoss: 0.357161\n",
      "Train Epoch: 4 [12400/50000 (25%)]\tLoss: 2.503965\n",
      "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 0.507718\n",
      "Train Epoch: 4 [13200/50000 (26%)]\tLoss: 0.596417\n",
      "Train Epoch: 4 [13600/50000 (27%)]\tLoss: 0.994773\n",
      "Train Epoch: 4 [14000/50000 (28%)]\tLoss: 0.701419\n",
      "Train Epoch: 4 [14400/50000 (29%)]\tLoss: 0.611266\n",
      "Train Epoch: 4 [14800/50000 (30%)]\tLoss: 1.680382\n",
      "Train Epoch: 4 [15200/50000 (30%)]\tLoss: 0.179846\n",
      "Train Epoch: 4 [15600/50000 (31%)]\tLoss: 1.774798\n",
      "Train Epoch: 4 [16000/50000 (32%)]\tLoss: 0.397481\n",
      "Train Epoch: 4 [16400/50000 (33%)]\tLoss: 1.170985\n",
      "Train Epoch: 4 [16800/50000 (34%)]\tLoss: 0.538508\n",
      "Train Epoch: 4 [17200/50000 (34%)]\tLoss: 1.274455\n",
      "Train Epoch: 4 [17600/50000 (35%)]\tLoss: 0.707302\n",
      "Train Epoch: 4 [18000/50000 (36%)]\tLoss: 1.491969\n",
      "Train Epoch: 4 [18400/50000 (37%)]\tLoss: 0.493706\n",
      "Train Epoch: 4 [18800/50000 (38%)]\tLoss: 0.928750\n",
      "Train Epoch: 4 [19200/50000 (38%)]\tLoss: 1.245934\n",
      "Train Epoch: 4 [19600/50000 (39%)]\tLoss: 1.285086\n",
      "Train Epoch: 4 [20000/50000 (40%)]\tLoss: 0.552421\n",
      "Train Epoch: 4 [20400/50000 (41%)]\tLoss: 0.793304\n",
      "Train Epoch: 4 [20800/50000 (42%)]\tLoss: 0.249331\n",
      "Train Epoch: 4 [21200/50000 (42%)]\tLoss: 0.662142\n",
      "Train Epoch: 4 [21600/50000 (43%)]\tLoss: 0.226545\n",
      "Train Epoch: 4 [22000/50000 (44%)]\tLoss: 0.595838\n",
      "Train Epoch: 4 [22400/50000 (45%)]\tLoss: 0.666189\n",
      "Train Epoch: 4 [22800/50000 (46%)]\tLoss: 0.401583\n",
      "Train Epoch: 4 [23200/50000 (46%)]\tLoss: 1.134734\n",
      "Train Epoch: 4 [23600/50000 (47%)]\tLoss: 0.226302\n",
      "Train Epoch: 4 [24000/50000 (48%)]\tLoss: 1.299718\n",
      "Train Epoch: 4 [24400/50000 (49%)]\tLoss: 0.778303\n",
      "Train Epoch: 4 [24800/50000 (50%)]\tLoss: 0.539506\n",
      "Train Epoch: 4 [25200/50000 (50%)]\tLoss: 0.602949\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 1.266978\n",
      "Train Epoch: 4 [26000/50000 (52%)]\tLoss: 0.792437\n",
      "Train Epoch: 4 [26400/50000 (53%)]\tLoss: 0.960827\n",
      "Train Epoch: 4 [26800/50000 (54%)]\tLoss: 0.302367\n",
      "Train Epoch: 4 [27200/50000 (54%)]\tLoss: 0.597224\n",
      "Train Epoch: 4 [27600/50000 (55%)]\tLoss: 0.501721\n",
      "Train Epoch: 4 [28000/50000 (56%)]\tLoss: 0.761973\n",
      "Train Epoch: 4 [28400/50000 (57%)]\tLoss: 0.164525\n",
      "Train Epoch: 4 [28800/50000 (58%)]\tLoss: 1.062741\n",
      "Train Epoch: 4 [29200/50000 (58%)]\tLoss: 0.939422\n",
      "Train Epoch: 4 [29600/50000 (59%)]\tLoss: 0.065135\n",
      "Train Epoch: 4 [30000/50000 (60%)]\tLoss: 0.028386\n",
      "Train Epoch: 4 [30400/50000 (61%)]\tLoss: 0.242562\n",
      "Train Epoch: 4 [30800/50000 (62%)]\tLoss: 1.151541\n",
      "Train Epoch: 4 [31200/50000 (62%)]\tLoss: 2.014153\n",
      "Train Epoch: 4 [31600/50000 (63%)]\tLoss: 0.897194\n",
      "Train Epoch: 4 [32000/50000 (64%)]\tLoss: 0.391716\n",
      "Train Epoch: 4 [32400/50000 (65%)]\tLoss: 0.594682\n",
      "Train Epoch: 4 [32800/50000 (66%)]\tLoss: 1.382768\n",
      "Train Epoch: 4 [33200/50000 (66%)]\tLoss: 0.998616\n",
      "Train Epoch: 4 [33600/50000 (67%)]\tLoss: 0.467647\n",
      "Train Epoch: 4 [34000/50000 (68%)]\tLoss: 0.203847\n",
      "Train Epoch: 4 [34400/50000 (69%)]\tLoss: 0.410510\n",
      "Train Epoch: 4 [34800/50000 (70%)]\tLoss: 0.527091\n",
      "Train Epoch: 4 [35200/50000 (70%)]\tLoss: 0.136452\n",
      "Train Epoch: 4 [35600/50000 (71%)]\tLoss: 2.066346\n",
      "Train Epoch: 4 [36000/50000 (72%)]\tLoss: 0.963714\n",
      "Train Epoch: 4 [36400/50000 (73%)]\tLoss: 0.973377\n",
      "Train Epoch: 4 [36800/50000 (74%)]\tLoss: 0.915519\n",
      "Train Epoch: 4 [37200/50000 (74%)]\tLoss: 0.206926\n",
      "Train Epoch: 4 [37600/50000 (75%)]\tLoss: 1.370765\n",
      "Train Epoch: 4 [38000/50000 (76%)]\tLoss: 0.140422\n",
      "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 0.895073\n",
      "Train Epoch: 4 [38800/50000 (78%)]\tLoss: 0.493818\n",
      "Train Epoch: 4 [39200/50000 (78%)]\tLoss: 2.069606\n",
      "Train Epoch: 4 [39600/50000 (79%)]\tLoss: 0.036878\n",
      "Train Epoch: 4 [40000/50000 (80%)]\tLoss: 1.955279\n",
      "Train Epoch: 4 [40400/50000 (81%)]\tLoss: 0.215048\n",
      "Train Epoch: 4 [40800/50000 (82%)]\tLoss: 1.684434\n",
      "Train Epoch: 4 [41200/50000 (82%)]\tLoss: 0.822400\n",
      "Train Epoch: 4 [41600/50000 (83%)]\tLoss: 0.056934\n",
      "Train Epoch: 4 [42000/50000 (84%)]\tLoss: 0.645708\n",
      "Train Epoch: 4 [42400/50000 (85%)]\tLoss: 0.074874\n",
      "Train Epoch: 4 [42800/50000 (86%)]\tLoss: 1.068762\n",
      "Train Epoch: 4 [43200/50000 (86%)]\tLoss: 1.529906\n",
      "Train Epoch: 4 [43600/50000 (87%)]\tLoss: 0.573381\n",
      "Train Epoch: 4 [44000/50000 (88%)]\tLoss: 1.185181\n",
      "Train Epoch: 4 [44400/50000 (89%)]\tLoss: 0.718306\n",
      "Train Epoch: 4 [44800/50000 (90%)]\tLoss: 0.510618\n",
      "Train Epoch: 4 [45200/50000 (90%)]\tLoss: 0.472727\n",
      "Train Epoch: 4 [45600/50000 (91%)]\tLoss: 0.711331\n",
      "Train Epoch: 4 [46000/50000 (92%)]\tLoss: 2.080756\n",
      "Train Epoch: 4 [46400/50000 (93%)]\tLoss: 1.384895\n",
      "Train Epoch: 4 [46800/50000 (94%)]\tLoss: 0.154412\n",
      "Train Epoch: 4 [47200/50000 (94%)]\tLoss: 0.203902\n",
      "Train Epoch: 4 [47600/50000 (95%)]\tLoss: 2.658205\n",
      "Train Epoch: 4 [48000/50000 (96%)]\tLoss: 2.017488\n",
      "Train Epoch: 4 [48400/50000 (97%)]\tLoss: 1.353571\n",
      "Train Epoch: 4 [48800/50000 (98%)]\tLoss: 1.377324\n",
      "Train Epoch: 4 [49200/50000 (98%)]\tLoss: 0.403692\n",
      "Train Epoch: 4 [49600/50000 (99%)]\tLoss: 0.528376\n",
      "Testing model for Experiment 2\n",
      "\n",
      "Test set: Average loss: 0.2851, Accuracy: 6214/10000 (62%)\n",
      "\n",
      "Training model for Experiment 2\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 0.524254\n",
      "Train Epoch: 5 [400/50000 (1%)]\tLoss: 0.401806\n",
      "Train Epoch: 5 [800/50000 (2%)]\tLoss: 0.352124\n",
      "Train Epoch: 5 [1200/50000 (2%)]\tLoss: 1.393712\n",
      "Train Epoch: 5 [1600/50000 (3%)]\tLoss: 0.855090\n",
      "Train Epoch: 5 [2000/50000 (4%)]\tLoss: 0.442760\n",
      "Train Epoch: 5 [2400/50000 (5%)]\tLoss: 2.040000\n",
      "Train Epoch: 5 [2800/50000 (6%)]\tLoss: 0.361441\n",
      "Train Epoch: 5 [3200/50000 (6%)]\tLoss: 0.366811\n",
      "Train Epoch: 5 [3600/50000 (7%)]\tLoss: 0.581715\n",
      "Train Epoch: 5 [4000/50000 (8%)]\tLoss: 0.529698\n",
      "Train Epoch: 5 [4400/50000 (9%)]\tLoss: 2.655068\n",
      "Train Epoch: 5 [4800/50000 (10%)]\tLoss: 0.261744\n",
      "Train Epoch: 5 [5200/50000 (10%)]\tLoss: 0.918370\n",
      "Train Epoch: 5 [5600/50000 (11%)]\tLoss: 0.412317\n",
      "Train Epoch: 5 [6000/50000 (12%)]\tLoss: 0.811213\n",
      "Train Epoch: 5 [6400/50000 (13%)]\tLoss: 0.733318\n",
      "Train Epoch: 5 [6800/50000 (14%)]\tLoss: 0.488807\n",
      "Train Epoch: 5 [7200/50000 (14%)]\tLoss: 1.155675\n",
      "Train Epoch: 5 [7600/50000 (15%)]\tLoss: 0.187543\n",
      "Train Epoch: 5 [8000/50000 (16%)]\tLoss: 0.784985\n",
      "Train Epoch: 5 [8400/50000 (17%)]\tLoss: 0.214934\n",
      "Train Epoch: 5 [8800/50000 (18%)]\tLoss: 0.947048\n",
      "Train Epoch: 5 [9200/50000 (18%)]\tLoss: 1.347417\n",
      "Train Epoch: 5 [9600/50000 (19%)]\tLoss: 0.329832\n",
      "Train Epoch: 5 [10000/50000 (20%)]\tLoss: 1.051205\n",
      "Train Epoch: 5 [10400/50000 (21%)]\tLoss: 1.000770\n",
      "Train Epoch: 5 [10800/50000 (22%)]\tLoss: 0.400776\n",
      "Train Epoch: 5 [11200/50000 (22%)]\tLoss: 0.073715\n",
      "Train Epoch: 5 [11600/50000 (23%)]\tLoss: 1.483658\n",
      "Train Epoch: 5 [12000/50000 (24%)]\tLoss: 0.168509\n",
      "Train Epoch: 5 [12400/50000 (25%)]\tLoss: 2.673458\n",
      "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 0.174275\n",
      "Train Epoch: 5 [13200/50000 (26%)]\tLoss: 1.225438\n",
      "Train Epoch: 5 [13600/50000 (27%)]\tLoss: 0.346886\n",
      "Train Epoch: 5 [14000/50000 (28%)]\tLoss: 0.319140\n",
      "Train Epoch: 5 [14400/50000 (29%)]\tLoss: 0.933965\n",
      "Train Epoch: 5 [14800/50000 (30%)]\tLoss: 0.234794\n",
      "Train Epoch: 5 [15200/50000 (30%)]\tLoss: 1.835099\n",
      "Train Epoch: 5 [15600/50000 (31%)]\tLoss: 0.240883\n",
      "Train Epoch: 5 [16000/50000 (32%)]\tLoss: 0.010554\n",
      "Train Epoch: 5 [16400/50000 (33%)]\tLoss: 0.581064\n",
      "Train Epoch: 5 [16800/50000 (34%)]\tLoss: 0.929992\n",
      "Train Epoch: 5 [17200/50000 (34%)]\tLoss: 0.007099\n",
      "Train Epoch: 5 [17600/50000 (35%)]\tLoss: 0.264461\n",
      "Train Epoch: 5 [18000/50000 (36%)]\tLoss: 0.969967\n",
      "Train Epoch: 5 [18400/50000 (37%)]\tLoss: 0.808848\n",
      "Train Epoch: 5 [18800/50000 (38%)]\tLoss: 0.609240\n",
      "Train Epoch: 5 [19200/50000 (38%)]\tLoss: 1.085721\n",
      "Train Epoch: 5 [19600/50000 (39%)]\tLoss: 0.350234\n",
      "Train Epoch: 5 [20000/50000 (40%)]\tLoss: 0.107804\n",
      "Train Epoch: 5 [20400/50000 (41%)]\tLoss: 0.423886\n",
      "Train Epoch: 5 [20800/50000 (42%)]\tLoss: 0.451966\n",
      "Train Epoch: 5 [21200/50000 (42%)]\tLoss: 0.033945\n",
      "Train Epoch: 5 [21600/50000 (43%)]\tLoss: 0.997225\n",
      "Train Epoch: 5 [22000/50000 (44%)]\tLoss: 0.633773\n",
      "Train Epoch: 5 [22400/50000 (45%)]\tLoss: 0.966732\n",
      "Train Epoch: 5 [22800/50000 (46%)]\tLoss: 0.711112\n",
      "Train Epoch: 5 [23200/50000 (46%)]\tLoss: 1.875484\n",
      "Train Epoch: 5 [23600/50000 (47%)]\tLoss: 0.918156\n",
      "Train Epoch: 5 [24000/50000 (48%)]\tLoss: 2.047252\n",
      "Train Epoch: 5 [24400/50000 (49%)]\tLoss: 0.104680\n",
      "Train Epoch: 5 [24800/50000 (50%)]\tLoss: 0.563036\n",
      "Train Epoch: 5 [25200/50000 (50%)]\tLoss: 0.341873\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 0.853453\n",
      "Train Epoch: 5 [26000/50000 (52%)]\tLoss: 0.734675\n",
      "Train Epoch: 5 [26400/50000 (53%)]\tLoss: 1.156685\n",
      "Train Epoch: 5 [26800/50000 (54%)]\tLoss: 0.930831\n",
      "Train Epoch: 5 [27200/50000 (54%)]\tLoss: 0.827378\n",
      "Train Epoch: 5 [27600/50000 (55%)]\tLoss: 0.703996\n",
      "Train Epoch: 5 [28000/50000 (56%)]\tLoss: 1.697937\n",
      "Train Epoch: 5 [28400/50000 (57%)]\tLoss: 0.006944\n",
      "Train Epoch: 5 [28800/50000 (58%)]\tLoss: 0.914720\n",
      "Train Epoch: 5 [29200/50000 (58%)]\tLoss: 0.197181\n",
      "Train Epoch: 5 [29600/50000 (59%)]\tLoss: 0.373654\n",
      "Train Epoch: 5 [30000/50000 (60%)]\tLoss: 0.528730\n",
      "Train Epoch: 5 [30400/50000 (61%)]\tLoss: 1.066529\n",
      "Train Epoch: 5 [30800/50000 (62%)]\tLoss: 0.284515\n",
      "Train Epoch: 5 [31200/50000 (62%)]\tLoss: 0.871811\n",
      "Train Epoch: 5 [31600/50000 (63%)]\tLoss: 0.955274\n",
      "Train Epoch: 5 [32000/50000 (64%)]\tLoss: 0.707444\n",
      "Train Epoch: 5 [32400/50000 (65%)]\tLoss: 0.030421\n",
      "Train Epoch: 5 [32800/50000 (66%)]\tLoss: 1.160770\n",
      "Train Epoch: 5 [33200/50000 (66%)]\tLoss: 0.822783\n",
      "Train Epoch: 5 [33600/50000 (67%)]\tLoss: 0.232020\n",
      "Train Epoch: 5 [34000/50000 (68%)]\tLoss: 0.588584\n",
      "Train Epoch: 5 [34400/50000 (69%)]\tLoss: 0.023788\n",
      "Train Epoch: 5 [34800/50000 (70%)]\tLoss: 0.971012\n",
      "Train Epoch: 5 [35200/50000 (70%)]\tLoss: 1.871522\n",
      "Train Epoch: 5 [35600/50000 (71%)]\tLoss: 0.898527\n",
      "Train Epoch: 5 [36000/50000 (72%)]\tLoss: 0.604786\n",
      "Train Epoch: 5 [36400/50000 (73%)]\tLoss: 0.913967\n",
      "Train Epoch: 5 [36800/50000 (74%)]\tLoss: 0.460516\n",
      "Train Epoch: 5 [37200/50000 (74%)]\tLoss: 0.636357\n",
      "Train Epoch: 5 [37600/50000 (75%)]\tLoss: 0.783670\n",
      "Train Epoch: 5 [38000/50000 (76%)]\tLoss: 1.319144\n",
      "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 0.209880\n",
      "Train Epoch: 5 [38800/50000 (78%)]\tLoss: 0.580899\n",
      "Train Epoch: 5 [39200/50000 (78%)]\tLoss: 0.761165\n",
      "Train Epoch: 5 [39600/50000 (79%)]\tLoss: 0.495104\n",
      "Train Epoch: 5 [40000/50000 (80%)]\tLoss: 1.087655\n",
      "Train Epoch: 5 [40400/50000 (81%)]\tLoss: 0.154839\n",
      "Train Epoch: 5 [40800/50000 (82%)]\tLoss: 0.089267\n",
      "Train Epoch: 5 [41200/50000 (82%)]\tLoss: 0.328839\n",
      "Train Epoch: 5 [41600/50000 (83%)]\tLoss: 0.732745\n",
      "Train Epoch: 5 [42000/50000 (84%)]\tLoss: 0.704109\n",
      "Train Epoch: 5 [42400/50000 (85%)]\tLoss: 1.466594\n",
      "Train Epoch: 5 [42800/50000 (86%)]\tLoss: 0.761450\n",
      "Train Epoch: 5 [43200/50000 (86%)]\tLoss: 0.207179\n",
      "Train Epoch: 5 [43600/50000 (87%)]\tLoss: 0.863345\n",
      "Train Epoch: 5 [44000/50000 (88%)]\tLoss: 1.071954\n",
      "Train Epoch: 5 [44400/50000 (89%)]\tLoss: 1.082033\n",
      "Train Epoch: 5 [44800/50000 (90%)]\tLoss: 0.651434\n",
      "Train Epoch: 5 [45200/50000 (90%)]\tLoss: 0.532020\n",
      "Train Epoch: 5 [45600/50000 (91%)]\tLoss: 0.257107\n",
      "Train Epoch: 5 [46000/50000 (92%)]\tLoss: 0.154912\n",
      "Train Epoch: 5 [46400/50000 (93%)]\tLoss: 0.592310\n",
      "Train Epoch: 5 [46800/50000 (94%)]\tLoss: 0.454140\n",
      "Train Epoch: 5 [47200/50000 (94%)]\tLoss: 0.482515\n",
      "Train Epoch: 5 [47600/50000 (95%)]\tLoss: 0.379710\n",
      "Train Epoch: 5 [48000/50000 (96%)]\tLoss: 0.825098\n",
      "Train Epoch: 5 [48400/50000 (97%)]\tLoss: 0.182674\n",
      "Train Epoch: 5 [48800/50000 (98%)]\tLoss: 0.852787\n",
      "Train Epoch: 5 [49200/50000 (98%)]\tLoss: 1.970910\n",
      "Train Epoch: 5 [49600/50000 (99%)]\tLoss: 0.837774\n",
      "Testing model for Experiment 2\n",
      "\n",
      "Test set: Average loss: 0.3029, Accuracy: 6311/10000 (63%)\n",
      "\n",
      "Training model for Experiment 2\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 0.059696\n",
      "Train Epoch: 6 [400/50000 (1%)]\tLoss: 0.266160\n",
      "Train Epoch: 6 [800/50000 (2%)]\tLoss: 0.527273\n",
      "Train Epoch: 6 [1200/50000 (2%)]\tLoss: 0.373787\n",
      "Train Epoch: 6 [1600/50000 (3%)]\tLoss: 2.000384\n",
      "Train Epoch: 6 [2000/50000 (4%)]\tLoss: 0.488302\n",
      "Train Epoch: 6 [2400/50000 (5%)]\tLoss: 0.079561\n",
      "Train Epoch: 6 [2800/50000 (6%)]\tLoss: 0.594091\n",
      "Train Epoch: 6 [3200/50000 (6%)]\tLoss: 0.173596\n",
      "Train Epoch: 6 [3600/50000 (7%)]\tLoss: 0.477388\n",
      "Train Epoch: 6 [4000/50000 (8%)]\tLoss: 0.147740\n",
      "Train Epoch: 6 [4400/50000 (9%)]\tLoss: 1.424284\n",
      "Train Epoch: 6 [4800/50000 (10%)]\tLoss: 0.201765\n",
      "Train Epoch: 6 [5200/50000 (10%)]\tLoss: 1.131031\n",
      "Train Epoch: 6 [5600/50000 (11%)]\tLoss: 0.836438\n",
      "Train Epoch: 6 [6000/50000 (12%)]\tLoss: 0.081407\n",
      "Train Epoch: 6 [6400/50000 (13%)]\tLoss: 0.434292\n",
      "Train Epoch: 6 [6800/50000 (14%)]\tLoss: 0.804662\n",
      "Train Epoch: 6 [7200/50000 (14%)]\tLoss: 0.312506\n",
      "Train Epoch: 6 [7600/50000 (15%)]\tLoss: 1.769936\n",
      "Train Epoch: 6 [8000/50000 (16%)]\tLoss: 0.202940\n",
      "Train Epoch: 6 [8400/50000 (17%)]\tLoss: 0.151754\n",
      "Train Epoch: 6 [8800/50000 (18%)]\tLoss: 0.347677\n",
      "Train Epoch: 6 [9200/50000 (18%)]\tLoss: 0.595633\n",
      "Train Epoch: 6 [9600/50000 (19%)]\tLoss: 0.175196\n",
      "Train Epoch: 6 [10000/50000 (20%)]\tLoss: 1.094463\n",
      "Train Epoch: 6 [10400/50000 (21%)]\tLoss: 0.819001\n",
      "Train Epoch: 6 [10800/50000 (22%)]\tLoss: 0.950382\n",
      "Train Epoch: 6 [11200/50000 (22%)]\tLoss: 0.582831\n",
      "Train Epoch: 6 [11600/50000 (23%)]\tLoss: 0.895526\n",
      "Train Epoch: 6 [12000/50000 (24%)]\tLoss: 1.729461\n",
      "Train Epoch: 6 [12400/50000 (25%)]\tLoss: 0.038097\n",
      "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 0.494408\n",
      "Train Epoch: 6 [13200/50000 (26%)]\tLoss: 1.830410\n",
      "Train Epoch: 6 [13600/50000 (27%)]\tLoss: 0.679998\n",
      "Train Epoch: 6 [14000/50000 (28%)]\tLoss: 1.440460\n",
      "Train Epoch: 6 [14400/50000 (29%)]\tLoss: 0.468537\n",
      "Train Epoch: 6 [14800/50000 (30%)]\tLoss: 0.358321\n",
      "Train Epoch: 6 [15200/50000 (30%)]\tLoss: 0.625190\n",
      "Train Epoch: 6 [15600/50000 (31%)]\tLoss: 0.094852\n",
      "Train Epoch: 6 [16000/50000 (32%)]\tLoss: 0.527739\n",
      "Train Epoch: 6 [16400/50000 (33%)]\tLoss: 0.544666\n",
      "Train Epoch: 6 [16800/50000 (34%)]\tLoss: 1.064908\n",
      "Train Epoch: 6 [17200/50000 (34%)]\tLoss: 1.633483\n",
      "Train Epoch: 6 [17600/50000 (35%)]\tLoss: 1.193122\n",
      "Train Epoch: 6 [18000/50000 (36%)]\tLoss: 0.652474\n",
      "Train Epoch: 6 [18400/50000 (37%)]\tLoss: 0.856051\n",
      "Train Epoch: 6 [18800/50000 (38%)]\tLoss: 0.922781\n",
      "Train Epoch: 6 [19200/50000 (38%)]\tLoss: 0.757840\n",
      "Train Epoch: 6 [19600/50000 (39%)]\tLoss: 0.881066\n",
      "Train Epoch: 6 [20000/50000 (40%)]\tLoss: 0.643319\n",
      "Train Epoch: 6 [20400/50000 (41%)]\tLoss: 1.953077\n",
      "Train Epoch: 6 [20800/50000 (42%)]\tLoss: 0.673586\n",
      "Train Epoch: 6 [21200/50000 (42%)]\tLoss: 0.742466\n",
      "Train Epoch: 6 [21600/50000 (43%)]\tLoss: 1.043773\n",
      "Train Epoch: 6 [22000/50000 (44%)]\tLoss: 0.034063\n",
      "Train Epoch: 6 [22400/50000 (45%)]\tLoss: 0.839562\n",
      "Train Epoch: 6 [22800/50000 (46%)]\tLoss: 0.663805\n",
      "Train Epoch: 6 [23200/50000 (46%)]\tLoss: 0.048783\n",
      "Train Epoch: 6 [23600/50000 (47%)]\tLoss: 0.479546\n",
      "Train Epoch: 6 [24000/50000 (48%)]\tLoss: 1.411677\n",
      "Train Epoch: 6 [24400/50000 (49%)]\tLoss: 0.675646\n",
      "Train Epoch: 6 [24800/50000 (50%)]\tLoss: 0.613291\n",
      "Train Epoch: 6 [25200/50000 (50%)]\tLoss: 0.271300\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 0.215518\n",
      "Train Epoch: 6 [26000/50000 (52%)]\tLoss: 0.404564\n",
      "Train Epoch: 6 [26400/50000 (53%)]\tLoss: 0.440124\n",
      "Train Epoch: 6 [26800/50000 (54%)]\tLoss: 0.984455\n",
      "Train Epoch: 6 [27200/50000 (54%)]\tLoss: 0.755523\n",
      "Train Epoch: 6 [27600/50000 (55%)]\tLoss: 0.474286\n",
      "Train Epoch: 6 [28000/50000 (56%)]\tLoss: 0.487848\n",
      "Train Epoch: 6 [28400/50000 (57%)]\tLoss: 0.174876\n",
      "Train Epoch: 6 [28800/50000 (58%)]\tLoss: 0.428046\n",
      "Train Epoch: 6 [29200/50000 (58%)]\tLoss: 2.257789\n",
      "Train Epoch: 6 [29600/50000 (59%)]\tLoss: 0.143590\n",
      "Train Epoch: 6 [30000/50000 (60%)]\tLoss: 0.347369\n",
      "Train Epoch: 6 [30400/50000 (61%)]\tLoss: 0.606851\n",
      "Train Epoch: 6 [30800/50000 (62%)]\tLoss: 1.146960\n",
      "Train Epoch: 6 [31200/50000 (62%)]\tLoss: 0.867433\n",
      "Train Epoch: 6 [31600/50000 (63%)]\tLoss: 1.453781\n",
      "Train Epoch: 6 [32000/50000 (64%)]\tLoss: 0.320576\n",
      "Train Epoch: 6 [32400/50000 (65%)]\tLoss: 1.923437\n",
      "Train Epoch: 6 [32800/50000 (66%)]\tLoss: 0.578365\n",
      "Train Epoch: 6 [33200/50000 (66%)]\tLoss: 0.382623\n",
      "Train Epoch: 6 [33600/50000 (67%)]\tLoss: 0.722367\n",
      "Train Epoch: 6 [34000/50000 (68%)]\tLoss: 0.950226\n",
      "Train Epoch: 6 [34400/50000 (69%)]\tLoss: 0.068710\n",
      "Train Epoch: 6 [34800/50000 (70%)]\tLoss: 0.848864\n",
      "Train Epoch: 6 [35200/50000 (70%)]\tLoss: 0.239889\n",
      "Train Epoch: 6 [35600/50000 (71%)]\tLoss: 0.422756\n",
      "Train Epoch: 6 [36000/50000 (72%)]\tLoss: 0.842750\n",
      "Train Epoch: 6 [36400/50000 (73%)]\tLoss: 0.318031\n",
      "Train Epoch: 6 [36800/50000 (74%)]\tLoss: 0.627490\n",
      "Train Epoch: 6 [37200/50000 (74%)]\tLoss: 1.189867\n",
      "Train Epoch: 6 [37600/50000 (75%)]\tLoss: 0.915656\n",
      "Train Epoch: 6 [38000/50000 (76%)]\tLoss: 0.145938\n",
      "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 0.750234\n",
      "Train Epoch: 6 [38800/50000 (78%)]\tLoss: 0.333929\n",
      "Train Epoch: 6 [39200/50000 (78%)]\tLoss: 0.358921\n",
      "Train Epoch: 6 [39600/50000 (79%)]\tLoss: 0.343891\n",
      "Train Epoch: 6 [40000/50000 (80%)]\tLoss: 0.109574\n",
      "Train Epoch: 6 [40400/50000 (81%)]\tLoss: 0.092836\n",
      "Train Epoch: 6 [40800/50000 (82%)]\tLoss: 0.504746\n",
      "Train Epoch: 6 [41200/50000 (82%)]\tLoss: 0.619192\n",
      "Train Epoch: 6 [41600/50000 (83%)]\tLoss: 1.091194\n",
      "Train Epoch: 6 [42000/50000 (84%)]\tLoss: 1.365490\n",
      "Train Epoch: 6 [42400/50000 (85%)]\tLoss: 0.397244\n",
      "Train Epoch: 6 [42800/50000 (86%)]\tLoss: 0.358097\n",
      "Train Epoch: 6 [43200/50000 (86%)]\tLoss: 0.482690\n",
      "Train Epoch: 6 [43600/50000 (87%)]\tLoss: 0.443224\n",
      "Train Epoch: 6 [44000/50000 (88%)]\tLoss: 0.910379\n",
      "Train Epoch: 6 [44400/50000 (89%)]\tLoss: 0.233786\n",
      "Train Epoch: 6 [44800/50000 (90%)]\tLoss: 0.083750\n",
      "Train Epoch: 6 [45200/50000 (90%)]\tLoss: 0.502983\n",
      "Train Epoch: 6 [45600/50000 (91%)]\tLoss: 1.167781\n",
      "Train Epoch: 6 [46000/50000 (92%)]\tLoss: 1.705695\n",
      "Train Epoch: 6 [46400/50000 (93%)]\tLoss: 0.548175\n",
      "Train Epoch: 6 [46800/50000 (94%)]\tLoss: 0.205205\n",
      "Train Epoch: 6 [47200/50000 (94%)]\tLoss: 0.927719\n",
      "Train Epoch: 6 [47600/50000 (95%)]\tLoss: 0.466847\n",
      "Train Epoch: 6 [48000/50000 (96%)]\tLoss: 0.751713\n",
      "Train Epoch: 6 [48400/50000 (97%)]\tLoss: 0.564390\n",
      "Train Epoch: 6 [48800/50000 (98%)]\tLoss: 0.611973\n",
      "Train Epoch: 6 [49200/50000 (98%)]\tLoss: 1.103899\n",
      "Train Epoch: 6 [49600/50000 (99%)]\tLoss: 0.748371\n",
      "Testing model for Experiment 2\n",
      "\n",
      "Test set: Average loss: 0.3195, Accuracy: 6177/10000 (62%)\n",
      "\n",
      "Training model for Experiment 2\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 2.049775\n",
      "Train Epoch: 7 [400/50000 (1%)]\tLoss: 0.127292\n",
      "Train Epoch: 7 [800/50000 (2%)]\tLoss: 0.758304\n",
      "Train Epoch: 7 [1200/50000 (2%)]\tLoss: 0.487987\n",
      "Train Epoch: 7 [1600/50000 (3%)]\tLoss: 0.103345\n",
      "Train Epoch: 7 [2000/50000 (4%)]\tLoss: 0.066477\n",
      "Train Epoch: 7 [2400/50000 (5%)]\tLoss: 0.183214\n",
      "Train Epoch: 7 [2800/50000 (6%)]\tLoss: 0.089509\n",
      "Train Epoch: 7 [3200/50000 (6%)]\tLoss: 0.255754\n",
      "Train Epoch: 7 [3600/50000 (7%)]\tLoss: 0.531276\n",
      "Train Epoch: 7 [4000/50000 (8%)]\tLoss: 1.335001\n",
      "Train Epoch: 7 [4400/50000 (9%)]\tLoss: 0.732671\n",
      "Train Epoch: 7 [4800/50000 (10%)]\tLoss: 0.617783\n",
      "Train Epoch: 7 [5200/50000 (10%)]\tLoss: 0.746159\n",
      "Train Epoch: 7 [5600/50000 (11%)]\tLoss: 0.502946\n",
      "Train Epoch: 7 [6000/50000 (12%)]\tLoss: 0.404988\n",
      "Train Epoch: 7 [6400/50000 (13%)]\tLoss: 0.001463\n",
      "Train Epoch: 7 [6800/50000 (14%)]\tLoss: 0.219875\n",
      "Train Epoch: 7 [7200/50000 (14%)]\tLoss: 0.082226\n",
      "Train Epoch: 7 [7600/50000 (15%)]\tLoss: 0.026110\n",
      "Train Epoch: 7 [8000/50000 (16%)]\tLoss: 0.247137\n",
      "Train Epoch: 7 [8400/50000 (17%)]\tLoss: 0.197978\n",
      "Train Epoch: 7 [8800/50000 (18%)]\tLoss: 2.780729\n",
      "Train Epoch: 7 [9200/50000 (18%)]\tLoss: 0.884508\n",
      "Train Epoch: 7 [9600/50000 (19%)]\tLoss: 1.274646\n",
      "Train Epoch: 7 [10000/50000 (20%)]\tLoss: 1.142928\n",
      "Train Epoch: 7 [10400/50000 (21%)]\tLoss: 1.287910\n",
      "Train Epoch: 7 [10800/50000 (22%)]\tLoss: 0.112572\n",
      "Train Epoch: 7 [11200/50000 (22%)]\tLoss: 0.975884\n",
      "Train Epoch: 7 [11600/50000 (23%)]\tLoss: 0.025825\n",
      "Train Epoch: 7 [12000/50000 (24%)]\tLoss: 0.434127\n",
      "Train Epoch: 7 [12400/50000 (25%)]\tLoss: 0.054256\n",
      "Train Epoch: 7 [12800/50000 (26%)]\tLoss: 0.014341\n",
      "Train Epoch: 7 [13200/50000 (26%)]\tLoss: 0.419153\n",
      "Train Epoch: 7 [13600/50000 (27%)]\tLoss: 0.093817\n",
      "Train Epoch: 7 [14000/50000 (28%)]\tLoss: 0.576512\n",
      "Train Epoch: 7 [14400/50000 (29%)]\tLoss: 0.356334\n",
      "Train Epoch: 7 [14800/50000 (30%)]\tLoss: 1.230242\n",
      "Train Epoch: 7 [15200/50000 (30%)]\tLoss: 0.538481\n",
      "Train Epoch: 7 [15600/50000 (31%)]\tLoss: 0.016812\n",
      "Train Epoch: 7 [16000/50000 (32%)]\tLoss: 0.783489\n",
      "Train Epoch: 7 [16400/50000 (33%)]\tLoss: 0.292060\n",
      "Train Epoch: 7 [16800/50000 (34%)]\tLoss: 0.635402\n",
      "Train Epoch: 7 [17200/50000 (34%)]\tLoss: 0.388721\n",
      "Train Epoch: 7 [17600/50000 (35%)]\tLoss: 0.015166\n",
      "Train Epoch: 7 [18000/50000 (36%)]\tLoss: 0.351721\n",
      "Train Epoch: 7 [18400/50000 (37%)]\tLoss: 2.031878\n",
      "Train Epoch: 7 [18800/50000 (38%)]\tLoss: 0.324581\n",
      "Train Epoch: 7 [19200/50000 (38%)]\tLoss: 0.037137\n",
      "Train Epoch: 7 [19600/50000 (39%)]\tLoss: 0.255670\n",
      "Train Epoch: 7 [20000/50000 (40%)]\tLoss: 1.690599\n",
      "Train Epoch: 7 [20400/50000 (41%)]\tLoss: 0.306302\n",
      "Train Epoch: 7 [20800/50000 (42%)]\tLoss: 0.285125\n",
      "Train Epoch: 7 [21200/50000 (42%)]\tLoss: 0.348479\n",
      "Train Epoch: 7 [21600/50000 (43%)]\tLoss: 0.223107\n",
      "Train Epoch: 7 [22000/50000 (44%)]\tLoss: 0.165655\n",
      "Train Epoch: 7 [22400/50000 (45%)]\tLoss: 0.920298\n",
      "Train Epoch: 7 [22800/50000 (46%)]\tLoss: 0.373624\n",
      "Train Epoch: 7 [23200/50000 (46%)]\tLoss: 0.910485\n",
      "Train Epoch: 7 [23600/50000 (47%)]\tLoss: 0.413504\n",
      "Train Epoch: 7 [24000/50000 (48%)]\tLoss: 0.192527\n",
      "Train Epoch: 7 [24400/50000 (49%)]\tLoss: 1.101835\n",
      "Train Epoch: 7 [24800/50000 (50%)]\tLoss: 0.367121\n",
      "Train Epoch: 7 [25200/50000 (50%)]\tLoss: 0.172851\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 0.606324\n",
      "Train Epoch: 7 [26000/50000 (52%)]\tLoss: 0.184875\n",
      "Train Epoch: 7 [26400/50000 (53%)]\tLoss: 0.071089\n",
      "Train Epoch: 7 [26800/50000 (54%)]\tLoss: 0.329675\n",
      "Train Epoch: 7 [27200/50000 (54%)]\tLoss: 1.517627\n",
      "Train Epoch: 7 [27600/50000 (55%)]\tLoss: 0.789418\n",
      "Train Epoch: 7 [28000/50000 (56%)]\tLoss: 0.835238\n",
      "Train Epoch: 7 [28400/50000 (57%)]\tLoss: 0.705705\n",
      "Train Epoch: 7 [28800/50000 (58%)]\tLoss: 0.379231\n",
      "Train Epoch: 7 [29200/50000 (58%)]\tLoss: 0.306308\n",
      "Train Epoch: 7 [29600/50000 (59%)]\tLoss: 0.000361\n",
      "Train Epoch: 7 [30000/50000 (60%)]\tLoss: 0.775033\n",
      "Train Epoch: 7 [30400/50000 (61%)]\tLoss: 1.272970\n",
      "Train Epoch: 7 [30800/50000 (62%)]\tLoss: 0.529968\n",
      "Train Epoch: 7 [31200/50000 (62%)]\tLoss: 1.442649\n",
      "Train Epoch: 7 [31600/50000 (63%)]\tLoss: 0.302627\n",
      "Train Epoch: 7 [32000/50000 (64%)]\tLoss: 0.661995\n",
      "Train Epoch: 7 [32400/50000 (65%)]\tLoss: 0.820249\n",
      "Train Epoch: 7 [32800/50000 (66%)]\tLoss: 0.557118\n",
      "Train Epoch: 7 [33200/50000 (66%)]\tLoss: 0.380299\n",
      "Train Epoch: 7 [33600/50000 (67%)]\tLoss: 0.768624\n",
      "Train Epoch: 7 [34000/50000 (68%)]\tLoss: 1.415763\n",
      "Train Epoch: 7 [34400/50000 (69%)]\tLoss: 0.402197\n",
      "Train Epoch: 7 [34800/50000 (70%)]\tLoss: 0.043079\n",
      "Train Epoch: 7 [35200/50000 (70%)]\tLoss: 1.639232\n",
      "Train Epoch: 7 [35600/50000 (71%)]\tLoss: 0.274936\n",
      "Train Epoch: 7 [36000/50000 (72%)]\tLoss: 0.172713\n",
      "Train Epoch: 7 [36400/50000 (73%)]\tLoss: 1.092457\n",
      "Train Epoch: 7 [36800/50000 (74%)]\tLoss: 0.063536\n",
      "Train Epoch: 7 [37200/50000 (74%)]\tLoss: 2.087473\n",
      "Train Epoch: 7 [37600/50000 (75%)]\tLoss: 0.053659\n",
      "Train Epoch: 7 [38000/50000 (76%)]\tLoss: 0.322055\n",
      "Train Epoch: 7 [38400/50000 (77%)]\tLoss: 1.172855\n",
      "Train Epoch: 7 [38800/50000 (78%)]\tLoss: 0.019803\n",
      "Train Epoch: 7 [39200/50000 (78%)]\tLoss: 0.259843\n",
      "Train Epoch: 7 [39600/50000 (79%)]\tLoss: 1.727482\n",
      "Train Epoch: 7 [40000/50000 (80%)]\tLoss: 0.524207\n",
      "Train Epoch: 7 [40400/50000 (81%)]\tLoss: 0.377527\n",
      "Train Epoch: 7 [40800/50000 (82%)]\tLoss: 0.164516\n",
      "Train Epoch: 7 [41200/50000 (82%)]\tLoss: 0.571343\n",
      "Train Epoch: 7 [41600/50000 (83%)]\tLoss: 1.008522\n",
      "Train Epoch: 7 [42000/50000 (84%)]\tLoss: 0.610554\n",
      "Train Epoch: 7 [42400/50000 (85%)]\tLoss: 1.481285\n",
      "Train Epoch: 7 [42800/50000 (86%)]\tLoss: 1.511593\n",
      "Train Epoch: 7 [43200/50000 (86%)]\tLoss: 0.478594\n",
      "Train Epoch: 7 [43600/50000 (87%)]\tLoss: 1.566028\n",
      "Train Epoch: 7 [44000/50000 (88%)]\tLoss: 0.172782\n",
      "Train Epoch: 7 [44400/50000 (89%)]\tLoss: 0.495561\n",
      "Train Epoch: 7 [44800/50000 (90%)]\tLoss: 0.021374\n",
      "Train Epoch: 7 [45200/50000 (90%)]\tLoss: 0.913712\n",
      "Train Epoch: 7 [45600/50000 (91%)]\tLoss: 0.469213\n",
      "Train Epoch: 7 [46000/50000 (92%)]\tLoss: 2.328446\n",
      "Train Epoch: 7 [46400/50000 (93%)]\tLoss: 0.315486\n",
      "Train Epoch: 7 [46800/50000 (94%)]\tLoss: 0.016274\n",
      "Train Epoch: 7 [47200/50000 (94%)]\tLoss: 0.301324\n",
      "Train Epoch: 7 [47600/50000 (95%)]\tLoss: 0.242473\n",
      "Train Epoch: 7 [48000/50000 (96%)]\tLoss: 0.511706\n",
      "Train Epoch: 7 [48400/50000 (97%)]\tLoss: 0.841726\n",
      "Train Epoch: 7 [48800/50000 (98%)]\tLoss: 1.726844\n",
      "Train Epoch: 7 [49200/50000 (98%)]\tLoss: 0.024709\n",
      "Train Epoch: 7 [49600/50000 (99%)]\tLoss: 0.107176\n",
      "Testing model for Experiment 2\n",
      "\n",
      "Test set: Average loss: 0.3293, Accuracy: 6270/10000 (63%)\n",
      "\n",
      "Training model for Experiment 2\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 0.194797\n",
      "Train Epoch: 8 [400/50000 (1%)]\tLoss: 0.661338\n",
      "Train Epoch: 8 [800/50000 (2%)]\tLoss: 0.054228\n",
      "Train Epoch: 8 [1200/50000 (2%)]\tLoss: 0.426434\n",
      "Train Epoch: 8 [1600/50000 (3%)]\tLoss: 1.197838\n",
      "Train Epoch: 8 [2000/50000 (4%)]\tLoss: 0.691200\n",
      "Train Epoch: 8 [2400/50000 (5%)]\tLoss: 0.021827\n",
      "Train Epoch: 8 [2800/50000 (6%)]\tLoss: 0.255538\n",
      "Train Epoch: 8 [3200/50000 (6%)]\tLoss: 0.897154\n",
      "Train Epoch: 8 [3600/50000 (7%)]\tLoss: 0.067088\n",
      "Train Epoch: 8 [4000/50000 (8%)]\tLoss: 0.051251\n",
      "Train Epoch: 8 [4400/50000 (9%)]\tLoss: 0.541056\n",
      "Train Epoch: 8 [4800/50000 (10%)]\tLoss: 0.074553\n",
      "Train Epoch: 8 [5200/50000 (10%)]\tLoss: 0.099219\n",
      "Train Epoch: 8 [5600/50000 (11%)]\tLoss: 0.278598\n",
      "Train Epoch: 8 [6000/50000 (12%)]\tLoss: 0.011610\n",
      "Train Epoch: 8 [6400/50000 (13%)]\tLoss: 0.640918\n",
      "Train Epoch: 8 [6800/50000 (14%)]\tLoss: 0.453657\n",
      "Train Epoch: 8 [7200/50000 (14%)]\tLoss: 0.398308\n",
      "Train Epoch: 8 [7600/50000 (15%)]\tLoss: 0.212099\n",
      "Train Epoch: 8 [8000/50000 (16%)]\tLoss: 0.455770\n",
      "Train Epoch: 8 [8400/50000 (17%)]\tLoss: 0.133737\n",
      "Train Epoch: 8 [8800/50000 (18%)]\tLoss: 1.818918\n",
      "Train Epoch: 8 [9200/50000 (18%)]\tLoss: 0.207829\n",
      "Train Epoch: 8 [9600/50000 (19%)]\tLoss: 0.340216\n",
      "Train Epoch: 8 [10000/50000 (20%)]\tLoss: 2.177504\n",
      "Train Epoch: 8 [10400/50000 (21%)]\tLoss: 0.035283\n",
      "Train Epoch: 8 [10800/50000 (22%)]\tLoss: 1.279255\n",
      "Train Epoch: 8 [11200/50000 (22%)]\tLoss: 1.180473\n",
      "Train Epoch: 8 [11600/50000 (23%)]\tLoss: 1.300903\n",
      "Train Epoch: 8 [12000/50000 (24%)]\tLoss: 0.098617\n",
      "Train Epoch: 8 [12400/50000 (25%)]\tLoss: 0.877386\n",
      "Train Epoch: 8 [12800/50000 (26%)]\tLoss: 0.554202\n",
      "Train Epoch: 8 [13200/50000 (26%)]\tLoss: 0.751352\n",
      "Train Epoch: 8 [13600/50000 (27%)]\tLoss: 0.341078\n",
      "Train Epoch: 8 [14000/50000 (28%)]\tLoss: 0.425103\n",
      "Train Epoch: 8 [14400/50000 (29%)]\tLoss: 0.708852\n",
      "Train Epoch: 8 [14800/50000 (30%)]\tLoss: 0.067450\n",
      "Train Epoch: 8 [15200/50000 (30%)]\tLoss: 0.333987\n",
      "Train Epoch: 8 [15600/50000 (31%)]\tLoss: 0.334907\n",
      "Train Epoch: 8 [16000/50000 (32%)]\tLoss: 0.367477\n",
      "Train Epoch: 8 [16400/50000 (33%)]\tLoss: 2.110680\n",
      "Train Epoch: 8 [16800/50000 (34%)]\tLoss: 0.226916\n",
      "Train Epoch: 8 [17200/50000 (34%)]\tLoss: 1.354243\n",
      "Train Epoch: 8 [17600/50000 (35%)]\tLoss: 0.159110\n",
      "Train Epoch: 8 [18000/50000 (36%)]\tLoss: 0.093369\n",
      "Train Epoch: 8 [18400/50000 (37%)]\tLoss: 0.047572\n",
      "Train Epoch: 8 [18800/50000 (38%)]\tLoss: 1.615037\n",
      "Train Epoch: 8 [19200/50000 (38%)]\tLoss: 1.708113\n",
      "Train Epoch: 8 [19600/50000 (39%)]\tLoss: 0.332123\n",
      "Train Epoch: 8 [20000/50000 (40%)]\tLoss: 0.983554\n",
      "Train Epoch: 8 [20400/50000 (41%)]\tLoss: 0.758683\n",
      "Train Epoch: 8 [20800/50000 (42%)]\tLoss: 1.045195\n",
      "Train Epoch: 8 [21200/50000 (42%)]\tLoss: 0.086793\n",
      "Train Epoch: 8 [21600/50000 (43%)]\tLoss: 0.177708\n",
      "Train Epoch: 8 [22000/50000 (44%)]\tLoss: 0.599716\n",
      "Train Epoch: 8 [22400/50000 (45%)]\tLoss: 1.275494\n",
      "Train Epoch: 8 [22800/50000 (46%)]\tLoss: 0.003585\n",
      "Train Epoch: 8 [23200/50000 (46%)]\tLoss: 0.523650\n",
      "Train Epoch: 8 [23600/50000 (47%)]\tLoss: 0.006904\n",
      "Train Epoch: 8 [24000/50000 (48%)]\tLoss: 1.152568\n",
      "Train Epoch: 8 [24400/50000 (49%)]\tLoss: 0.002658\n",
      "Train Epoch: 8 [24800/50000 (50%)]\tLoss: 0.544568\n",
      "Train Epoch: 8 [25200/50000 (50%)]\tLoss: 0.815175\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 0.312345\n",
      "Train Epoch: 8 [26000/50000 (52%)]\tLoss: 0.483256\n",
      "Train Epoch: 8 [26400/50000 (53%)]\tLoss: 0.947168\n",
      "Train Epoch: 8 [26800/50000 (54%)]\tLoss: 1.154583\n",
      "Train Epoch: 8 [27200/50000 (54%)]\tLoss: 0.402994\n",
      "Train Epoch: 8 [27600/50000 (55%)]\tLoss: 0.134429\n",
      "Train Epoch: 8 [28000/50000 (56%)]\tLoss: 0.565812\n",
      "Train Epoch: 8 [28400/50000 (57%)]\tLoss: 0.683385\n",
      "Train Epoch: 8 [28800/50000 (58%)]\tLoss: 0.032418\n",
      "Train Epoch: 8 [29200/50000 (58%)]\tLoss: 0.906119\n",
      "Train Epoch: 8 [29600/50000 (59%)]\tLoss: 0.061288\n",
      "Train Epoch: 8 [30000/50000 (60%)]\tLoss: 1.799276\n",
      "Train Epoch: 8 [30400/50000 (61%)]\tLoss: 1.454378\n",
      "Train Epoch: 8 [30800/50000 (62%)]\tLoss: 1.543278\n",
      "Train Epoch: 8 [31200/50000 (62%)]\tLoss: 0.602927\n",
      "Train Epoch: 8 [31600/50000 (63%)]\tLoss: 0.548595\n",
      "Train Epoch: 8 [32000/50000 (64%)]\tLoss: 0.458140\n",
      "Train Epoch: 8 [32400/50000 (65%)]\tLoss: 0.854070\n",
      "Train Epoch: 8 [32800/50000 (66%)]\tLoss: 0.273159\n",
      "Train Epoch: 8 [33200/50000 (66%)]\tLoss: 0.205286\n",
      "Train Epoch: 8 [33600/50000 (67%)]\tLoss: 0.656569\n",
      "Train Epoch: 8 [34000/50000 (68%)]\tLoss: 0.242719\n",
      "Train Epoch: 8 [34400/50000 (69%)]\tLoss: 0.514879\n",
      "Train Epoch: 8 [34800/50000 (70%)]\tLoss: 1.795048\n",
      "Train Epoch: 8 [35200/50000 (70%)]\tLoss: 0.255221\n",
      "Train Epoch: 8 [35600/50000 (71%)]\tLoss: 0.022617\n",
      "Train Epoch: 8 [36000/50000 (72%)]\tLoss: 0.367652\n",
      "Train Epoch: 8 [36400/50000 (73%)]\tLoss: 0.000147\n",
      "Train Epoch: 8 [36800/50000 (74%)]\tLoss: 1.079596\n",
      "Train Epoch: 8 [37200/50000 (74%)]\tLoss: 0.462515\n",
      "Train Epoch: 8 [37600/50000 (75%)]\tLoss: 0.642406\n",
      "Train Epoch: 8 [38000/50000 (76%)]\tLoss: 0.646493\n",
      "Train Epoch: 8 [38400/50000 (77%)]\tLoss: 0.036628\n",
      "Train Epoch: 8 [38800/50000 (78%)]\tLoss: 0.410129\n",
      "Train Epoch: 8 [39200/50000 (78%)]\tLoss: 1.462431\n",
      "Train Epoch: 8 [39600/50000 (79%)]\tLoss: 0.728517\n",
      "Train Epoch: 8 [40000/50000 (80%)]\tLoss: 1.608071\n",
      "Train Epoch: 8 [40400/50000 (81%)]\tLoss: 0.476739\n",
      "Train Epoch: 8 [40800/50000 (82%)]\tLoss: 0.100480\n",
      "Train Epoch: 8 [41200/50000 (82%)]\tLoss: 0.628372\n",
      "Train Epoch: 8 [41600/50000 (83%)]\tLoss: 1.707162\n",
      "Train Epoch: 8 [42000/50000 (84%)]\tLoss: 0.857753\n",
      "Train Epoch: 8 [42400/50000 (85%)]\tLoss: 0.033467\n",
      "Train Epoch: 8 [42800/50000 (86%)]\tLoss: 0.410826\n",
      "Train Epoch: 8 [43200/50000 (86%)]\tLoss: 0.227538\n",
      "Train Epoch: 8 [43600/50000 (87%)]\tLoss: 0.404263\n",
      "Train Epoch: 8 [44000/50000 (88%)]\tLoss: 0.663733\n",
      "Train Epoch: 8 [44400/50000 (89%)]\tLoss: 0.364154\n",
      "Train Epoch: 8 [44800/50000 (90%)]\tLoss: 0.384358\n",
      "Train Epoch: 8 [45200/50000 (90%)]\tLoss: 0.388537\n",
      "Train Epoch: 8 [45600/50000 (91%)]\tLoss: 1.267463\n",
      "Train Epoch: 8 [46000/50000 (92%)]\tLoss: 0.589201\n",
      "Train Epoch: 8 [46400/50000 (93%)]\tLoss: 0.437010\n",
      "Train Epoch: 8 [46800/50000 (94%)]\tLoss: 1.816784\n",
      "Train Epoch: 8 [47200/50000 (94%)]\tLoss: 0.596641\n",
      "Train Epoch: 8 [47600/50000 (95%)]\tLoss: 1.789370\n",
      "Train Epoch: 8 [48000/50000 (96%)]\tLoss: 0.739261\n",
      "Train Epoch: 8 [48400/50000 (97%)]\tLoss: 0.381676\n",
      "Train Epoch: 8 [48800/50000 (98%)]\tLoss: 0.073007\n",
      "Train Epoch: 8 [49200/50000 (98%)]\tLoss: 0.611577\n",
      "Train Epoch: 8 [49600/50000 (99%)]\tLoss: 1.271936\n",
      "Testing model for Experiment 2\n",
      "\n",
      "Test set: Average loss: 0.3650, Accuracy: 6155/10000 (62%)\n",
      "\n",
      "Training model for Experiment 2\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 0.502604\n",
      "Train Epoch: 9 [400/50000 (1%)]\tLoss: 0.006144\n",
      "Train Epoch: 9 [800/50000 (2%)]\tLoss: 0.111008\n",
      "Train Epoch: 9 [1200/50000 (2%)]\tLoss: 0.053744\n",
      "Train Epoch: 9 [1600/50000 (3%)]\tLoss: 0.318523\n",
      "Train Epoch: 9 [2000/50000 (4%)]\tLoss: 1.149760\n",
      "Train Epoch: 9 [2400/50000 (5%)]\tLoss: 0.096503\n",
      "Train Epoch: 9 [2800/50000 (6%)]\tLoss: 0.117224\n",
      "Train Epoch: 9 [3200/50000 (6%)]\tLoss: 0.509090\n",
      "Train Epoch: 9 [3600/50000 (7%)]\tLoss: 0.160243\n",
      "Train Epoch: 9 [4000/50000 (8%)]\tLoss: 0.393353\n",
      "Train Epoch: 9 [4400/50000 (9%)]\tLoss: 0.205239\n",
      "Train Epoch: 9 [4800/50000 (10%)]\tLoss: 0.367468\n",
      "Train Epoch: 9 [5200/50000 (10%)]\tLoss: 0.915409\n",
      "Train Epoch: 9 [5600/50000 (11%)]\tLoss: 0.073747\n",
      "Train Epoch: 9 [6000/50000 (12%)]\tLoss: 0.005080\n",
      "Train Epoch: 9 [6400/50000 (13%)]\tLoss: 0.763786\n",
      "Train Epoch: 9 [6800/50000 (14%)]\tLoss: 0.111985\n",
      "Train Epoch: 9 [7200/50000 (14%)]\tLoss: 0.011801\n",
      "Train Epoch: 9 [7600/50000 (15%)]\tLoss: 0.164249\n",
      "Train Epoch: 9 [8000/50000 (16%)]\tLoss: 0.260701\n",
      "Train Epoch: 9 [8400/50000 (17%)]\tLoss: 2.679719\n",
      "Train Epoch: 9 [8800/50000 (18%)]\tLoss: 0.802994\n",
      "Train Epoch: 9 [9200/50000 (18%)]\tLoss: 0.020719\n",
      "Train Epoch: 9 [9600/50000 (19%)]\tLoss: 1.020019\n",
      "Train Epoch: 9 [10000/50000 (20%)]\tLoss: 1.645783\n",
      "Train Epoch: 9 [10400/50000 (21%)]\tLoss: 0.009490\n",
      "Train Epoch: 9 [10800/50000 (22%)]\tLoss: 0.734332\n",
      "Train Epoch: 9 [11200/50000 (22%)]\tLoss: 0.085934\n",
      "Train Epoch: 9 [11600/50000 (23%)]\tLoss: 0.106678\n",
      "Train Epoch: 9 [12000/50000 (24%)]\tLoss: 0.003864\n",
      "Train Epoch: 9 [12400/50000 (25%)]\tLoss: 0.008905\n",
      "Train Epoch: 9 [12800/50000 (26%)]\tLoss: 0.770010\n",
      "Train Epoch: 9 [13200/50000 (26%)]\tLoss: 2.155614\n",
      "Train Epoch: 9 [13600/50000 (27%)]\tLoss: 0.215201\n",
      "Train Epoch: 9 [14000/50000 (28%)]\tLoss: 0.790150\n",
      "Train Epoch: 9 [14400/50000 (29%)]\tLoss: 0.146547\n",
      "Train Epoch: 9 [14800/50000 (30%)]\tLoss: 0.366020\n",
      "Train Epoch: 9 [15200/50000 (30%)]\tLoss: 0.392728\n",
      "Train Epoch: 9 [15600/50000 (31%)]\tLoss: 1.558590\n",
      "Train Epoch: 9 [16000/50000 (32%)]\tLoss: 0.274732\n",
      "Train Epoch: 9 [16400/50000 (33%)]\tLoss: 0.651811\n",
      "Train Epoch: 9 [16800/50000 (34%)]\tLoss: 1.033900\n",
      "Train Epoch: 9 [17200/50000 (34%)]\tLoss: 0.233125\n",
      "Train Epoch: 9 [17600/50000 (35%)]\tLoss: 0.020290\n",
      "Train Epoch: 9 [18000/50000 (36%)]\tLoss: 1.100278\n",
      "Train Epoch: 9 [18400/50000 (37%)]\tLoss: 1.026463\n",
      "Train Epoch: 9 [18800/50000 (38%)]\tLoss: 0.260357\n",
      "Train Epoch: 9 [19200/50000 (38%)]\tLoss: 0.024726\n",
      "Train Epoch: 9 [19600/50000 (39%)]\tLoss: 0.003396\n",
      "Train Epoch: 9 [20000/50000 (40%)]\tLoss: 0.014791\n",
      "Train Epoch: 9 [20400/50000 (41%)]\tLoss: 1.252360\n",
      "Train Epoch: 9 [20800/50000 (42%)]\tLoss: 1.018177\n",
      "Train Epoch: 9 [21200/50000 (42%)]\tLoss: 0.277749\n",
      "Train Epoch: 9 [21600/50000 (43%)]\tLoss: 2.380877\n",
      "Train Epoch: 9 [22000/50000 (44%)]\tLoss: 0.718004\n",
      "Train Epoch: 9 [22400/50000 (45%)]\tLoss: 0.526430\n",
      "Train Epoch: 9 [22800/50000 (46%)]\tLoss: 0.592915\n",
      "Train Epoch: 9 [23200/50000 (46%)]\tLoss: 0.474708\n",
      "Train Epoch: 9 [23600/50000 (47%)]\tLoss: 0.174986\n",
      "Train Epoch: 9 [24000/50000 (48%)]\tLoss: 0.751776\n",
      "Train Epoch: 9 [24400/50000 (49%)]\tLoss: 0.379844\n",
      "Train Epoch: 9 [24800/50000 (50%)]\tLoss: 0.083223\n",
      "Train Epoch: 9 [25200/50000 (50%)]\tLoss: 1.476999\n",
      "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 0.180028\n",
      "Train Epoch: 9 [26000/50000 (52%)]\tLoss: 0.002757\n",
      "Train Epoch: 9 [26400/50000 (53%)]\tLoss: 0.597206\n",
      "Train Epoch: 9 [26800/50000 (54%)]\tLoss: 0.481458\n",
      "Train Epoch: 9 [27200/50000 (54%)]\tLoss: 0.024966\n",
      "Train Epoch: 9 [27600/50000 (55%)]\tLoss: 1.183594\n",
      "Train Epoch: 9 [28000/50000 (56%)]\tLoss: 0.377989\n",
      "Train Epoch: 9 [28400/50000 (57%)]\tLoss: 0.036524\n",
      "Train Epoch: 9 [28800/50000 (58%)]\tLoss: 0.868822\n",
      "Train Epoch: 9 [29200/50000 (58%)]\tLoss: 0.008256\n",
      "Train Epoch: 9 [29600/50000 (59%)]\tLoss: 0.192172\n",
      "Train Epoch: 9 [30000/50000 (60%)]\tLoss: 0.802902\n",
      "Train Epoch: 9 [30400/50000 (61%)]\tLoss: 1.321033\n",
      "Train Epoch: 9 [30800/50000 (62%)]\tLoss: 0.352310\n",
      "Train Epoch: 9 [31200/50000 (62%)]\tLoss: 0.204694\n",
      "Train Epoch: 9 [31600/50000 (63%)]\tLoss: 0.788609\n",
      "Train Epoch: 9 [32000/50000 (64%)]\tLoss: 0.282029\n",
      "Train Epoch: 9 [32400/50000 (65%)]\tLoss: 0.504485\n",
      "Train Epoch: 9 [32800/50000 (66%)]\tLoss: 0.469307\n",
      "Train Epoch: 9 [33200/50000 (66%)]\tLoss: 1.597695\n",
      "Train Epoch: 9 [33600/50000 (67%)]\tLoss: 1.397106\n",
      "Train Epoch: 9 [34000/50000 (68%)]\tLoss: 0.425981\n",
      "Train Epoch: 9 [34400/50000 (69%)]\tLoss: 1.640877\n",
      "Train Epoch: 9 [34800/50000 (70%)]\tLoss: 0.363544\n",
      "Train Epoch: 9 [35200/50000 (70%)]\tLoss: 0.975787\n",
      "Train Epoch: 9 [35600/50000 (71%)]\tLoss: 0.796290\n",
      "Train Epoch: 9 [36000/50000 (72%)]\tLoss: 0.997918\n",
      "Train Epoch: 9 [36400/50000 (73%)]\tLoss: 0.583647\n",
      "Train Epoch: 9 [36800/50000 (74%)]\tLoss: 0.519148\n",
      "Train Epoch: 9 [37200/50000 (74%)]\tLoss: 0.102680\n",
      "Train Epoch: 9 [37600/50000 (75%)]\tLoss: 1.065416\n",
      "Train Epoch: 9 [38000/50000 (76%)]\tLoss: 0.840581\n",
      "Train Epoch: 9 [38400/50000 (77%)]\tLoss: 0.118720\n",
      "Train Epoch: 9 [38800/50000 (78%)]\tLoss: 0.542394\n",
      "Train Epoch: 9 [39200/50000 (78%)]\tLoss: 1.853505\n",
      "Train Epoch: 9 [39600/50000 (79%)]\tLoss: 0.629753\n",
      "Train Epoch: 9 [40000/50000 (80%)]\tLoss: 0.196949\n",
      "Train Epoch: 9 [40400/50000 (81%)]\tLoss: 0.588077\n",
      "Train Epoch: 9 [40800/50000 (82%)]\tLoss: 0.001565\n",
      "Train Epoch: 9 [41200/50000 (82%)]\tLoss: 0.030781\n",
      "Train Epoch: 9 [41600/50000 (83%)]\tLoss: 1.148061\n",
      "Train Epoch: 9 [42000/50000 (84%)]\tLoss: 0.102267\n",
      "Train Epoch: 9 [42400/50000 (85%)]\tLoss: 0.242968\n",
      "Train Epoch: 9 [42800/50000 (86%)]\tLoss: 0.200131\n",
      "Train Epoch: 9 [43200/50000 (86%)]\tLoss: 1.264366\n",
      "Train Epoch: 9 [43600/50000 (87%)]\tLoss: 0.222149\n",
      "Train Epoch: 9 [44000/50000 (88%)]\tLoss: 0.090940\n",
      "Train Epoch: 9 [44400/50000 (89%)]\tLoss: 0.529107\n",
      "Train Epoch: 9 [44800/50000 (90%)]\tLoss: 0.543238\n",
      "Train Epoch: 9 [45200/50000 (90%)]\tLoss: 2.531723\n",
      "Train Epoch: 9 [45600/50000 (91%)]\tLoss: 0.262455\n",
      "Train Epoch: 9 [46000/50000 (92%)]\tLoss: 0.013270\n",
      "Train Epoch: 9 [46400/50000 (93%)]\tLoss: 0.359169\n",
      "Train Epoch: 9 [46800/50000 (94%)]\tLoss: 0.226040\n",
      "Train Epoch: 9 [47200/50000 (94%)]\tLoss: 0.009955\n",
      "Train Epoch: 9 [47600/50000 (95%)]\tLoss: 2.914237\n",
      "Train Epoch: 9 [48000/50000 (96%)]\tLoss: 1.358154\n",
      "Train Epoch: 9 [48400/50000 (97%)]\tLoss: 0.022707\n",
      "Train Epoch: 9 [48800/50000 (98%)]\tLoss: 0.272955\n",
      "Train Epoch: 9 [49200/50000 (98%)]\tLoss: 0.280702\n",
      "Train Epoch: 9 [49600/50000 (99%)]\tLoss: 2.016258\n",
      "Testing model for Experiment 2\n",
      "\n",
      "Test set: Average loss: 0.3723, Accuracy: 6191/10000 (62%)\n",
      "\n",
      "Training model for Experiment 2\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLoss: 0.006421\n",
      "Train Epoch: 10 [400/50000 (1%)]\tLoss: 0.014787\n",
      "Train Epoch: 10 [800/50000 (2%)]\tLoss: 0.638992\n",
      "Train Epoch: 10 [1200/50000 (2%)]\tLoss: 0.866575\n",
      "Train Epoch: 10 [1600/50000 (3%)]\tLoss: 0.042934\n",
      "Train Epoch: 10 [2000/50000 (4%)]\tLoss: 0.015158\n",
      "Train Epoch: 10 [2400/50000 (5%)]\tLoss: 0.025701\n",
      "Train Epoch: 10 [2800/50000 (6%)]\tLoss: 0.151610\n",
      "Train Epoch: 10 [3200/50000 (6%)]\tLoss: 0.693970\n",
      "Train Epoch: 10 [3600/50000 (7%)]\tLoss: 0.794527\n",
      "Train Epoch: 10 [4000/50000 (8%)]\tLoss: 0.321881\n",
      "Train Epoch: 10 [4400/50000 (9%)]\tLoss: 1.036302\n",
      "Train Epoch: 10 [4800/50000 (10%)]\tLoss: 0.000758\n",
      "Train Epoch: 10 [5200/50000 (10%)]\tLoss: 1.296598\n",
      "Train Epoch: 10 [5600/50000 (11%)]\tLoss: 0.086127\n",
      "Train Epoch: 10 [6000/50000 (12%)]\tLoss: 1.071391\n",
      "Train Epoch: 10 [6400/50000 (13%)]\tLoss: 2.106014\n",
      "Train Epoch: 10 [6800/50000 (14%)]\tLoss: 0.590577\n",
      "Train Epoch: 10 [7200/50000 (14%)]\tLoss: 0.324207\n",
      "Train Epoch: 10 [7600/50000 (15%)]\tLoss: 0.582985\n",
      "Train Epoch: 10 [8000/50000 (16%)]\tLoss: 0.897946\n",
      "Train Epoch: 10 [8400/50000 (17%)]\tLoss: 1.369099\n",
      "Train Epoch: 10 [8800/50000 (18%)]\tLoss: 0.439141\n",
      "Train Epoch: 10 [9200/50000 (18%)]\tLoss: 0.286141\n",
      "Train Epoch: 10 [9600/50000 (19%)]\tLoss: 0.525341\n",
      "Train Epoch: 10 [10000/50000 (20%)]\tLoss: 0.272751\n",
      "Train Epoch: 10 [10400/50000 (21%)]\tLoss: 0.065807\n",
      "Train Epoch: 10 [10800/50000 (22%)]\tLoss: 0.392344\n",
      "Train Epoch: 10 [11200/50000 (22%)]\tLoss: 0.401487\n",
      "Train Epoch: 10 [11600/50000 (23%)]\tLoss: 0.129113\n",
      "Train Epoch: 10 [12000/50000 (24%)]\tLoss: 0.382682\n",
      "Train Epoch: 10 [12400/50000 (25%)]\tLoss: 0.755524\n",
      "Train Epoch: 10 [12800/50000 (26%)]\tLoss: 1.260648\n",
      "Train Epoch: 10 [13200/50000 (26%)]\tLoss: 0.279025\n",
      "Train Epoch: 10 [13600/50000 (27%)]\tLoss: 0.137790\n",
      "Train Epoch: 10 [14000/50000 (28%)]\tLoss: 0.102494\n",
      "Train Epoch: 10 [14400/50000 (29%)]\tLoss: 0.553281\n",
      "Train Epoch: 10 [14800/50000 (30%)]\tLoss: 0.024433\n",
      "Train Epoch: 10 [15200/50000 (30%)]\tLoss: 0.102557\n",
      "Train Epoch: 10 [15600/50000 (31%)]\tLoss: 0.017313\n",
      "Train Epoch: 10 [16000/50000 (32%)]\tLoss: 0.572392\n",
      "Train Epoch: 10 [16400/50000 (33%)]\tLoss: 0.241119\n",
      "Train Epoch: 10 [16800/50000 (34%)]\tLoss: 0.604564\n",
      "Train Epoch: 10 [17200/50000 (34%)]\tLoss: 1.212520\n",
      "Train Epoch: 10 [17600/50000 (35%)]\tLoss: 0.025327\n",
      "Train Epoch: 10 [18000/50000 (36%)]\tLoss: 0.772199\n",
      "Train Epoch: 10 [18400/50000 (37%)]\tLoss: 0.148743\n",
      "Train Epoch: 10 [18800/50000 (38%)]\tLoss: 0.069260\n",
      "Train Epoch: 10 [19200/50000 (38%)]\tLoss: 0.017906\n",
      "Train Epoch: 10 [19600/50000 (39%)]\tLoss: 0.887226\n",
      "Train Epoch: 10 [20000/50000 (40%)]\tLoss: 0.018127\n",
      "Train Epoch: 10 [20400/50000 (41%)]\tLoss: 0.148569\n",
      "Train Epoch: 10 [20800/50000 (42%)]\tLoss: 0.596378\n",
      "Train Epoch: 10 [21200/50000 (42%)]\tLoss: 0.266612\n",
      "Train Epoch: 10 [21600/50000 (43%)]\tLoss: 0.248914\n",
      "Train Epoch: 10 [22000/50000 (44%)]\tLoss: 0.079241\n",
      "Train Epoch: 10 [22400/50000 (45%)]\tLoss: 0.134007\n",
      "Train Epoch: 10 [22800/50000 (46%)]\tLoss: 0.260266\n",
      "Train Epoch: 10 [23200/50000 (46%)]\tLoss: 1.167778\n",
      "Train Epoch: 10 [23600/50000 (47%)]\tLoss: 0.426856\n",
      "Train Epoch: 10 [24000/50000 (48%)]\tLoss: 1.308651\n",
      "Train Epoch: 10 [24400/50000 (49%)]\tLoss: 0.123427\n",
      "Train Epoch: 10 [24800/50000 (50%)]\tLoss: 0.263641\n",
      "Train Epoch: 10 [25200/50000 (50%)]\tLoss: 1.679452\n",
      "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 0.174611\n",
      "Train Epoch: 10 [26000/50000 (52%)]\tLoss: 0.586898\n",
      "Train Epoch: 10 [26400/50000 (53%)]\tLoss: 0.592959\n",
      "Train Epoch: 10 [26800/50000 (54%)]\tLoss: 0.246073\n",
      "Train Epoch: 10 [27200/50000 (54%)]\tLoss: 0.000575\n",
      "Train Epoch: 10 [27600/50000 (55%)]\tLoss: 0.923880\n",
      "Train Epoch: 10 [28000/50000 (56%)]\tLoss: 0.299981\n",
      "Train Epoch: 10 [28400/50000 (57%)]\tLoss: 1.377160\n",
      "Train Epoch: 10 [28800/50000 (58%)]\tLoss: 0.218452\n",
      "Train Epoch: 10 [29200/50000 (58%)]\tLoss: 1.006733\n",
      "Train Epoch: 10 [29600/50000 (59%)]\tLoss: 0.893757\n",
      "Train Epoch: 10 [30000/50000 (60%)]\tLoss: 0.892191\n",
      "Train Epoch: 10 [30400/50000 (61%)]\tLoss: 0.140912\n",
      "Train Epoch: 10 [30800/50000 (62%)]\tLoss: 0.036286\n",
      "Train Epoch: 10 [31200/50000 (62%)]\tLoss: 0.562118\n",
      "Train Epoch: 10 [31600/50000 (63%)]\tLoss: 0.390943\n",
      "Train Epoch: 10 [32000/50000 (64%)]\tLoss: 0.416415\n",
      "Train Epoch: 10 [32400/50000 (65%)]\tLoss: 0.018622\n",
      "Train Epoch: 10 [32800/50000 (66%)]\tLoss: 0.306138\n",
      "Train Epoch: 10 [33200/50000 (66%)]\tLoss: 0.466807\n",
      "Train Epoch: 10 [33600/50000 (67%)]\tLoss: 0.813950\n",
      "Train Epoch: 10 [34000/50000 (68%)]\tLoss: 0.535799\n",
      "Train Epoch: 10 [34400/50000 (69%)]\tLoss: 1.238163\n",
      "Train Epoch: 10 [34800/50000 (70%)]\tLoss: 0.122465\n",
      "Train Epoch: 10 [35200/50000 (70%)]\tLoss: 0.628619\n",
      "Train Epoch: 10 [35600/50000 (71%)]\tLoss: 0.628607\n",
      "Train Epoch: 10 [36000/50000 (72%)]\tLoss: 0.277445\n",
      "Train Epoch: 10 [36400/50000 (73%)]\tLoss: 0.088668\n",
      "Train Epoch: 10 [36800/50000 (74%)]\tLoss: 0.939071\n",
      "Train Epoch: 10 [37200/50000 (74%)]\tLoss: 0.054485\n",
      "Train Epoch: 10 [37600/50000 (75%)]\tLoss: 1.681494\n",
      "Train Epoch: 10 [38000/50000 (76%)]\tLoss: 1.263830\n",
      "Train Epoch: 10 [38400/50000 (77%)]\tLoss: 0.935867\n",
      "Train Epoch: 10 [38800/50000 (78%)]\tLoss: 0.377393\n",
      "Train Epoch: 10 [39200/50000 (78%)]\tLoss: 2.012439\n",
      "Train Epoch: 10 [39600/50000 (79%)]\tLoss: 1.136780\n",
      "Train Epoch: 10 [40000/50000 (80%)]\tLoss: 0.656864\n",
      "Train Epoch: 10 [40400/50000 (81%)]\tLoss: 2.448444\n",
      "Train Epoch: 10 [40800/50000 (82%)]\tLoss: 0.061734\n",
      "Train Epoch: 10 [41200/50000 (82%)]\tLoss: 0.658751\n",
      "Train Epoch: 10 [41600/50000 (83%)]\tLoss: 0.388403\n",
      "Train Epoch: 10 [42000/50000 (84%)]\tLoss: 0.671388\n",
      "Train Epoch: 10 [42400/50000 (85%)]\tLoss: 0.376377\n",
      "Train Epoch: 10 [42800/50000 (86%)]\tLoss: 0.001329\n",
      "Train Epoch: 10 [43200/50000 (86%)]\tLoss: 0.158129\n",
      "Train Epoch: 10 [43600/50000 (87%)]\tLoss: 1.064041\n",
      "Train Epoch: 10 [44000/50000 (88%)]\tLoss: 0.231640\n",
      "Train Epoch: 10 [44400/50000 (89%)]\tLoss: 0.336402\n",
      "Train Epoch: 10 [44800/50000 (90%)]\tLoss: 0.529348\n",
      "Train Epoch: 10 [45200/50000 (90%)]\tLoss: 1.046306\n",
      "Train Epoch: 10 [45600/50000 (91%)]\tLoss: 0.903760\n",
      "Train Epoch: 10 [46000/50000 (92%)]\tLoss: 0.027737\n",
      "Train Epoch: 10 [46400/50000 (93%)]\tLoss: 1.587315\n",
      "Train Epoch: 10 [46800/50000 (94%)]\tLoss: 0.284502\n",
      "Train Epoch: 10 [47200/50000 (94%)]\tLoss: 0.102899\n",
      "Train Epoch: 10 [47600/50000 (95%)]\tLoss: 0.458508\n",
      "Train Epoch: 10 [48000/50000 (96%)]\tLoss: 1.311225\n",
      "Train Epoch: 10 [48400/50000 (97%)]\tLoss: 1.203138\n",
      "Train Epoch: 10 [48800/50000 (98%)]\tLoss: 0.412500\n",
      "Train Epoch: 10 [49200/50000 (98%)]\tLoss: 0.081340\n",
      "Train Epoch: 10 [49600/50000 (99%)]\tLoss: 0.887622\n",
      "Testing model for Experiment 2\n",
      "\n",
      "Test set: Average loss: 0.3925, Accuracy: 6086/10000 (61%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run training and testing for ten epochs\n",
    "for epoch in range(1, 11):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Experiment 3 (20/100 points): Hyperparameter Tuning**\n",
    "#### Explore different hyper-parameters, including learning rate, batch size, and number of epochs. Plus, use a validation set to tune the hyper-parameters and report the results on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### I'll be increasing the batch size, decreasing the learning rate and increasing the number of epochs. The goal is to get better results than the previous experiments by also validating the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using numpy and SubsetRandomSampler for shuffling the dataset\n",
    "import numpy as np\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Downloading the CIFAR-10 dataset with the customized image transformation (may take a while, especially the first time and with bad internet connection)\n",
    "cifar_train_data = datasets.CIFAR10(root='./data', train=True, download=True, transform=customize_image_transforming)\n",
    "cifar_test_data = datasets.CIFAR10(root='./data', train=False, download=True, transform=customize_image_transforming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the training set into training and validation sets\n",
    "num_train = len(cifar_train_data)\n",
    "indices = list(range(num_train))    # Indicess for shuffling\n",
    "split = int(num_train * 0.8)  # 80% for training, 20% for validation\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# Splitting the indices for training and validation\n",
    "train_idx, valid_idx = indices[:split], indices[split:]\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Altering the batch size in order to test the speed and efficiency of the model, as well as assigning workers and pin memory to speed up the process\n",
    "# This function will be used for testing different batch sizes\n",
    "def get_data_loaders(batch_size):\n",
    "    train_loader = torch.utils.data.DataLoader(cifar_train_data, batch_size=batch_size, sampler=train_sampler, num_workers=4, pin_memory=True)\n",
    "    valid_loader = torch.utils.data.DataLoader(cifar_train_data, batch_size=batch_size, sampler=valid_sampler, num_workers=4, pin_memory=True)\n",
    "    test_loader = torch.utils.data.DataLoader(cifar_test_data, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "    return train_loader, valid_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layers for third experiment - Not much changes from the past experiment\n",
    "convolutional_layer = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1).to(gpu_device)   # 32 filters, 3x3 kernel and ReLU activation function, directed to the gpu processor\n",
    "convolutional_layer2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1).to(gpu_device)    # 128 filters, 3x3 kernel and ReLU activation function, directed to the gpu processor\n",
    "dropout_layer = nn.Dropout(0.25).to(gpu_device)   # Dropout layer with 25% probability, directed to the gpu processor\n",
    "max_pooling_layer = nn.MaxPool2d(2, 2).to(gpu_device)   # Max pooling layer with 2x2 pool size, directed to the gpu processor\n",
    "dense_layer = nn.Linear(64 * 16 * 16, 256).to(gpu_device)   # Dense layer with 256 units and ReLU activation, directed to the gpu processor\n",
    "dense_layer2 = nn.Linear(256, 128).to(gpu_device)   # Dense layer with 128 units and ReLU activation, directed to the gpu processor\n",
    "dense_output_layer = nn.Linear(128, 10).to(gpu_device)  # Dense output layer, transforming the output to a prediction of 10 classes, directed to the gpu processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set loss criterion\n",
    "loss_criterion = torch.nn.NLLLoss()\n",
    "\n",
    "# Function to get the optimizer with a specific learning rate\n",
    "def get_optimizer(learning_rate):\n",
    "    return optim.Adam([{'params': convolutional_layer.parameters()},\n",
    "                        {'params': convolutional_layer2.parameters()},\n",
    "                        {'params': dropout_layer.parameters()},\n",
    "                        {'params': dense_layer.parameters()},\n",
    "                        {'params': dense_layer2.parameters()},\n",
    "                        {'params': dense_output_layer.parameters()}], lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "def train(epoch, train_loader, optimizer):\n",
    "    # It's only necessary to set the training mode for dropout and batch normalization layers\n",
    "    print(f'Training model for Experiment 3')\n",
    "    for batch_index, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(gpu_device), target.to(gpu_device)\n",
    "        optimizer.zero_grad()\n",
    "        tensor_x = relu(convolutional_layer(data))\n",
    "        tensor_x = relu(convolutional_layer2(tensor_x))\n",
    "        tensor_x = max_pooling_layer(tensor_x)\n",
    "        tensor_x = tensor_x.view(-1, 64 * 16 * 16)  # Flatten layer\n",
    "        tensor_x = relu(dense_layer(tensor_x))\n",
    "        tensor_x = dropout_layer(tensor_x)\n",
    "        tensor_x = relu(dense_layer2(tensor_x))\n",
    "        tensor_x = dropout_layer(tensor_x)\n",
    "        tensor_x = dense_output_layer(tensor_x)\n",
    "        training_loss = log_softmax(tensor_x, dim=1)  # Apply log-softmax\n",
    "        training_loss = loss_criterion(training_loss, target)\n",
    "        training_loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_index % 100 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_index * len(data)}/{len(train_loader.dataset)} ({100. * batch_index / len(train_loader):.0f}%)]\\tLoss: {training_loss.item():.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the model\n",
    "def test(test_loader):\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    print(f'Testing model for Experiment 3')\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(gpu_device), target.to(gpu_device)\n",
    "            tensor_x = relu(convolutional_layer(data))\n",
    "            tensor_x = relu(convolutional_layer2(tensor_x))\n",
    "            tensor_x = max_pooling_layer(tensor_x)\n",
    "            tensor_x = tensor_x.view(-1, 64 * 16 * 16)  # Flatten layer\n",
    "            tensor_x = relu(dense_layer(tensor_x))\n",
    "            tensor_x = dropout_layer(tensor_x)\n",
    "            tensor_x = relu(dense_layer2(tensor_x))\n",
    "            tensor_x = dropout_layer(tensor_x)\n",
    "            tensor_x = dense_output_layer(tensor_x)\n",
    "            test_loss_prob = log_softmax(tensor_x, dim=1)  # Apply log-softmax\n",
    "            test_loss += loss_criterion(test_loss_prob, target).item()\n",
    "            pred = test_loss_prob.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({accuracy:.0f}%)\\n')\n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation function\n",
    "def validate_model(val_loader):\n",
    "    print(f'Validating model for Experiment 3')\n",
    "    valid_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            data, target = data.to(gpu_device), target.to(gpu_device)\n",
    "            tensor_x = relu(convolutional_layer(data))\n",
    "            tensor_x = relu(convolutional_layer2(tensor_x))\n",
    "            tensor_x = max_pooling_layer(tensor_x)\n",
    "            tensor_x = tensor_x.view(-1, 64 * 16 * 16)  # Flatten layer\n",
    "            tensor_x = relu(dense_layer(tensor_x))\n",
    "            tensor_x = dropout_layer(tensor_x)\n",
    "            tensor_x = relu(dense_layer2(tensor_x))\n",
    "            tensor_x = dropout_layer(tensor_x)\n",
    "            tensor_x = dense_output_layer(tensor_x)\n",
    "            validate_loss_prob = log_softmax(tensor_x, dim=1)  # Apply log-softmax\n",
    "            valid_loss += loss_criterion(validate_loss_prob, target).item()\n",
    "            pred = validate_loss_prob.argmax(dim=1, keepdim=True)\n",
    "            total += target.size(0)\n",
    "            correct += (pred == target).sum().item()\n",
    "    accuracy = 100 * correct / len(val_loader.dataset)\n",
    "    avg_loss = valid_loss / len(val_loader)\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set GPU device to improve performance and speed\n",
    "gpu_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment with lr=0.001, batch_size=128, epochs=10\n",
      "Training model for Experiment 3\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 0.379387\n",
      "Train Epoch: 1 [12800/50000 (32%)]\tLoss: 0.215443\n",
      "Train Epoch: 1 [25600/50000 (64%)]\tLoss: 0.220473\n",
      "Train Epoch: 1 [38400/50000 (96%)]\tLoss: 0.128500\n",
      "Training model for Experiment 3\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 0.105479\n",
      "Train Epoch: 2 [12800/50000 (32%)]\tLoss: 0.167410\n",
      "Train Epoch: 2 [25600/50000 (64%)]\tLoss: 0.098701\n",
      "Train Epoch: 2 [38400/50000 (96%)]\tLoss: 0.044359\n",
      "Training model for Experiment 3\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 0.107503\n",
      "Train Epoch: 3 [12800/50000 (32%)]\tLoss: 0.102005\n",
      "Train Epoch: 3 [25600/50000 (64%)]\tLoss: 0.194630\n",
      "Train Epoch: 3 [38400/50000 (96%)]\tLoss: 0.121953\n",
      "Training model for Experiment 3\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 0.105054\n",
      "Train Epoch: 4 [12800/50000 (32%)]\tLoss: 0.047363\n",
      "Train Epoch: 4 [25600/50000 (64%)]\tLoss: 0.158953\n",
      "Train Epoch: 4 [38400/50000 (96%)]\tLoss: 0.047313\n",
      "Training model for Experiment 3\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 0.059480\n",
      "Train Epoch: 5 [12800/50000 (32%)]\tLoss: 0.163105\n",
      "Train Epoch: 5 [25600/50000 (64%)]\tLoss: 0.077290\n",
      "Train Epoch: 5 [38400/50000 (96%)]\tLoss: 0.041856\n",
      "Training model for Experiment 3\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 0.044099\n",
      "Train Epoch: 6 [12800/50000 (32%)]\tLoss: 0.019315\n",
      "Train Epoch: 6 [25600/50000 (64%)]\tLoss: 0.031126\n",
      "Train Epoch: 6 [38400/50000 (96%)]\tLoss: 0.011286\n",
      "Training model for Experiment 3\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 0.129972\n",
      "Train Epoch: 7 [12800/50000 (32%)]\tLoss: 0.043844\n",
      "Train Epoch: 7 [25600/50000 (64%)]\tLoss: 0.041621\n",
      "Train Epoch: 7 [38400/50000 (96%)]\tLoss: 0.038858\n",
      "Training model for Experiment 3\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 0.056327\n",
      "Train Epoch: 8 [12800/50000 (32%)]\tLoss: 0.045194\n",
      "Train Epoch: 8 [25600/50000 (64%)]\tLoss: 0.044963\n",
      "Train Epoch: 8 [38400/50000 (96%)]\tLoss: 0.151925\n",
      "Training model for Experiment 3\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 0.097669\n",
      "Train Epoch: 9 [12800/50000 (32%)]\tLoss: 0.023667\n",
      "Train Epoch: 9 [25600/50000 (64%)]\tLoss: 0.036526\n",
      "Train Epoch: 9 [38400/50000 (96%)]\tLoss: 0.141648\n",
      "Training model for Experiment 3\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLoss: 0.176458\n",
      "Train Epoch: 10 [12800/50000 (32%)]\tLoss: 0.055558\n",
      "Train Epoch: 10 [25600/50000 (64%)]\tLoss: 0.156696\n",
      "Train Epoch: 10 [38400/50000 (96%)]\tLoss: 0.062148\n",
      "Validating model for Experiment 3\n",
      "Validation loss: 2.1995, Validation accuracy: 266.52%\n",
      "Testing model for Experiment 3\n",
      "\n",
      "Test set: Average loss: 0.0181, Accuracy: 6638/10000 (66%)\n",
      "\n",
      "Running experiment with lr=0.0005, batch_size=64, epochs=15\n",
      "Training model for Experiment 3\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 0.012086\n",
      "Train Epoch: 1 [6400/50000 (16%)]\tLoss: 0.078751\n",
      "Train Epoch: 1 [12800/50000 (32%)]\tLoss: 0.004461\n",
      "Train Epoch: 1 [19200/50000 (48%)]\tLoss: 0.015528\n",
      "Train Epoch: 1 [25600/50000 (64%)]\tLoss: 0.053747\n",
      "Train Epoch: 1 [32000/50000 (80%)]\tLoss: 0.066401\n",
      "Train Epoch: 1 [38400/50000 (96%)]\tLoss: 0.001486\n",
      "Training model for Experiment 3\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 0.004494\n",
      "Train Epoch: 2 [6400/50000 (16%)]\tLoss: 0.008676\n",
      "Train Epoch: 2 [12800/50000 (32%)]\tLoss: 0.109235\n",
      "Train Epoch: 2 [19200/50000 (48%)]\tLoss: 0.008912\n",
      "Train Epoch: 2 [25600/50000 (64%)]\tLoss: 0.080034\n",
      "Train Epoch: 2 [32000/50000 (80%)]\tLoss: 0.031672\n",
      "Train Epoch: 2 [38400/50000 (96%)]\tLoss: 0.069322\n",
      "Training model for Experiment 3\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 0.071608\n",
      "Train Epoch: 3 [6400/50000 (16%)]\tLoss: 0.255002\n",
      "Train Epoch: 3 [12800/50000 (32%)]\tLoss: 0.115963\n",
      "Train Epoch: 3 [19200/50000 (48%)]\tLoss: 0.002468\n",
      "Train Epoch: 3 [25600/50000 (64%)]\tLoss: 0.008251\n",
      "Train Epoch: 3 [32000/50000 (80%)]\tLoss: 0.000982\n",
      "Train Epoch: 3 [38400/50000 (96%)]\tLoss: 0.008358\n",
      "Training model for Experiment 3\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 0.072558\n",
      "Train Epoch: 4 [6400/50000 (16%)]\tLoss: 0.015564\n",
      "Train Epoch: 4 [12800/50000 (32%)]\tLoss: 0.026913\n",
      "Train Epoch: 4 [19200/50000 (48%)]\tLoss: 0.108436\n",
      "Train Epoch: 4 [25600/50000 (64%)]\tLoss: 0.284368\n",
      "Train Epoch: 4 [32000/50000 (80%)]\tLoss: 0.041210\n",
      "Train Epoch: 4 [38400/50000 (96%)]\tLoss: 0.003755\n",
      "Training model for Experiment 3\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 0.034440\n",
      "Train Epoch: 5 [6400/50000 (16%)]\tLoss: 0.044316\n",
      "Train Epoch: 5 [12800/50000 (32%)]\tLoss: 0.037198\n",
      "Train Epoch: 5 [19200/50000 (48%)]\tLoss: 0.005954\n",
      "Train Epoch: 5 [25600/50000 (64%)]\tLoss: 0.038054\n",
      "Train Epoch: 5 [32000/50000 (80%)]\tLoss: 0.119549\n",
      "Train Epoch: 5 [38400/50000 (96%)]\tLoss: 0.007145\n",
      "Training model for Experiment 3\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 0.017258\n",
      "Train Epoch: 6 [6400/50000 (16%)]\tLoss: 0.029154\n",
      "Train Epoch: 6 [12800/50000 (32%)]\tLoss: 0.010401\n",
      "Train Epoch: 6 [19200/50000 (48%)]\tLoss: 0.008921\n",
      "Train Epoch: 6 [25600/50000 (64%)]\tLoss: 0.013956\n",
      "Train Epoch: 6 [32000/50000 (80%)]\tLoss: 0.014535\n",
      "Train Epoch: 6 [38400/50000 (96%)]\tLoss: 0.038794\n",
      "Training model for Experiment 3\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 0.018483\n",
      "Train Epoch: 7 [6400/50000 (16%)]\tLoss: 0.014206\n",
      "Train Epoch: 7 [12800/50000 (32%)]\tLoss: 0.008239\n",
      "Train Epoch: 7 [19200/50000 (48%)]\tLoss: 0.007809\n",
      "Train Epoch: 7 [25600/50000 (64%)]\tLoss: 0.225550\n",
      "Train Epoch: 7 [32000/50000 (80%)]\tLoss: 0.005501\n",
      "Train Epoch: 7 [38400/50000 (96%)]\tLoss: 0.024237\n",
      "Training model for Experiment 3\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 0.014852\n",
      "Train Epoch: 8 [6400/50000 (16%)]\tLoss: 0.001727\n",
      "Train Epoch: 8 [12800/50000 (32%)]\tLoss: 0.003303\n",
      "Train Epoch: 8 [19200/50000 (48%)]\tLoss: 0.115211\n",
      "Train Epoch: 8 [25600/50000 (64%)]\tLoss: 0.004150\n",
      "Train Epoch: 8 [32000/50000 (80%)]\tLoss: 0.001482\n",
      "Train Epoch: 8 [38400/50000 (96%)]\tLoss: 0.029216\n",
      "Training model for Experiment 3\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 0.123320\n",
      "Train Epoch: 9 [6400/50000 (16%)]\tLoss: 0.016288\n",
      "Train Epoch: 9 [12800/50000 (32%)]\tLoss: 0.000827\n",
      "Train Epoch: 9 [19200/50000 (48%)]\tLoss: 0.000557\n",
      "Train Epoch: 9 [25600/50000 (64%)]\tLoss: 0.008555\n",
      "Train Epoch: 9 [32000/50000 (80%)]\tLoss: 0.010445\n",
      "Train Epoch: 9 [38400/50000 (96%)]\tLoss: 0.004261\n",
      "Training model for Experiment 3\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLoss: 0.039142\n",
      "Train Epoch: 10 [6400/50000 (16%)]\tLoss: 0.018470\n",
      "Train Epoch: 10 [12800/50000 (32%)]\tLoss: 0.015155\n",
      "Train Epoch: 10 [19200/50000 (48%)]\tLoss: 0.013695\n",
      "Train Epoch: 10 [25600/50000 (64%)]\tLoss: 0.072724\n",
      "Train Epoch: 10 [32000/50000 (80%)]\tLoss: 0.000515\n",
      "Train Epoch: 10 [38400/50000 (96%)]\tLoss: 0.234917\n",
      "Training model for Experiment 3\n",
      "Train Epoch: 11 [0/50000 (0%)]\tLoss: 0.004630\n",
      "Train Epoch: 11 [6400/50000 (16%)]\tLoss: 0.018856\n",
      "Train Epoch: 11 [12800/50000 (32%)]\tLoss: 0.077425\n",
      "Train Epoch: 11 [19200/50000 (48%)]\tLoss: 0.000506\n",
      "Train Epoch: 11 [25600/50000 (64%)]\tLoss: 0.008305\n",
      "Train Epoch: 11 [32000/50000 (80%)]\tLoss: 0.004667\n",
      "Train Epoch: 11 [38400/50000 (96%)]\tLoss: 0.001237\n",
      "Training model for Experiment 3\n",
      "Train Epoch: 12 [0/50000 (0%)]\tLoss: 0.012402\n",
      "Train Epoch: 12 [6400/50000 (16%)]\tLoss: 0.008860\n",
      "Train Epoch: 12 [12800/50000 (32%)]\tLoss: 0.024181\n",
      "Train Epoch: 12 [19200/50000 (48%)]\tLoss: 0.052891\n",
      "Train Epoch: 12 [25600/50000 (64%)]\tLoss: 0.091278\n",
      "Train Epoch: 12 [32000/50000 (80%)]\tLoss: 0.013344\n",
      "Train Epoch: 12 [38400/50000 (96%)]\tLoss: 0.010628\n",
      "Training model for Experiment 3\n",
      "Train Epoch: 13 [0/50000 (0%)]\tLoss: 0.005649\n",
      "Train Epoch: 13 [6400/50000 (16%)]\tLoss: 0.048385\n",
      "Train Epoch: 13 [12800/50000 (32%)]\tLoss: 0.074231\n",
      "Train Epoch: 13 [19200/50000 (48%)]\tLoss: 0.075886\n",
      "Train Epoch: 13 [25600/50000 (64%)]\tLoss: 0.109746\n",
      "Train Epoch: 13 [32000/50000 (80%)]\tLoss: 0.001725\n",
      "Train Epoch: 13 [38400/50000 (96%)]\tLoss: 0.003169\n",
      "Training model for Experiment 3\n",
      "Train Epoch: 14 [0/50000 (0%)]\tLoss: 0.102542\n",
      "Train Epoch: 14 [6400/50000 (16%)]\tLoss: 0.011618\n",
      "Train Epoch: 14 [12800/50000 (32%)]\tLoss: 0.004492\n",
      "Train Epoch: 14 [19200/50000 (48%)]\tLoss: 0.014774\n",
      "Train Epoch: 14 [25600/50000 (64%)]\tLoss: 0.009418\n",
      "Train Epoch: 14 [32000/50000 (80%)]\tLoss: 0.002872\n",
      "Train Epoch: 14 [38400/50000 (96%)]\tLoss: 0.007104\n",
      "Training model for Experiment 3\n",
      "Train Epoch: 15 [0/50000 (0%)]\tLoss: 0.002426\n",
      "Train Epoch: 15 [6400/50000 (16%)]\tLoss: 0.026811\n",
      "Train Epoch: 15 [12800/50000 (32%)]\tLoss: 0.071706\n",
      "Train Epoch: 15 [19200/50000 (48%)]\tLoss: 0.002105\n",
      "Train Epoch: 15 [25600/50000 (64%)]\tLoss: 0.009607\n",
      "Train Epoch: 15 [32000/50000 (80%)]\tLoss: 0.029620\n",
      "Train Epoch: 15 [38400/50000 (96%)]\tLoss: 0.000868\n",
      "Validating model for Experiment 3\n",
      "Validation loss: 2.4872, Validation accuracy: 139.02%\n",
      "Testing model for Experiment 3\n",
      "\n",
      "Test set: Average loss: 0.0404, Accuracy: 6707/10000 (67%)\n",
      "\n",
      "Running experiment with lr=0.01, batch_size=256, epochs=5\n",
      "Training model for Experiment 3\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 0.017033\n",
      "Train Epoch: 1 [25600/50000 (64%)]\tLoss: 0.426312\n",
      "Training model for Experiment 3\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 0.337435\n",
      "Train Epoch: 2 [25600/50000 (64%)]\tLoss: 0.336951\n",
      "Training model for Experiment 3\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 0.281818\n",
      "Train Epoch: 3 [25600/50000 (64%)]\tLoss: 0.558631\n",
      "Training model for Experiment 3\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 0.380105\n",
      "Train Epoch: 4 [25600/50000 (64%)]\tLoss: 0.373455\n",
      "Training model for Experiment 3\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 0.462562\n",
      "Train Epoch: 5 [25600/50000 (64%)]\tLoss: 0.510711\n",
      "Validating model for Experiment 3\n",
      "Validation loss: 1.7944, Validation accuracy: 521.33%\n",
      "Testing model for Experiment 3\n",
      "\n",
      "Test set: Average loss: 0.0074, Accuracy: 5911/10000 (59%)\n",
      "\n",
      "lr=0.001, batch_size=128, epochs=10 -> Val Loss: 2.1995, Val Acc: 266.52%, Test Loss: 0.0181, Test Acc: 66.38%\n",
      "lr=0.0005, batch_size=64, epochs=15 -> Val Loss: 2.4872, Val Acc: 139.02%, Test Loss: 0.0404, Test Acc: 67.07%\n",
      "lr=0.01, batch_size=256, epochs=5 -> Val Loss: 1.7944, Val Acc: 521.33%, Test Loss: 0.0074, Test Acc: 59.11%\n"
     ]
    }
   ],
   "source": [
    "# Hyper-parameter configurations, evaluating different batch sizes, learning rates and epochs\n",
    "experiments = [\n",
    "    {'learning_rate': 0.001, 'batch_size': 128, 'epochs': 10},  # This should be the default configuration\n",
    "    {'learning_rate': 0.0005, 'batch_size': 64, 'epochs': 15},  # This should be the most accurate configuration\n",
    "    {'learning_rate': 0.01, 'batch_size': 256, 'epochs': 5},    # This should be the fastest configuration\n",
    "]\n",
    "\n",
    "# Results dictionary\n",
    "results = {}\n",
    "\n",
    "for config in experiments:\n",
    "    print(f\"Running experiment with lr={config['learning_rate']}, batch_size={config['batch_size']}, epochs={config['epochs']}\")\n",
    "\n",
    "    # Get data loaders\n",
    "    train_loader, valid_loader, test_loader = get_data_loaders(config['batch_size'])\n",
    "    \n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = get_optimizer(learning_rate=config['learning_rate'])\n",
    "    \n",
    "    # Train the model\n",
    "    for epoch in range(config['epochs']):\n",
    "        train(epoch+1, train_loader, optimizer)\n",
    "    \n",
    "    # Validate the model\n",
    "    val_loss, val_accuracy = validate_model(valid_loader)\n",
    "    print(f'Validation loss: {val_loss:.4f}, Validation accuracy: {val_accuracy:.2f}%')\n",
    "    \n",
    "    # Test the model\n",
    "    test_loss, test_accuracy = test(test_loader)\n",
    "    \n",
    "    # Save results\n",
    "    results[config['learning_rate'], config['batch_size'], config['epochs']] = (val_loss, val_accuracy, test_loss, test_accuracy)\n",
    "\n",
    "# Print results\n",
    "for params, result in results.items():\n",
    "    print(f\"lr={params[0]}, batch_size={params[1]}, epochs={params[2]} -> Val Loss: {result[0]:.4f}, Val Acc: {result[1]:.2f}%, Test Loss: {result[2]:.4f}, Test Acc: {result[3]:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(Optional) Experiment 4 (10/100 points): Advanced Techniques**\n",
    "#### Consider implementing one or more advanced techniques, such as batch normalisation, data augmentation, or transfer learning. (Even you could try more exotique architectures.) Hence, comparing the model’s performance with these techniques to the baseline model will be easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding data augmentation: random crop, random horizontal flip, random rotation, color jitter and normalization (this was already done in the last experiments, but it's important to mention it here as well)\n",
    "customize_image_transforming = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=1),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.25, contrast=0.25, saturation=0.25, hue=0.25),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maintaining the batch size from previous experiment since it got better and faster results\n",
    "cifar_train_loader = DataLoader(cifar_train_data, batch_size=256, shuffle=True, num_workers=4, pin_memory=True)\n",
    "cifar_test_loader = DataLoader(cifar_test_data, batch_size=128, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layers for fourth experiment - Added batch normalization layers for the convolutional and dense layers\n",
    "convolutional_layer = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1).to(gpu_device)   # 32 filters, 3x3 kernel and ReLU activation function, directed to the gpu processor\n",
    "convolutional_layer2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1).to(gpu_device)    # 128 filters, 3x3 kernel and ReLU activation function, directed to the gpu processor\n",
    "dropout_layer = nn.Dropout(0.25).to(gpu_device)   # Dropout layer with 25% probability, directed to the gpu processor\n",
    "max_pooling_layer = nn.MaxPool2d(2, 2).to(gpu_device)   # Max pooling layer with 2x2 pool size, directed to the gpu processor\n",
    "dense_layer = nn.Linear(64 * 16 * 16, 256).to(gpu_device)   # Dense layer with 256 units and ReLU activation, directed to the gpu processor\n",
    "dense_layer2 = nn.Linear(256, 128).to(gpu_device)   # Dense layer with 128 units and ReLU activation, directed to the gpu processor\n",
    "dense_output_layer = nn.Linear(128, 10).to(gpu_device)  # Dense output layer, transforming the output to a prediction of 10 classes, directed to the gpu processor\n",
    "batch_normalization_1 = nn.BatchNorm2d(32).to(gpu_device)\n",
    "batch_normalization_2 = nn.BatchNorm2d(64).to(gpu_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer with a lower learning rate: 0.0005\n",
    "loss_criterion = torch.nn.NLLLoss()\n",
    "adam_optimizer = optim.Adam([{'params': convolutional_layer.parameters()},\n",
    "                        {'params': convolutional_layer2.parameters()},\n",
    "                        {'params': dropout_layer.parameters()},\n",
    "                        {'params': max_pooling_layer.parameters()},\n",
    "                        {'params': dense_layer.parameters()},\n",
    "                        {'params': dense_layer2.parameters()},\n",
    "                        {'params': dense_output_layer.parameters()},\n",
    "                        {'params': batch_normalization_1.parameters()},\n",
    "                        {'params': batch_normalization_2.parameters()},], lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model for experiment 4\n",
    "def train(epoch):\n",
    "    # It's only necessary to set the training mode for dropout and batch normalization layers\n",
    "    print(f'Training model for Experiment 4')\n",
    "    for batch_index, (data, target) in enumerate(cifar_train_loader):\n",
    "        data, target = data.to(gpu_device), target.to(gpu_device)\n",
    "        adam_optimizer.zero_grad()\n",
    "        # Adding batch normalization layers to the convolutional layers sequentially to make it easier to read\n",
    "        tensor_x = relu(convolutional_layer(data))\n",
    "        tensor_x = batch_normalization_1(tensor_x)\n",
    "        tensor_x = relu(convolutional_layer2(tensor_x))\n",
    "        tensor_x = batch_normalization_2(tensor_x)\n",
    "        tensor_x = max_pooling_layer(tensor_x)\n",
    "        tensor_x = tensor_x.view(-1, 64 * 16 * 16)  # Flatten layer\n",
    "        tensor_x = relu(dense_layer(tensor_x))\n",
    "        tensor_x = dropout_layer(tensor_x)\n",
    "        tensor_x = relu(dense_layer2(tensor_x))\n",
    "        tensor_x = dropout_layer(tensor_x)\n",
    "        tensor_x = dense_output_layer(tensor_x)\n",
    "        training_loss = log_softmax(tensor_x, dim=1)  # Apply log-softmax\n",
    "        training_loss = loss_criterion(training_loss, target)\n",
    "        training_loss.backward()\n",
    "        adam_optimizer.step()\n",
    "        if batch_index % 100 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_index * len(data)}/{len(cifar_train_loader.dataset)} ({100. * batch_index / len(cifar_train_loader):.0f}%)]\\tLoss: {training_loss.item():.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the model\n",
    "def test():\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    print(f'Testing model for Experiment 4')\n",
    "    with torch.no_grad():\n",
    "        for data, target in cifar_test_loader:\n",
    "            data, target = data.to(gpu_device), target.to(gpu_device)\n",
    "            # Adding batch normalization layers to the convolutional layers sequentially to make it easier to read\n",
    "            tensor_x = relu(convolutional_layer(data))\n",
    "            tensor_x = batch_normalization_1(tensor_x)\n",
    "            tensor_x = relu(convolutional_layer2(tensor_x))\n",
    "            tensor_x = batch_normalization_2(tensor_x)\n",
    "            tensor_x = max_pooling_layer(tensor_x)\n",
    "            tensor_x = tensor_x.view(-1, 64 * 16 * 16)  # Flatten layer\n",
    "            tensor_x = relu(dense_layer(tensor_x))\n",
    "            tensor_x = dropout_layer(tensor_x)\n",
    "            tensor_x = relu(dense_layer2(tensor_x))\n",
    "            tensor_x = dropout_layer(tensor_x)\n",
    "            tensor_x = dense_output_layer(tensor_x)\n",
    "            test_loss_prob = log_softmax(tensor_x, dim=1)  # Apply log-softmax\n",
    "            test_loss += loss_criterion(test_loss_prob, target).item()\n",
    "            pred = test_loss_prob.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(cifar_test_loader.dataset)\n",
    "    accuracy = 100. * correct / len(cifar_test_loader.dataset)\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(cifar_test_loader.dataset)} ({accuracy:.0f}%)\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Experiment 4\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.314706\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 1.319792\n",
      "Testing model for Experiment 4\n",
      "\n",
      "Test set: Average loss: 0.0091, Accuracy: 5891/10000 (59%)\n",
      "\n",
      "Training model for Experiment 4\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.086420\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 0.952454\n",
      "Testing model for Experiment 4\n",
      "\n",
      "Test set: Average loss: 0.0081, Accuracy: 6410/10000 (64%)\n",
      "\n",
      "Training model for Experiment 4\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 0.906369\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 0.767351\n",
      "Testing model for Experiment 4\n",
      "\n",
      "Test set: Average loss: 0.0076, Accuracy: 6727/10000 (67%)\n",
      "\n",
      "Training model for Experiment 4\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 0.650548\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 0.623951\n",
      "Testing model for Experiment 4\n",
      "\n",
      "Test set: Average loss: 0.0077, Accuracy: 6792/10000 (68%)\n",
      "\n",
      "Training model for Experiment 4\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 0.463723\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 0.486013\n",
      "Testing model for Experiment 4\n",
      "\n",
      "Test set: Average loss: 0.0076, Accuracy: 6909/10000 (69%)\n",
      "\n",
      "Training model for Experiment 4\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 0.325712\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 0.391529\n",
      "Testing model for Experiment 4\n",
      "\n",
      "Test set: Average loss: 0.0086, Accuracy: 6886/10000 (69%)\n",
      "\n",
      "Training model for Experiment 4\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 0.253139\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 0.226209\n",
      "Testing model for Experiment 4\n",
      "\n",
      "Test set: Average loss: 0.0093, Accuracy: 6922/10000 (69%)\n",
      "\n",
      "Training model for Experiment 4\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 0.241326\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 0.201024\n",
      "Testing model for Experiment 4\n",
      "\n",
      "Test set: Average loss: 0.0100, Accuracy: 6928/10000 (69%)\n",
      "\n",
      "Training model for Experiment 4\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 0.118696\n",
      "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 0.139390\n",
      "Testing model for Experiment 4\n",
      "\n",
      "Test set: Average loss: 0.0106, Accuracy: 6872/10000 (69%)\n",
      "\n",
      "Training model for Experiment 4\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLoss: 0.128859\n",
      "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 0.192129\n",
      "Testing model for Experiment 4\n",
      "\n",
      "Test set: Average loss: 0.0109, Accuracy: 6979/10000 (70%)\n",
      "\n",
      "Training model for Experiment 4\n",
      "Train Epoch: 11 [0/50000 (0%)]\tLoss: 0.089161\n",
      "Train Epoch: 11 [25600/50000 (51%)]\tLoss: 0.139128\n",
      "Testing model for Experiment 4\n",
      "\n",
      "Test set: Average loss: 0.0114, Accuracy: 6974/10000 (70%)\n",
      "\n",
      "Training model for Experiment 4\n",
      "Train Epoch: 12 [0/50000 (0%)]\tLoss: 0.109085\n",
      "Train Epoch: 12 [25600/50000 (51%)]\tLoss: 0.136861\n",
      "Testing model for Experiment 4\n",
      "\n",
      "Test set: Average loss: 0.0117, Accuracy: 6950/10000 (70%)\n",
      "\n",
      "Training model for Experiment 4\n",
      "Train Epoch: 13 [0/50000 (0%)]\tLoss: 0.069975\n",
      "Train Epoch: 13 [25600/50000 (51%)]\tLoss: 0.133889\n",
      "Testing model for Experiment 4\n",
      "\n",
      "Test set: Average loss: 0.0119, Accuracy: 6956/10000 (70%)\n",
      "\n",
      "Training model for Experiment 4\n",
      "Train Epoch: 14 [0/50000 (0%)]\tLoss: 0.056126\n",
      "Train Epoch: 14 [25600/50000 (51%)]\tLoss: 0.047827\n",
      "Testing model for Experiment 4\n",
      "\n",
      "Test set: Average loss: 0.0124, Accuracy: 6851/10000 (69%)\n",
      "\n",
      "Training model for Experiment 4\n",
      "Train Epoch: 15 [0/50000 (0%)]\tLoss: 0.043476\n",
      "Train Epoch: 15 [25600/50000 (51%)]\tLoss: 0.086604\n",
      "Testing model for Experiment 4\n",
      "\n",
      "Test set: Average loss: 0.0128, Accuracy: 6947/10000 (69%)\n",
      "\n",
      "Training model for Experiment 4\n",
      "Train Epoch: 16 [0/50000 (0%)]\tLoss: 0.082595\n",
      "Train Epoch: 16 [25600/50000 (51%)]\tLoss: 0.107397\n",
      "Testing model for Experiment 4\n",
      "\n",
      "Test set: Average loss: 0.0132, Accuracy: 6930/10000 (69%)\n",
      "\n",
      "Training model for Experiment 4\n",
      "Train Epoch: 17 [0/50000 (0%)]\tLoss: 0.069766\n",
      "Train Epoch: 17 [25600/50000 (51%)]\tLoss: 0.070776\n",
      "Testing model for Experiment 4\n",
      "\n",
      "Test set: Average loss: 0.0128, Accuracy: 6926/10000 (69%)\n",
      "\n",
      "Training model for Experiment 4\n",
      "Train Epoch: 18 [0/50000 (0%)]\tLoss: 0.039250\n",
      "Train Epoch: 18 [25600/50000 (51%)]\tLoss: 0.057406\n",
      "Testing model for Experiment 4\n",
      "\n",
      "Test set: Average loss: 0.0134, Accuracy: 6943/10000 (69%)\n",
      "\n",
      "Training model for Experiment 4\n",
      "Train Epoch: 19 [0/50000 (0%)]\tLoss: 0.061446\n",
      "Train Epoch: 19 [25600/50000 (51%)]\tLoss: 0.074416\n",
      "Testing model for Experiment 4\n",
      "\n",
      "Test set: Average loss: 0.0134, Accuracy: 6958/10000 (70%)\n",
      "\n",
      "Training model for Experiment 4\n",
      "Train Epoch: 20 [0/50000 (0%)]\tLoss: 0.025614\n",
      "Train Epoch: 20 [25600/50000 (51%)]\tLoss: 0.053544\n",
      "Testing model for Experiment 4\n",
      "\n",
      "Test set: Average loss: 0.0138, Accuracy: 6948/10000 (69%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run training and testing for twenty epochs, same as experiment 3\n",
    "for epoch in range(1, 21):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now something more interesting, let's do transfer learning with the RESnet-34 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformaciones diferentes para el entrenamiento y la prueba\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Load datasets with the new transformations\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the transformed datasets into the dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=256, shuffle=True, num_workers=4, pin_memory=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alope\\OneDrive\\Documentos\\GitHub\\M2_5---CNN-with-CIFAR-10\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\alope\\OneDrive\\Documentos\\GitHub\\M2_5---CNN-with-CIFAR-10\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to C:\\Users\\alope/.cache\\torch\\hub\\checkpoints\\resnet34-b627a593.pth\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "# Load a pre-trained ResNet-34 model to do the transfer learning\n",
    "resnet = models.resnet34(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the final fully connected layer for CIFAR-10, which has 10 classes, so 10 outputs\n",
    "num_ftrs = resnet.fc.in_features\n",
    "resnet.fc = nn.Linear(num_ftrs, 10)\n",
    "model = resnet.to(gpu_device) # Send the model to the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the model initial layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Only the final layer parameters will be updated\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train(epoch):\n",
    "    print(f'Training model for Experiment 4 - Transfer Learning')\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(trainloader):\n",
    "        data, target = data.to(gpu_device), target.to(gpu_device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(trainloader.dataset)} ({100. * batch_idx / len(trainloader):.0f}%)]\\tLoss: {loss.item():.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing function\n",
    "def test():\n",
    "    print(f'Testing model for Experiment 4 - Transfer Learning')\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in testloader:\n",
    "            data, target = data.to(gpu_device), target.to(gpu_device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    \n",
    "    test_loss /= len(testloader.dataset)\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(testloader.dataset)} ({100. * correct / len(testloader.dataset):.0f}%)\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for Experiment 4 - Transfer Learning\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.546026\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 1.885236\n",
      "Testing model for Experiment 4 - Transfer Learning\n",
      "\n",
      "Test set: Average loss: 0.0189, Accuracy: 3692/10000 (37%)\n",
      "\n",
      "Training model for Experiment 4 - Transfer Learning\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.809667\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 1.823084\n",
      "Testing model for Experiment 4 - Transfer Learning\n",
      "\n",
      "Test set: Average loss: 0.0178, Accuracy: 3951/10000 (40%)\n",
      "\n",
      "Training model for Experiment 4 - Transfer Learning\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1.743235\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 1.684243\n",
      "Testing model for Experiment 4 - Transfer Learning\n",
      "\n",
      "Test set: Average loss: 0.0177, Accuracy: 4008/10000 (40%)\n",
      "\n",
      "Training model for Experiment 4 - Transfer Learning\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 1.713868\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 1.670638\n",
      "Testing model for Experiment 4 - Transfer Learning\n",
      "\n",
      "Test set: Average loss: 0.0176, Accuracy: 4069/10000 (41%)\n",
      "\n",
      "Training model for Experiment 4 - Transfer Learning\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 1.610903\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 1.575483\n",
      "Testing model for Experiment 4 - Transfer Learning\n",
      "\n",
      "Test set: Average loss: 0.0173, Accuracy: 4183/10000 (42%)\n",
      "\n",
      "Training model for Experiment 4 - Transfer Learning\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 1.635903\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 1.609023\n",
      "Testing model for Experiment 4 - Transfer Learning\n",
      "\n",
      "Test set: Average loss: 0.0173, Accuracy: 4197/10000 (42%)\n",
      "\n",
      "Training model for Experiment 4 - Transfer Learning\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 1.522157\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 1.679972\n",
      "Testing model for Experiment 4 - Transfer Learning\n",
      "\n",
      "Test set: Average loss: 0.0173, Accuracy: 4156/10000 (42%)\n",
      "\n",
      "Training model for Experiment 4 - Transfer Learning\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 1.655854\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 1.656483\n",
      "Testing model for Experiment 4 - Transfer Learning\n",
      "\n",
      "Test set: Average loss: 0.0171, Accuracy: 4221/10000 (42%)\n",
      "\n",
      "Training model for Experiment 4 - Transfer Learning\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 1.649857\n",
      "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 1.700584\n",
      "Testing model for Experiment 4 - Transfer Learning\n",
      "\n",
      "Test set: Average loss: 0.0170, Accuracy: 4263/10000 (43%)\n",
      "\n",
      "Training model for Experiment 4 - Transfer Learning\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLoss: 1.523010\n",
      "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 1.757145\n",
      "Testing model for Experiment 4 - Transfer Learning\n",
      "\n",
      "Test set: Average loss: 0.0171, Accuracy: 4279/10000 (43%)\n",
      "\n",
      "Training model for Experiment 4 - Transfer Learning\n",
      "Train Epoch: 11 [0/50000 (0%)]\tLoss: 1.523473\n",
      "Train Epoch: 11 [25600/50000 (51%)]\tLoss: 1.593808\n",
      "Testing model for Experiment 4 - Transfer Learning\n",
      "\n",
      "Test set: Average loss: 0.0171, Accuracy: 4263/10000 (43%)\n",
      "\n",
      "Training model for Experiment 4 - Transfer Learning\n",
      "Train Epoch: 12 [0/50000 (0%)]\tLoss: 1.640054\n",
      "Train Epoch: 12 [25600/50000 (51%)]\tLoss: 1.535491\n",
      "Testing model for Experiment 4 - Transfer Learning\n",
      "\n",
      "Test set: Average loss: 0.0170, Accuracy: 4289/10000 (43%)\n",
      "\n",
      "Training model for Experiment 4 - Transfer Learning\n",
      "Train Epoch: 13 [0/50000 (0%)]\tLoss: 1.559648\n",
      "Train Epoch: 13 [25600/50000 (51%)]\tLoss: 1.553072\n",
      "Testing model for Experiment 4 - Transfer Learning\n",
      "\n",
      "Test set: Average loss: 0.0169, Accuracy: 4278/10000 (43%)\n",
      "\n",
      "Training model for Experiment 4 - Transfer Learning\n",
      "Train Epoch: 14 [0/50000 (0%)]\tLoss: 1.518981\n",
      "Train Epoch: 14 [25600/50000 (51%)]\tLoss: 1.619603\n",
      "Testing model for Experiment 4 - Transfer Learning\n",
      "\n",
      "Test set: Average loss: 0.0169, Accuracy: 4305/10000 (43%)\n",
      "\n",
      "Training model for Experiment 4 - Transfer Learning\n",
      "Train Epoch: 15 [0/50000 (0%)]\tLoss: 1.586177\n",
      "Train Epoch: 15 [25600/50000 (51%)]\tLoss: 1.486298\n",
      "Testing model for Experiment 4 - Transfer Learning\n",
      "\n",
      "Test set: Average loss: 0.0170, Accuracy: 4249/10000 (42%)\n",
      "\n",
      "Training model for Experiment 4 - Transfer Learning\n",
      "Train Epoch: 16 [0/50000 (0%)]\tLoss: 1.496656\n",
      "Train Epoch: 16 [25600/50000 (51%)]\tLoss: 1.669109\n",
      "Testing model for Experiment 4 - Transfer Learning\n",
      "\n",
      "Test set: Average loss: 0.0170, Accuracy: 4289/10000 (43%)\n",
      "\n",
      "Training model for Experiment 4 - Transfer Learning\n",
      "Train Epoch: 17 [0/50000 (0%)]\tLoss: 1.586992\n",
      "Train Epoch: 17 [25600/50000 (51%)]\tLoss: 1.596733\n",
      "Testing model for Experiment 4 - Transfer Learning\n",
      "\n",
      "Test set: Average loss: 0.0171, Accuracy: 4267/10000 (43%)\n",
      "\n",
      "Training model for Experiment 4 - Transfer Learning\n",
      "Train Epoch: 18 [0/50000 (0%)]\tLoss: 1.663809\n",
      "Train Epoch: 18 [25600/50000 (51%)]\tLoss: 1.680792\n",
      "Testing model for Experiment 4 - Transfer Learning\n",
      "\n",
      "Test set: Average loss: 0.0168, Accuracy: 4306/10000 (43%)\n",
      "\n",
      "Training model for Experiment 4 - Transfer Learning\n",
      "Train Epoch: 19 [0/50000 (0%)]\tLoss: 1.597440\n",
      "Train Epoch: 19 [25600/50000 (51%)]\tLoss: 1.767721\n",
      "Testing model for Experiment 4 - Transfer Learning\n",
      "\n",
      "Test set: Average loss: 0.0169, Accuracy: 4297/10000 (43%)\n",
      "\n",
      "Training model for Experiment 4 - Transfer Learning\n",
      "Train Epoch: 20 [0/50000 (0%)]\tLoss: 1.614287\n",
      "Train Epoch: 20 [25600/50000 (51%)]\tLoss: 1.613821\n",
      "Testing model for Experiment 4 - Transfer Learning\n",
      "\n",
      "Test set: Average loss: 0.0170, Accuracy: 4262/10000 (43%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run training and testing for 20 epochs\n",
    "for epoch in range(1, 21):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
